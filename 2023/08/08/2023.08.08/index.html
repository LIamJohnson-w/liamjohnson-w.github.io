<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>【用户画像(七)】数据挖掘之RFM,RFE,PSM标签计算 | SilverSucks</title><meta name="author" content="Jason"><meta name="copyright" content="Jason"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="数据挖掘KMeans算法KMeans介绍 k均值聚类算法（k-means clustering algorithm）是一种迭代求解的聚类分析算法，其步骤是，预将数据分为K组，则随机选取K个对象作为初始的聚类中心，然后计算每个对象与各个种子聚类中心之间的距离，把每个对象分配给距离它最近的聚类中心。聚类"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://liamjohnson-w.github.io/2023/08/08/2023.08.08/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '【用户画像(七)】数据挖掘之RFM,RFE,PSM标签计算',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-08-09 21:52:29'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"> <script src="/live2d-widget/autoload.js"></script><script src="/live2d-widget/autoload.js"> </script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/tx.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">232</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">58</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Links</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-gamepad"></i><span> Games</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/mikutap/"><i class="fa-fw fa fa-music"></i><span> MikuTap 初音未来</span></a></li><li><a class="site-page child" href="/starbattle/"><i class="fa-fw fa fa-space-shuttle"></i><span> StartBattle 星际大战</span></a></li><li><a class="site-page child" href="/2048/"><i class="fa-fw fa fa-flag"></i><span> 2048 经典游戏</span></a></li><li><a class="site-page child" href="/battlecity/"><i class="fa-fw fa fa-arrow-circle-left"></i><span> BattleCity 坦克大战</span></a></li><li><a class="site-page child" href="/pacman/"><i class="fa-fw fa fa-bolt"></i><span> PacMan  吃豆人</span></a></li><li><a class="site-page child" href="/tetris/"><i class="fa-fw fa fa-arrows-alt"></i><span> Tetris 俄罗斯方块</span></a></li><li><a class="site-page child" href="/smallcat/"><i class="fa-fw fa fa-paw"></i><span> CatchCat 困住小猫</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-leaf"></i><span> Moments</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/diary/"><i class="fa-fw fas fa-bookmark"></i><span> Diary</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fa fa-hourglass-half"></i><span> Gallery</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-podcast"></i><span> More</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags标签</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About关于</span></a></li><li><a class="site-page child" href="/messageboard/"><i class="fa-fw fas fa-bookmark"></i><span> Messageboard留言板</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s1.ax1x.com/2023/04/18/p9i6u5D.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="SilverSucks"><span class="site-name">SilverSucks</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Links</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-gamepad"></i><span> Games</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/mikutap/"><i class="fa-fw fa fa-music"></i><span> MikuTap 初音未来</span></a></li><li><a class="site-page child" href="/starbattle/"><i class="fa-fw fa fa-space-shuttle"></i><span> StartBattle 星际大战</span></a></li><li><a class="site-page child" href="/2048/"><i class="fa-fw fa fa-flag"></i><span> 2048 经典游戏</span></a></li><li><a class="site-page child" href="/battlecity/"><i class="fa-fw fa fa-arrow-circle-left"></i><span> BattleCity 坦克大战</span></a></li><li><a class="site-page child" href="/pacman/"><i class="fa-fw fa fa-bolt"></i><span> PacMan  吃豆人</span></a></li><li><a class="site-page child" href="/tetris/"><i class="fa-fw fa fa-arrows-alt"></i><span> Tetris 俄罗斯方块</span></a></li><li><a class="site-page child" href="/smallcat/"><i class="fa-fw fa fa-paw"></i><span> CatchCat 困住小猫</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-leaf"></i><span> Moments</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/diary/"><i class="fa-fw fas fa-bookmark"></i><span> Diary</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fa fa-hourglass-half"></i><span> Gallery</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-podcast"></i><span> More</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags标签</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About关于</span></a></li><li><a class="site-page child" href="/messageboard/"><i class="fa-fw fas fa-bookmark"></i><span> Messageboard留言板</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">【用户画像(七)】数据挖掘之RFM,RFE,PSM标签计算</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-08-07T16:00:00.000Z" title="Created 2023-08-08 00:00:00">2023-08-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-08-09T13:52:29.000Z" title="Updated 2023-08-09 21:52:29">2023-08-09</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="【用户画像(七)】数据挖掘之RFM,RFE,PSM标签计算"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="数据挖掘KMeans算法"><a href="#数据挖掘KMeans算法" class="headerlink" title="数据挖掘KMeans算法"></a><font size=6 color='red' face='华文楷体'>数据挖掘KMeans算法</font></h1><h2 id="KMeans介绍"><a href="#KMeans介绍" class="headerlink" title="KMeans介绍"></a><font size=5 color='orange' face='华文楷体'>KMeans介绍</font></h2><blockquote>
<p>k均值聚类算法（k-means clustering algorithm）是一种<code>迭代</code>求解的<code>聚类分析算法</code>，其步骤是，预将数据分为K组，则随机选取K个对象作为初始的<code>聚类中心</code>，然后计算每个对象与各个种子聚类中心之间的距离，把每个对象分配给距离它最近的聚类中心。聚类中心以及分配给它们的对象就代表一个<code>聚类</code>。每分配一个样本，聚类的聚类中心会根据聚类中现有的对象被<code>重新计算</code>。这个过程将不断重复直到满足某个终止条件。终止条件可以是没有（或最小数目）对象被重新分配给不同的聚类，没有（或最小数目）聚类中心再发生变化，误差平方和局部最小。</p>
</blockquote>
<h2 id="余弦相似度"><a href="#余弦相似度" class="headerlink" title="余弦相似度"></a><font size=5 color='orange' face='华文楷体'>余弦相似度</font></h2><h3 id="什么是余弦相似度"><a href="#什么是余弦相似度" class="headerlink" title="什么是余弦相似度"></a><font size=4 color='green' face='华文楷体'>什么是余弦相似度</font></h3><blockquote>
<p>**余弦相似度算法：**一个向量空间中两个向量夹角间的余弦值作为衡量两个个体之间差异的大小，余弦值接近1，夹角趋于0，表明两个向量越相似，余弦值接近于0，夹角趋于90度，表明两个向量越不相似</p>
</blockquote>
<blockquote>
<p>主要应用在数据查重场景中, 这里推荐一篇大佬的文章, 写的简单易懂</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u014539465/article/details/105353638/">https://blog.csdn.net/u014539465/article/details/105353638/</a></p>
<p>文档1：有&#x2F;问题&#x2F;下课&#x2F;找&#x2F;我&#x2F; 1827777777</p>
<p>文档2：下课&#x2F;有&#x2F;问题&#x2F;可以&#x2F;找&#x2F;我&#x2F; 1877777777</p>
<p>文档1：(TF, IDF)</p>
<p>有 1 0.5</p>
<p>问题 1 0.5</p>
<p>下课 1 0.5</p>
<p>找 1 0.5</p>
<p>我 1 0.5</p>
<p>18.. 10.5</p>
</blockquote>
<h2 id="KMeans算法原理"><a href="#KMeans算法原理" class="headerlink" title="KMeans算法原理"></a><font size=5 color='orange' face='华文楷体'>KMeans算法原理</font></h2><blockquote>
<p>k-means其实包含两层内容：</p>
<ul>
<li>K表示初始中心点个数（计划聚类数）</li>
<li>means求中心点到其他数据点距离的平均值, K自己设置(2,3,4,5,6,7,8)</li>
</ul>
</blockquote>
<ul>
<li><p><input checked="" disabled="" type="checkbox"> 
说白了就是计算给定数据中心点的位置(通过不断矫正某个簇的中心点距离其它点的距离的方差- 方差越小越说明接近中心, 来实现聚类算法)</p>
</li>
<li><p><input disabled="" type="checkbox"> 
具体步骤如下：</p>
<ul>
<li><p>随机设置K个特征空间内的点作为初始的聚类中心</p>
</li>
<li><p>对于其他每个点计算到K个中心的距离，未知的点选择最近的一个聚类中心点作为标记类别</p>
</li>
<li><p>接着对着标记的聚类中心之后，重新计算出每个聚类的新中心点（平均值）</p>
</li>
<li><p>如果计算得出的新中心点与原中心点一样（质心不再移动），那么结束，否则重新进行第二步过程</p>
</li>
</ul>
</li>
</ul>
<p><img src="https://markdownotepic.oss-cn-hangzhou.aliyuncs.com/imgs/image-20230518170849066.png?images" alt="image-20230518170849066"></p>
<h2 id="KMeans算法特点"><a href="#KMeans算法特点" class="headerlink" title="KMeans算法特点"></a><font size=5 color='orange' face='华文楷体'>KMeans算法特点</font></h2><blockquote>
<p>优点：速度快，简单</p>
<ul>
<li>对处理大数据集，该算法保持可伸缩性和高效率。</li>
<li>当簇近似为高斯分布(也就是概论中学的正态分布)时，它的效果较好。</li>
</ul>
<p>缺点：最终结果跟初始点选择相关，容易陷入局部最优</p>
<ul>
<li>k均值算法中k是实现者给定的，这个k值的选定是非常难估计的。</li>
<li>k均值的聚类算法需要不断地进行样本分类调整，不断地计算调整后的新的聚类中心，当数据量大的时候，算法开销很大。</li>
<li>k均值是求得局部最优解的算法，所以对于初始化时选取的k个聚类的中心比较敏感，不同点的中心选取策略可能带来不同的聚类结果。</li>
<li>对噪声点和孤立点数据敏感。</li>
</ul>
<p><code>KMeans一般是其他聚类方法的基础算法，如谱聚类。</code></p>
</blockquote>
<h2 id="KMeans模型评估"><a href="#KMeans模型评估" class="headerlink" title="KMeans模型评估"></a><font size=5 color='orange' face='华文楷体'>KMeans模型评估</font></h2><ul>
<li>SSE表示数据样本与它所属的簇中心之间的距离（差异度）平方之和。<ul>
<li><img src="https://markdownotepic.oss-cn-hangzhou.aliyuncs.com/imgs/wps6.png?images" alt="img"></li>
<li>直观的来说，SSE越小，表示数据点越接近它们的中心，聚类效果越好。</li>
<li>因为对误差取了平方，更加重视那些远离中心的点。</li>
</ul>
</li>
<li>聚类算法评估使用SC系数&#x2F;轮廓系数<ul>
<li><img src="https://markdownotepic.oss-cn-hangzhou.aliyuncs.com/imgs/sc.png?images"></li>
<li>轮廓系数: 取值范围[ -1,1] 取值越大越好 </li>
<li>聚成不同的类别  k &#x3D; 3, k &#x3D; 4,k&#x3D;5,k&#x3D;6, k&#x3D;7 , 每次聚类之后, 都算一下轮廓系数, 轮廓系数最大的聚类的方式就是最佳的K值</li>
</ul>
</li>
</ul>
<h2 id="KMeans模型实现"><a href="#KMeans模型实现" class="headerlink" title="KMeans模型实现"></a><font size=5 color='orange' face='华文楷体'>KMeans模型实现</font></h2><ul>
<li><code>from pyspark.ml.clustering import KMeans</code>     创建KMeans聚类对象</li>
<li><code>from pyspark.ml.evaluation import ClusteringEvaluator</code>    创建ClusteringEvaluator  聚类评估器对象</li>
<li>一般需要搭配VectorAssembler聚类使用, 给出参数features_column, prediction_column, key, seed就可以训练模型</li>
<li>通过</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.clustering <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> ClusteringEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 创建Spark运行环境</span></span><br><span class="line">    spark = SparkSession\</span><br><span class="line">            .builder\</span><br><span class="line">            .appName(<span class="string">&#x27;Kmeans算法实现&#x27;</span>)\</span><br><span class="line">            .master(<span class="string">&#x27;local[*]&#x27;</span>)\</span><br><span class="line">            .getOrCreate()</span><br><span class="line">    <span class="comment"># 1, 加载数据</span></span><br><span class="line">    data_df = spark.read\</span><br><span class="line">        .<span class="built_in">format</span>(<span class="string">&#x27;csv&#x27;</span>)\</span><br><span class="line">        .option(<span class="string">&#x27;header&#x27;</span>, <span class="literal">True</span>)\</span><br><span class="line">        .option(<span class="string">&#x27;inferSchema&#x27;</span>, <span class="literal">True</span>)\</span><br><span class="line">        .load(<span class="string">&#x27;/root/a.txt&#x27;</span>)</span><br><span class="line">    <span class="comment"># data_df.show()</span></span><br><span class="line">    <span class="comment"># +-----------+----+</span></span><br><span class="line">    <span class="comment"># |Weightindex|PH值|</span></span><br><span class="line">    <span class="comment"># +-----------+----+</span></span><br><span class="line">    <span class="comment"># |        1.0| 1.0|</span></span><br><span class="line">    <span class="comment"># |        2.0| 1.0|</span></span><br><span class="line">    <span class="comment"># |        4.0| 3.0|</span></span><br><span class="line">    <span class="comment"># |        5.0| 4.0|</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2, 特征工程(将特征列封装到一个向量列当中</span></span><br><span class="line">    assembler = VectorAssembler(inputCols=[<span class="string">&#x27;Weightindex&#x27;</span>,<span class="string">&#x27;PH值&#x27;</span>], outputCol=<span class="string">&#x27;features&#x27;</span>)</span><br><span class="line">    <span class="comment"># 2.1 创建模型(VectorAssmebler可以省略fit), 并计算数据</span></span><br><span class="line">    result_df = assembler.transform(data_df)</span><br><span class="line">    <span class="comment"># result_df.show()</span></span><br><span class="line">    <span class="comment"># +-----------+----+---------+</span></span><br><span class="line">    <span class="comment"># |Weightindex|PH值| features|</span></span><br><span class="line">    <span class="comment"># +-----------+----+---------+</span></span><br><span class="line">    <span class="comment"># |        1.0| 1.0|[1.0,1.0]|</span></span><br><span class="line">    <span class="comment"># |        2.0| 1.0|[2.0,1.0]|</span></span><br><span class="line">    <span class="comment"># |        4.0| 3.0|[4.0,3.0]|</span></span><br><span class="line">    <span class="comment"># |        5.0| 4.0|[5.0,4.0]|</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3, 模型训练 (使用KMeans进行模型训练, 始终逃不过fit和transform</span></span><br><span class="line">    <span class="comment"># 3.1 创建KMeans对象</span></span><br><span class="line">    kmeans = KMeans(featuresCol=<span class="string">&#x27;features&#x27;</span>, predictionCol=<span class="string">&#x27;prediction&#x27;</span>,k=<span class="number">2</span>, seed=<span class="number">5</span>)</span><br><span class="line">    <span class="comment"># 3.2 创建模型,并计算</span></span><br><span class="line">    new_result_df = kmeans.fit(result_df).transform(result_df)</span><br><span class="line">    new_result_df.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4, 模型评估</span></span><br><span class="line">    evalutor = ClusteringEvaluator(predictionCol=<span class="string">&#x27;prediction&#x27;</span>, featuresCol=<span class="string">&#x27;features&#x27;</span>)</span><br><span class="line">    sc = evalutor.evaluate(new_result_df)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;轮廓系数为: <span class="subst">&#123;sc&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="KMeans计算RFM标签"><a href="#KMeans计算RFM标签" class="headerlink" title="KMeans计算RFM标签"></a><font size=6 color='red' face='华文楷体'>KMeans计算RFM标签</font></h1><h2 id="什么是RFM模型"><a href="#什么是RFM模型" class="headerlink" title="什么是RFM模型"></a><font size=5 color='orange' face='华文楷体'>什么是RFM模型</font></h2><blockquote>
<p>上篇文章介绍过了, 这里就不多bb了!</p>
<p>讲一下思想: </p>
<ul>
<li>首先通过KMeans算法得到prediction列</li>
<li>通过[numpy.sum(x) for x in centers]获取center_list中心点值的一个列表(列表中的元素和prediction中的0, 1, 2, 3簇标识一一对应)</li>
<li>将刚才获取的列表转为字典(for i in range(0, len(center_list): new_dict[i] &#x3D; center_list[i])顺序不会发生变化)</li>
<li>对字典进行排序,按值排序(key&#x3D;lambda x: x[1], reverse&#x3D;True)</li>
<li>取上面排过序的字典, 取字典的键, 并获取五级标签的id为值(价格敏感度高的排在前面, 且根据逻辑价格敏感度高的中心点的值越大)合成为新的字典new_dict</li>
<li>创建udf函数, 在后续调用, 将prediction类传入函数中, 最终返回new_dict[prediction]</li>
</ul>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">就是说</span>: <span class="string">按簇中心点的值排序, 值大的, 价格敏感度越高</span></span><br></pre></td></tr></table></figure>

</blockquote>
<h2 id="RFM标签计算流程"><a href="#RFM标签计算流程" class="headerlink" title="RFM标签计算流程"></a><font size=5 color='orange' face='华文楷体'>RFM标签计算流程</font></h2><blockquote>
<ul>
<li>1、计算 R&#x2F;F&#x2F;M的值 <ul>
<li>R  用户id分组消费时间求最大值,</li>
<li>F  用户id分组 count计数 (去重计数)</li>
<li>M  用户id分组 金额求和</li>
</ul>
</li>
<li>2、R&#x2F;F&#x2F;M 分别打分 </li>
<li>3、使用KMeans算法进行聚类  </li>
<li>4、将聚类结果和5级标签的rule匹配</li>
<li>5、给用户打上标签</li>
</ul>
</blockquote>
<h2 id="RFM标签计算实现"><a href="#RFM标签计算实现" class="headerlink" title="RFM标签计算实现"></a><font size=5 color='orange' face='华文楷体'>RFM标签计算实现</font></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> DataFrame</span><br><span class="line"><span class="keyword">import</span> pyspark.sql.functions <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StringType</span><br><span class="line"><span class="keyword">from</span> UserProfile.offline.base.TagComputeBase <span class="keyword">import</span> TagComputeBase</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.clustering <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TagCptByKmeans</span>(<span class="title class_ inherited__">TagComputeBase</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">tagCompute</span>(<span class="params">self, es_df: DataFrame, tag5_df: DataFrame</span>):</span><br><span class="line">        <span class="comment"># es_df.show()</span></span><br><span class="line">        <span class="comment"># +----------+--------+-----------+--------------------+</span></span><br><span class="line">        <span class="comment"># |finishtime|memberid|orderamount|             ordersn|</span></span><br><span class="line">        <span class="comment"># +----------+--------+-----------+--------------------+</span></span><br><span class="line">        <span class="comment"># |1594137600|     342|        1.0|jd_15062716252125282|</span></span><br><span class="line">        <span class="comment"># |1594310400|     405|     3699.0|jd_15062720080896457|</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># tag5_df.show()</span></span><br><span class="line">        <span class="comment"># +---+----+</span></span><br><span class="line">        <span class="comment"># | id|rule|</span></span><br><span class="line">        <span class="comment"># +---+----+</span></span><br><span class="line">        <span class="comment"># | 38|   1|</span></span><br><span class="line">        <span class="comment"># | 39|   2|</span></span><br><span class="line">        <span class="comment"># | 40|   3|</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1、计算 R/F/M的值</span></span><br><span class="line">        <span class="comment"># R  用户id分组消费时间求最大值,</span></span><br><span class="line">        rAgg = F.datediff(F.date_sub(F.current_date(), <span class="number">1035</span>),</span><br><span class="line">                          F.from_unixtime(F.<span class="built_in">max</span>(F.col(<span class="string">&#x27;finishtime&#x27;</span>)), <span class="built_in">format</span>=<span class="string">&#x27;yyyy-MM-dd&#x27;</span>)).alias(<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">        <span class="comment"># F  用户id分组 count计数 (去重计数)</span></span><br><span class="line">        fAgg = F.countDistinct(F.col(<span class="string">&#x27;ordersn&#x27;</span>)).alias(<span class="string">&#x27;f&#x27;</span>)</span><br><span class="line">        <span class="comment"># M  用户id分组 金额求和</span></span><br><span class="line">        mAgg = F.<span class="built_in">sum</span>(F.col(<span class="string">&#x27;orderamount&#x27;</span>)).alias(<span class="string">&#x27;m&#x27;</span>)</span><br><span class="line">        rfm_df = es_df.groupBy(<span class="string">&#x27;memberid&#x27;</span>).agg(rAgg, fAgg, mAgg)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># rfm_df.show()</span></span><br><span class="line">        <span class="comment"># +--------+---+---+------------------+</span></span><br><span class="line">        <span class="comment"># |memberid|  r|  f|                 m|</span></span><br><span class="line">        <span class="comment"># +--------+---+---+------------------+</span></span><br><span class="line">        <span class="comment"># |     747| 67|111|202788.09013915993|</span></span><br><span class="line">        <span class="comment"># |     303| 67| 97|168033.97006225586|</span></span><br><span class="line">        <span class="comment"># |      61| 67|230|373673.77001953125|</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2、R/F/M 分别打分</span></span><br><span class="line">        rScore = F.when(F.col(<span class="string">&#x27;r&#x27;</span>).between(<span class="number">1</span>, <span class="number">7</span>), <span class="number">5</span>) \</span><br><span class="line">            .when(F.col(<span class="string">&#x27;r&#x27;</span>).between(<span class="number">8</span>, <span class="number">14</span>), <span class="number">4</span>) \</span><br><span class="line">            .when(F.col(<span class="string">&#x27;r&#x27;</span>).between(<span class="number">15</span>, <span class="number">30</span>), <span class="number">3</span>) \</span><br><span class="line">            .when(F.col(<span class="string">&#x27;r&#x27;</span>).between(<span class="number">31</span>, <span class="number">60</span>), <span class="number">2</span>) \</span><br><span class="line">            .otherwise(<span class="number">1</span>).alias(<span class="string">&#x27;rScore&#x27;</span>)</span><br><span class="line">        fScore = F.when(F.col(<span class="string">&#x27;f&#x27;</span>).between(<span class="number">1</span>, <span class="number">100</span>), <span class="number">1</span>) \</span><br><span class="line">            .when(F.col(<span class="string">&#x27;f&#x27;</span>).between(<span class="number">101</span>, <span class="number">150</span>), <span class="number">2</span>) \</span><br><span class="line">            .when(F.col(<span class="string">&#x27;f&#x27;</span>).between(<span class="number">151</span>, <span class="number">200</span>), <span class="number">3</span>) \</span><br><span class="line">            .when(F.col(<span class="string">&#x27;f&#x27;</span>).between(<span class="number">201</span>, <span class="number">300</span>), <span class="number">4</span>) \</span><br><span class="line">            .otherwise(<span class="number">5</span>).alias(<span class="string">&#x27;fScore&#x27;</span>)</span><br><span class="line">        mScore = F.when(F.col(<span class="string">&#x27;m&#x27;</span>).between(<span class="number">1</span>, <span class="number">200000</span>), <span class="number">1</span>) \</span><br><span class="line">            .when(F.col(<span class="string">&#x27;m&#x27;</span>).between(<span class="number">200001</span>, <span class="number">300000</span>), <span class="number">2</span>) \</span><br><span class="line">            .when(F.col(<span class="string">&#x27;m&#x27;</span>).between(<span class="number">300001</span>, <span class="number">500000</span>), <span class="number">3</span>) \</span><br><span class="line">            .when(F.col(<span class="string">&#x27;m&#x27;</span>).between(<span class="number">500001</span>, <span class="number">800000</span>), <span class="number">4</span>) \</span><br><span class="line">            .otherwise(<span class="number">5</span>).alias(<span class="string">&#x27;mScore&#x27;</span>)</span><br><span class="line">        rfm_s_df = rfm_df.select(F.col(<span class="string">&#x27;memberid&#x27;</span>).alias(<span class="string">&#x27;userId&#x27;</span>), rScore, fScore, mScore)</span><br><span class="line">        <span class="comment"># rfm_s_df.show()</span></span><br><span class="line">        <span class="comment"># +------+------+------+------+</span></span><br><span class="line">        <span class="comment"># |userId|rScore|fScore|mScore|</span></span><br><span class="line">        <span class="comment"># +------+------+------+------+</span></span><br><span class="line">        <span class="comment"># |   747|     1|     2|     2|</span></span><br><span class="line">        <span class="comment"># |   303|     1|     1|     1|</span></span><br><span class="line">        <span class="comment"># |    61|     1|     4|     3|</span></span><br><span class="line">        <span class="comment"># 3、使用KMeans算法进行聚类</span></span><br><span class="line">        <span class="comment"># 3-1、进行特征工程将r f m三个维度列合并一个列中(使用VectorAssembler创建对象, Transform</span></span><br><span class="line">        vectorAssembler = VectorAssembler(inputCols=[<span class="string">&#x27;rScore&#x27;</span>, <span class="string">&#x27;fScore&#x27;</span>,<span class="string">&#x27;mScore&#x27;</span>], outputCol=<span class="string">&#x27;features&#x27;</span>)</span><br><span class="line">        assemble_df = vectorAssembler.transform(rfm_s_df)</span><br><span class="line">        <span class="comment"># assemble_df.show()</span></span><br><span class="line">        <span class="comment"># +------+------+------+------+-------------+</span></span><br><span class="line">        <span class="comment"># |userId|rScore|fScore|mScore|     features|</span></span><br><span class="line">        <span class="comment"># +------+------+------+------+-------------+</span></span><br><span class="line">        <span class="comment"># |   747|     1|     2|     2|[1.0,2.0,2.0]|</span></span><br><span class="line">        <span class="comment"># |   303|     1|     1|     1|[1.0,1.0,1.0]|</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3-2、使用KMeans算法进行模型训练</span></span><br><span class="line">        kmeans = KMeans(featuresCol=<span class="string">&#x27;features&#x27;</span>, predictionCol=<span class="string">&#x27;prediction&#x27;</span>, k=<span class="number">7</span>, seed=<span class="number">3</span>)</span><br><span class="line">        <span class="comment"># 创建模型</span></span><br><span class="line">        model = kmeans.fit(assemble_df)</span><br><span class="line">        <span class="comment"># 计算</span></span><br><span class="line">        prediction_df = model.transform(assemble_df)</span><br><span class="line">        prediction_df.show()</span><br><span class="line">        <span class="comment"># +------+------+------+------+-------------+----------+</span></span><br><span class="line">        <span class="comment"># |userId|rScore|fScore|mScore|     features|prediction|</span></span><br><span class="line">        <span class="comment"># +------+------+------+------+-------------+----------+</span></span><br><span class="line">        <span class="comment"># |   747|     1|     2|     2|[1.0,2.0,2.0]|         0|</span></span><br><span class="line">        <span class="comment"># |   303|     1|     1|     1|[1.0,1.0,1.0]|         4|</span></span><br><span class="line">        <span class="comment"># |    61|     1|     4|     3|[1.0,4.0,3.0]|         3|</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4、将聚类结果和5级标签的rule匹配(已经使用kemeans对数据进行聚类, 分成7个类,需要将每个类对应的值转换为价值标签</span></span><br><span class="line">        <span class="comment"># 4-1、求每个类别的得分</span></span><br><span class="line">        centers = model.clusterCenters()</span><br><span class="line">        <span class="built_in">print</span>(centers)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4-2 求每个中心点得分总和 (下面的等价于 for x in centers: centers_list.append(np.sum(x))</span></span><br><span class="line">        centers_list = [np.<span class="built_in">sum</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> centers]</span><br><span class="line">        <span class="built_in">print</span>(centers_list)</span><br><span class="line">        <span class="comment"># [5.0, 4.0, 9.357142857142858, 8.0, 3.1707317073170733, 6.1, 7.75]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4-3 将中心点的得分和中心点所属于的类别存入到字典中</span></span><br><span class="line">        centers_dict = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(centers_list)):</span><br><span class="line">            centers_dict[i] = centers_list[i]</span><br><span class="line">        <span class="built_in">print</span>(centers_dict)</span><br><span class="line">        <span class="comment"># &#123;0: 5.0, 1: 4.0, 2: 9.357142857142858, 3: 8.0, 4: 3.1707317073170733, 5: 6.1, 6: 7.75&#125;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4-4 对字典进行排序, x: x[1]表示取字典中的value进行排序, reverse=True倒序</span></span><br><span class="line">        sorted_dict = <span class="built_in">dict</span>(<span class="built_in">sorted</span>(centers_dict.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>))</span><br><span class="line">        <span class="built_in">print</span>(sorted_dict)</span><br><span class="line">        <span class="comment"># &#123;2: 9.357142857142858, 3: 8.0, 6: 7.75, 5: 6.1, 0: 5.0, 1: 4.0, 4: 3.1707317073170733&#125;</span></span><br><span class="line">        <span class="comment"># 取出五级标签的rule(将五级标签的rule转换为dict</span></span><br><span class="line">        id_list = tag5_df.rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> row: row.<span class="built_in">id</span>).collect()</span><br><span class="line">        <span class="built_in">print</span>(id_list) <span class="comment"># 顺序获取标签id, [38, 39, 40, 41, 42, 43, 44]</span></span><br><span class="line">        <span class="comment"># key是sorted_dict的键  value对应五级rule, 通过zip将两个东西合并起来</span></span><br><span class="line">        rule_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(sorted_dict.keys(), id_list))</span><br><span class="line">        <span class="built_in">print</span>(rule_dict)</span><br><span class="line">        <span class="comment"># 五级标签id与中心点类别： &#123;4: 38, 3: 39, 2: 40, 6: 41, 0: 42, 1: 43, 5: 44&#125;</span></span><br><span class="line"><span class="meta">        @F.udf</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">prediction2tag5Id</span>(<span class="params">prediction</span>):</span><br><span class="line">            <span class="keyword">return</span> rule_dict[prediction]</span><br><span class="line">        final_result_df = prediction_df.select(F.col(<span class="string">&#x27;userId&#x27;</span>).cast(StringType()).alias(<span class="string">&#x27;userId&#x27;</span>),</span><br><span class="line">                                      prediction2tag5Id(F.col(<span class="string">&#x27;prediction&#x27;</span>)).cast(StringType()).alias(<span class="string">&#x27;tagsId&#x27;</span>) )</span><br><span class="line">        <span class="keyword">return</span> final_result_df</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    appName = <span class="string">&#x27;通过kmeans算法计算rfm标签&#x27;</span></span><br><span class="line">    tag4Id = <span class="number">37</span></span><br><span class="line">    <span class="comment"># 创建标签计算对象</span></span><br><span class="line">    tagCpt = TagCptByKmeans(appName, tag4Id)</span><br><span class="line">    tagCpt.execute()</span><br></pre></td></tr></table></figure>



<h1 id="KMeans计算RFE标签"><a href="#KMeans计算RFE标签" class="headerlink" title="KMeans计算RFE标签"></a><font size=6 color='red' face='华文楷体'>KMeans计算RFE标签</font></h1><h2 id="什么是RFE模型"><a href="#什么是RFE模型" class="headerlink" title="什么是RFE模型"></a><font size=5 color='orange' face='华文楷体'>什么是RFE模型</font></h2><blockquote>
<p>RFE：用户活跃度标签:</p>
<p>使用场景：用户频繁使用但是消费场景比较少，比如信息流应用（今日头条, 腾讯新闻, 微博）</p>
</blockquote>
<h2 id="RFE标签计算流程"><a href="#RFE标签计算流程" class="headerlink" title="RFE标签计算流程"></a><font size=5 color='orange' face='华文楷体'>RFE标签计算流程</font></h2><blockquote>
<ul>
<li>1、计算 R&#x2F;F&#x2F;E的值</li>
<li>2、对R&#x2F;F&#x2F;E 分别打分 </li>
<li>3、使用KMeans算法进行聚类  </li>
<li>4、将聚类结果和5级标签的rule匹配</li>
<li>5、给用户打上标签</li>
</ul>
</blockquote>
<h2 id="RFE标签计算实现"><a href="#RFE标签计算实现" class="headerlink" title="RFE标签计算实现"></a><font size=5 color='orange' face='华文楷体'>RFE标签计算实现</font></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> DataFrame</span><br><span class="line"><span class="keyword">import</span> pyspark.sql.functions <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StringType</span><br><span class="line"><span class="keyword">from</span> UserProfile.offline.base.TagComputeBase <span class="keyword">import</span> TagComputeBase</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.clustering <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TagCptByKmeans</span>(<span class="title class_ inherited__">TagComputeBase</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">tagCompute</span>(<span class="params">self, es_df: DataFrame, tag5_df: DataFrame</span>):</span><br><span class="line">        <span class="comment"># es_df.show()</span></span><br><span class="line">        <span class="comment"># +--------------+--------------------+-------------------+</span></span><br><span class="line">        <span class="comment"># |global_user_id|             loc_url|           log_time|</span></span><br><span class="line">        <span class="comment"># +--------------+--------------------+-------------------+</span></span><br><span class="line">        <span class="comment"># |           806|http://search.esh...|2019-07-26 04:14:36|</span></span><br><span class="line">        <span class="comment"># |           139|http://m.eshop.co...|2019-07-28 19:00:37|</span></span><br><span class="line">        <span class="comment"># |           180|http://www.eshop....|2019-07-21 14:49:14|</span></span><br><span class="line">        <span class="comment"># |           482|http://m.eshop.co...|2019-08-10 23:43:39|</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># tag5_df.show()</span></span><br><span class="line">        <span class="comment"># +---+----+</span></span><br><span class="line">        <span class="comment"># | id|rule|</span></span><br><span class="line">        <span class="comment"># +---+----+</span></span><br><span class="line">        <span class="comment"># | 46|   1|</span></span><br><span class="line">        <span class="comment"># | 47|   2|</span></span><br><span class="line">        <span class="comment"># | 48|   3|</span></span><br><span class="line">        <span class="comment"># | 49|   4|</span></span><br><span class="line">        <span class="comment"># +---+----+</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1、计算 R/F/E的值</span></span><br><span class="line">        r_v = F.datediff(F.date_sub(F.current_date(), <span class="number">1450</span>), F.<span class="built_in">max</span>(F.col(<span class="string">&#x27;log_time&#x27;</span>))).alias(<span class="string">&#x27;r_v&#x27;</span>)</span><br><span class="line">        f_v = F.count(F.col(<span class="string">&#x27;loc_url&#x27;</span>)).alias(<span class="string">&#x27;f_v&#x27;</span>)</span><br><span class="line">        e_v = F.countDistinct(F.col(<span class="string">&#x27;loc_url&#x27;</span>)).alias(<span class="string">&#x27;e_v&#x27;</span>)</span><br><span class="line">        rfe_v_df = es_df.groupby(<span class="string">&#x27;global_user_id&#x27;</span>).agg(r_v, f_v, e_v)</span><br><span class="line">        <span class="comment"># rfe_v_df.show()</span></span><br><span class="line">        <span class="comment"># +--------------+---+---+---+</span></span><br><span class="line">        <span class="comment"># |global_user_id|r_v|f_v|e_v|</span></span><br><span class="line">        <span class="comment"># +--------------+---+---+---+</span></span><br><span class="line">        <span class="comment"># |           107|  2|823|280|</span></span><br><span class="line">        <span class="comment"># |           110|  2|680|249|</span></span><br><span class="line">        <span class="comment"># |           137|  2|858|290|</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2、对R/F/E 分别打分</span></span><br><span class="line">        r_s = F.when(F.col(<span class="string">&#x27;r_v&#x27;</span>).between(<span class="number">1</span>, <span class="number">3</span>), <span class="number">5</span>) \</span><br><span class="line">            .when(F.col(<span class="string">&#x27;r_v&#x27;</span>).between(<span class="number">4</span>, <span class="number">7</span>), <span class="number">4</span>) \</span><br><span class="line">            .when(F.col(<span class="string">&#x27;r_v&#x27;</span>).between(<span class="number">8</span>, <span class="number">15</span>), <span class="number">3</span>) \</span><br><span class="line">            .when(F.col(<span class="string">&#x27;r_v&#x27;</span>).between(<span class="number">16</span>, <span class="number">30</span>), <span class="number">2</span>) \</span><br><span class="line">            .otherwise(<span class="number">1</span>).alias(<span class="string">&#x27;r_s&#x27;</span>)</span><br><span class="line">        f_s = F.when(F.col(<span class="string">&#x27;f_v&#x27;</span>).between(<span class="number">1</span>, <span class="number">500</span>), <span class="number">1</span>) \</span><br><span class="line">            .when(F.col(<span class="string">&#x27;f_v&#x27;</span>).between(<span class="number">500</span>, <span class="number">550</span>), <span class="number">2</span>) \</span><br><span class="line">            .when(F.col(<span class="string">&#x27;f_v&#x27;</span>).between(<span class="number">550</span>, <span class="number">600</span>), <span class="number">3</span>) \</span><br><span class="line">            .when(F.col(<span class="string">&#x27;f_v&#x27;</span>).between(<span class="number">600</span>, <span class="number">700</span>), <span class="number">4</span>) \</span><br><span class="line">            .otherwise(<span class="number">5</span>).alias(<span class="string">&#x27;f_s&#x27;</span>)</span><br><span class="line">        e_s = F.when(F.col(<span class="string">&#x27;e_v&#x27;</span>).between(<span class="number">0</span>, <span class="number">200</span>), <span class="number">1</span>) \</span><br><span class="line">            .when(F.col(<span class="string">&#x27;e_v&#x27;</span>).between(<span class="number">200</span>, <span class="number">251</span>), <span class="number">2</span>) \</span><br><span class="line">            .when(F.col(<span class="string">&#x27;e_v&#x27;</span>).between(<span class="number">251</span>, <span class="number">300</span>), <span class="number">3</span>) \</span><br><span class="line">            .when(F.col(<span class="string">&#x27;e_v&#x27;</span>).between(<span class="number">300</span>, <span class="number">350</span>), <span class="number">4</span>) \</span><br><span class="line">            .otherwise(<span class="number">5</span>).alias(<span class="string">&#x27;e_s&#x27;</span>)</span><br><span class="line">        rfe_s_df = rfe_v_df.select(F.col(<span class="string">&#x27;global_user_id&#x27;</span>).alias(<span class="string">&#x27;userId&#x27;</span>),r_s, f_s, e_s)</span><br><span class="line">        <span class="comment"># rfe_s_df.show()</span></span><br><span class="line">        <span class="comment"># +------+---+---+---+</span></span><br><span class="line">        <span class="comment"># |userId|r_s|f_s|e_s|</span></span><br><span class="line">        <span class="comment"># +------+---+---+---+</span></span><br><span class="line">        <span class="comment"># |   107|  5|  5|  3|</span></span><br><span class="line">        <span class="comment"># |   110|  5|  4|  2|</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3、使用KMeans算法进行聚类(先用vectorassembler 在用KMeans</span></span><br><span class="line">        vector = VectorAssembler(inputCols=[<span class="string">&#x27;r_s&#x27;</span>, <span class="string">&#x27;f_s&#x27;</span>, <span class="string">&#x27;e_s&#x27;</span>],outputCol=<span class="string">&#x27;features&#x27;</span>)</span><br><span class="line">        assembler_df = vector.transform(rfe_s_df)</span><br><span class="line">        <span class="comment"># 3.2 使用KMeans算法进行模型训练</span></span><br><span class="line">        kmeans = KMeans(k=<span class="number">4</span>, featuresCol=<span class="string">&#x27;features&#x27;</span>, predictionCol=<span class="string">&#x27;prediction&#x27;</span>, seed=<span class="number">5</span>)</span><br><span class="line">        <span class="comment"># 创建模型</span></span><br><span class="line">        model = kmeans.fit(assembler_df)</span><br><span class="line">        KMeans_df = model.transform(assembler_df)</span><br><span class="line">        <span class="comment"># 打印进过模型训练的df, 有prediction列</span></span><br><span class="line">        <span class="comment"># KMeans_df.show()</span></span><br><span class="line">        <span class="comment"># +------+---+---+---+-------------+----------+</span></span><br><span class="line">        <span class="comment"># |userId|r_s|f_s|e_s|     features|prediction|</span></span><br><span class="line">        <span class="comment"># +------+---+---+---+-------------+----------+</span></span><br><span class="line">        <span class="comment"># |   107|  5|  5|  3|[5.0,5.0,3.0]|         1|</span></span><br><span class="line">        <span class="comment"># |   110|  5|  4|  2|[5.0,4.0,2.0]|         2|</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4、将聚类结果和5级标签的rule匹配</span></span><br><span class="line">        <span class="comment"># 4.1 首先算出聚类的中心点(查看中心点的得分, 算出得分的总和</span></span><br><span class="line">        <span class="comment"># 注意centers是model中的一个方法, 只有模型才能调用</span></span><br><span class="line">        centers = model.clusterCenters()</span><br><span class="line">        <span class="comment"># 将每组centers放到一个列表中</span></span><br><span class="line">        centers_list = [np.<span class="built_in">sum</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> centers]</span><br><span class="line">        <span class="built_in">print</span>(centers_list)</span><br><span class="line">        <span class="comment"># [12.0, 13.00498338870432, 11.0, 12.0]  -- 这里是一一对应prediction中的0, 1, 2</span></span><br><span class="line">        <span class="comment"># 将列表元素 转为字典中,不改变顺序,因为将center中的值取出来是与prediction中的0, 1,2 对应的</span></span><br><span class="line">        <span class="comment"># (生成的字典为: &#123;&#x27;1&#x27;: list中第一个元素, &#x27;2&#x27;: 第二个.....&#125;</span></span><br><span class="line">        centers_dict = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(centers_list)):</span><br><span class="line">            centers_dict[i] = centers_list[i]</span><br><span class="line">        <span class="comment"># 对字典中的元素进行排序(按照值从大到小的顺序排序</span></span><br><span class="line">        sorted_dict = <span class="built_in">dict</span>(<span class="built_in">sorted</span>(centers_dict.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>))</span><br><span class="line">        <span class="built_in">print</span>(sorted_dict)</span><br><span class="line">        <span class="comment"># &#123;1: 13.00498338870432, 0: 12.0, 3: 12.0, 2: 11.0&#125;</span></span><br><span class="line">        <span class="comment"># 获取五级标签的id( 用户价值高的排在前面</span></span><br><span class="line">        tag5_id_list = tag5_df.rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> row: row.<span class="built_in">id</span>).collect()</span><br><span class="line">        <span class="comment"># 将按照值的大小排过顺序的中心点字典的键为新字典的键, 值为tag5的id(价值高的排前面) 两个进行一一对应, 生成一个新的字典</span></span><br><span class="line">        prediction_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(sorted_dict.keys(), tag5_id_list))</span><br><span class="line">        <span class="built_in">print</span>(prediction_dict)</span><br><span class="line">        <span class="comment"># &#123;1: 46, 0: 47, 3: 48, 2: 49&#125;</span></span><br><span class="line">        <span class="comment"># 5、给用户打上标签</span></span><br><span class="line"><span class="meta">        @F.udf</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">prediction2TagsId</span>(<span class="params">prediction</span>):</span><br><span class="line">            <span class="keyword">return</span> prediction_dict[prediction]</span><br><span class="line"></span><br><span class="line">        result_df = KMeans_df.select(F.col(<span class="string">&#x27;userId&#x27;</span>).cast(StringType()).alias(<span class="string">&#x27;userId&#x27;</span>),</span><br><span class="line">                         prediction2TagsId(F.col(<span class="string">&#x27;prediction&#x27;</span>)).cast(StringType()).alias(<span class="string">&#x27;tagsId&#x27;</span>)</span><br><span class="line">                         )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result_df</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    appName = <span class="string">&#x27;通过KMeans算法计算RFE标签&#x27;</span></span><br><span class="line">    tag4Id = <span class="number">45</span></span><br><span class="line">    <span class="comment"># 创建标签计算对象</span></span><br><span class="line">    tagCpt = TagCptByKmeans(appName, tag4Id)</span><br><span class="line">    tagCpt.execute()</span><br></pre></td></tr></table></figure>



<h1 id="KMeans计算PSM标签"><a href="#KMeans计算PSM标签" class="headerlink" title="KMeans计算PSM标签"></a><font size=6 color='red' face='华文楷体'>KMeans计算PSM标签</font></h1><h2 id="什么是PSM模型"><a href="#什么是PSM模型" class="headerlink" title="什么是PSM模型"></a><font size=5 color='orange' face='华文楷体'>什么是PSM模型</font></h2><blockquote>
<p>PSM模型（Price Sensitivity Measurement），即价格敏感度模型，是当前价格测试模型中的一个常用模型，其特点为所有价格测试过程完全基于被访者的自然反应，没有任何竞争对手甚至自身产品的任何信息。通过该模型，可以得到产品的最优价格和合理的价格间。</p>
</blockquote>
<p>时在实际业务中，会把用户分为3-5类，比如分为<code>极度敏感、较敏感、一般敏感、较不敏感、极度不敏感</code>。</p>
<blockquote>
<p>PSM模型中相关概念名词说明如下：</p>
<p>ra: receivableAmount 应收金额</p>
<p>da: discountAmount 优惠金额</p>
<p>pa: practicalAmount 实收金额</p>
<p>tdon 优惠订单数  total discount order number</p>
<p>ton 总订单总数  total  order number</p>
<p>ada 平均优惠金额 average discount Amount </p>
<p>ara 平均每单应收  average receivable Amount</p>
<p>tda 优惠总金额  total discount Amount </p>
<p>tra 应收总金额 total receivable Amount</p>
<p>tdonr 优惠订单占比(优惠订单数 &#x2F; 订单总数) total discount order number ratio</p>
<p>adar 平均优惠金额占比(平均优惠金额 &#x2F; 平均每单应收金额) average discount amount ratio</p>
<p>tdar 优惠总金额占比(优惠总金额 &#x2F; 订单总金额) total discount amount ratio</p>
<p>psm &#x3D; 优惠订单占比 + 平均优惠金额占比 + 优惠总金额占比</p>
<p>psmScore &#x3D; tdonr + adar + tdar</p>
</blockquote>
<h2 id="标签计算流程"><a href="#标签计算流程" class="headerlink" title="标签计算流程"></a><font size=5 color='orange' face='华文楷体'>标签计算流程</font></h2><blockquote>
<ul>
<li>1、计算 psm 的值</li>
<li>2、使用KMeans算法进行聚类  </li>
<li>3、将聚类结果和5级标签的rule匹配</li>
<li>4、给用户打上标签</li>
</ul>
</blockquote>
<h2 id="标签计算实现"><a href="#标签计算实现" class="headerlink" title="标签计算实现"></a><font size=5 color='orange' face='华文楷体'>标签计算实现</font></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> DataFrame</span><br><span class="line"><span class="keyword">import</span> pyspark.sql.functions <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StringType</span><br><span class="line"><span class="keyword">from</span> UserProfile.offline.base.TagComputeBase <span class="keyword">import</span> TagComputeBase</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.clustering <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TagCptByKmeans</span>(<span class="title class_ inherited__">TagComputeBase</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">tagCompute</span>(<span class="params">self, es_df: DataFrame, tag5_df: DataFrame</span>):</span><br><span class="line">        <span class="comment"># es_df.show()</span></span><br><span class="line">        <span class="comment"># +---------------+--------+-----------+--------------------+</span></span><br><span class="line">        <span class="comment"># |couponcodevalue|memberid|orderamount|             ordersn|</span></span><br><span class="line">        <span class="comment"># +---------------+--------+-----------+--------------------+</span></span><br><span class="line">        <span class="comment"># |            0.0|     342|        1.0|jd_15062716252125282|</span></span><br><span class="line">        <span class="comment"># |            0.0|     405|     3699.0|jd_15062720080896457|</span></span><br><span class="line">        <span class="comment"># |            0.0|     653|     2699.0|jd_15062817103347299|</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># tag5_df.show()</span></span><br><span class="line">        <span class="comment"># +---+----+</span></span><br><span class="line">        <span class="comment"># | id|rule|</span></span><br><span class="line">        <span class="comment"># +---+----+</span></span><br><span class="line">        <span class="comment"># | 51|   1|</span></span><br><span class="line">        <span class="comment"># | 52|   2|</span></span><br><span class="line">        <span class="comment"># | 53|   3|</span></span><br><span class="line">        <span class="comment"># | 54|   4|</span></span><br><span class="line">        <span class="comment"># | 55|   5|</span></span><br><span class="line">        <span class="comment"># +---+----+</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算PSM的值</span></span><br><span class="line">        <span class="comment"># 优惠金额</span></span><br><span class="line">        da = F.col(<span class="string">&#x27;couponcodevalue&#x27;</span>).alias(<span class="string">&#x27;da&#x27;</span>)</span><br><span class="line">        <span class="comment"># 实收金额</span></span><br><span class="line">        pa = F.col(<span class="string">&#x27;orderamount&#x27;</span>).alias(<span class="string">&#x27;pa&#x27;</span>)</span><br><span class="line">        <span class="comment"># 应收金额</span></span><br><span class="line">        ra = da + pa</span><br><span class="line"></span><br><span class="line">        rdp_df = es_df.select(da, pa, ra.alias(<span class="string">&#x27;ra&#x27;</span>), F.col(<span class="string">&#x27;ordersn&#x27;</span>), F.col(<span class="string">&#x27;memberid&#x27;</span>).alias(<span class="string">&#x27;userId&#x27;</span>))</span><br><span class="line">        <span class="comment"># rdp_df.show()</span></span><br><span class="line">        <span class="comment"># +---+-------+-------+--------------------+------+</span></span><br><span class="line">        <span class="comment"># | da|     pa|     ra|             ordersn|userId|</span></span><br><span class="line">        <span class="comment"># +---+-------+-------+--------------------+------+</span></span><br><span class="line">        <span class="comment"># |0.0|    1.0|    1.0|jd_15062716252125282|   342|</span></span><br><span class="line">        <span class="comment"># |0.0| 3699.0| 3699.0|jd_15062720080896457|   405|</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 优惠订单数</span></span><br><span class="line">        tdon = F.<span class="built_in">sum</span>(F.when(F.col(<span class="string">&#x27;da&#x27;</span>) == <span class="number">0</span>, <span class="number">0</span>).otherwise(<span class="number">1</span>)).alias(<span class="string">&#x27;tdon&#x27;</span>)</span><br><span class="line">        <span class="comment"># 总订单数</span></span><br><span class="line">        ton = F.count(F.col(<span class="string">&#x27;ordersn&#x27;</span>)).alias(<span class="string">&#x27;ton&#x27;</span>)</span><br><span class="line">        <span class="comment"># 平均优惠金额</span></span><br><span class="line">        ada = F.avg(F.col(<span class="string">&#x27;da&#x27;</span>)).alias(<span class="string">&#x27;ada&#x27;</span>)</span><br><span class="line">        <span class="comment"># 优惠总金额</span></span><br><span class="line">        tda = F.<span class="built_in">sum</span>(F.col(<span class="string">&#x27;da&#x27;</span>)).alias(<span class="string">&#x27;tda&#x27;</span>)</span><br><span class="line">        <span class="comment"># 每单平均应收</span></span><br><span class="line">        ara = F.avg(F.col(<span class="string">&#x27;ra&#x27;</span>)).alias(<span class="string">&#x27;ara&#x27;</span>)</span><br><span class="line">        <span class="comment"># 应收总金额</span></span><br><span class="line">        tra = F.<span class="built_in">sum</span>(F.col(<span class="string">&#x27;ra&#x27;</span>)).alias(<span class="string">&#x27;tra&#x27;</span>)</span><br><span class="line">        rdp_agg_df = rdp_df.groupby(<span class="string">&#x27;userId&#x27;</span>).agg(tdon, ton, ada, tda, ara, tra)</span><br><span class="line">        <span class="comment"># rdp_agg_df.show()</span></span><br><span class="line">        <span class="comment"># +------+----+---+-------------------+------+------------------+------------------+</span></span><br><span class="line">        <span class="comment"># |userId|tdon|ton|                ada|   tda|               ara|               tra|</span></span><br><span class="line">        <span class="comment"># +------+----+---+-------------------+------+------------------+------------------+</span></span><br><span class="line">        <span class="comment"># |   898|   4|129|  5.426356589147287| 700.0|1822.9205431087996|235156.75006103516|</span></span><br><span class="line">        <span class="comment"># |    29|  10|246|  7.723577235772358|1900.0| 1648.066057530845| 405424.2501525879|</span></span><br><span class="line">        <span class="comment"># 用户敏感度 = 优惠订单占比 + 平均优惠金额占比 + 优惠总金额占比</span></span><br><span class="line">        <span class="comment"># 优惠订单占比（优惠订单数/订单总数）</span></span><br><span class="line">        tdonr = (F.col(<span class="string">&#x27;tdon&#x27;</span>) / F.col(<span class="string">&#x27;ton&#x27;</span>)).alias(<span class="string">&#x27;tdonr&#x27;</span>)</span><br><span class="line">        <span class="comment"># 平均优惠金额占比（平均优惠金额/平均每单应收金额）</span></span><br><span class="line">        adar = (F.col(<span class="string">&#x27;ada&#x27;</span>) / F.col(<span class="string">&#x27;ara&#x27;</span>)).alias(<span class="string">&#x27;adar&#x27;</span>)</span><br><span class="line">        <span class="comment"># 优惠总金额占比（优惠总金额/订单总金额）</span></span><br><span class="line">        tdar = (F.col(<span class="string">&#x27;tda&#x27;</span>) / F.col(<span class="string">&#x27;tra&#x27;</span>)).alias(<span class="string">&#x27;tdar&#x27;</span>)</span><br><span class="line">        psm_df = rdp_agg_df.select(<span class="string">&#x27;userId&#x27;</span>, (tdonr + adar + tdar).alias(<span class="string">&#x27;psm&#x27;</span>))</span><br><span class="line">        <span class="comment"># psm_df.show()</span></span><br><span class="line">        <span class="comment"># +------+--------------------+</span></span><br><span class="line">        <span class="comment"># |userId|                 psm|</span></span><br><span class="line">        <span class="comment"># +------+--------------------+</span></span><br><span class="line">        <span class="comment"># |   898| 0.03696122764997928|</span></span><br><span class="line">        <span class="comment"># |    29| 0.05002330415034498|</span></span><br><span class="line">        <span class="comment"># |    92|0.004834992278551832|</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 使用KMeans算法进行聚类</span></span><br><span class="line">        <span class="comment"># 特征筛选</span></span><br><span class="line">        assembler = VectorAssembler(inputCols=[<span class="string">&#x27;psm&#x27;</span>], outputCol=<span class="string">&#x27;features&#x27;</span>)</span><br><span class="line">        psm_vector_df = assembler.transform(psm_df)</span><br><span class="line">        <span class="comment"># KMeans对psm进行聚类, 并求中心点的分值, 分值越高越代表对价格的敏感度越高</span></span><br><span class="line">        kmeans = KMeans(k=<span class="number">5</span>, featuresCol=<span class="string">&#x27;features&#x27;</span>, predictionCol=<span class="string">&#x27;prediction&#x27;</span>, seed=<span class="number">5</span>)</span><br><span class="line">        <span class="comment"># 创建KMeans模型</span></span><br><span class="line">        model = kmeans.fit(psm_vector_df)</span><br><span class="line">        <span class="comment"># 进行计算</span></span><br><span class="line">        result_df = model.transform(psm_vector_df)</span><br><span class="line">        <span class="comment"># result_df.show()</span></span><br><span class="line">        <span class="comment"># +------+--------------------+--------------------+----------+</span></span><br><span class="line">        <span class="comment"># |userId|                 psm|            features|prediction|</span></span><br><span class="line">        <span class="comment"># +------+--------------------+--------------------+----------+</span></span><br><span class="line">        <span class="comment"># |   898| 0.03696122764997928|[0.03696122764997...|         2|</span></span><br><span class="line">        <span class="comment"># |    29| 0.05002330415034498|[0.05002330415034...|         3|</span></span><br><span class="line">        <span class="comment"># |    92|0.004834992278551832|[0.00483499227855...|         1|</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将聚类的值和五级标签的rule匹配</span></span><br><span class="line">        <span class="comment"># 获取聚类中心点的值(必须通过model.clusterCenters调用, 获取一个列表嵌套多个array, array中的是簇的每个点的值</span></span><br><span class="line">        centers = model.clusterCenters()</span><br><span class="line">        centers_list = [np.<span class="built_in">sum</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> centers]</span><br><span class="line">        <span class="built_in">print</span>(centers_list)</span><br><span class="line">        <span class="comment"># 为了不改变prediction中的顺序, 将列表中的元素整合成一个字典</span></span><br><span class="line">        centers_dict = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(centers_list)):</span><br><span class="line">            centers_dict[i] = centers_list[i]</span><br><span class="line">        <span class="comment"># 按照字典中的值对字典进行降序排序(后面的标签id也是敏感度高的在最上面</span></span><br><span class="line">        sorted_dict = <span class="built_in">dict</span>(<span class="built_in">sorted</span>(centers_dict.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>))</span><br><span class="line">        <span class="built_in">print</span>(sorted_dict)</span><br><span class="line">        <span class="comment"># 取出五级标签的id</span></span><br><span class="line">        tag5_ids_list = tag5_df.rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> row: row.<span class="built_in">id</span>).collect()</span><br><span class="line">        <span class="built_in">print</span>(tag5_ids_list)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将五级标签的id和字典中的值一一对应的连接起来(通过zip函数形成新的字典</span></span><br><span class="line">        tags_to_centers_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(sorted_dict.keys(), tag5_ids_list))</span><br><span class="line">        <span class="built_in">print</span>(tags_to_centers_dict)</span><br><span class="line"></span><br><span class="line"><span class="meta">        @F.udf</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">prediction2Id</span>(<span class="params">prediction</span>):</span><br><span class="line">            <span class="keyword">return</span> tags_to_centers_dict[prediction]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 挑选字段, 并返回最终的df</span></span><br><span class="line">        final_df = result_df.select(F.col(<span class="string">&#x27;userId&#x27;</span>).cast(StringType()).alias(<span class="string">&#x27;userId&#x27;</span>),</span><br><span class="line">                                    prediction2Id(F.col(<span class="string">&#x27;prediction&#x27;</span>)).cast(StringType()).alias(<span class="string">&#x27;tagsId&#x27;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># final_df.show()</span></span><br><span class="line">        <span class="comment"># +------+------+</span></span><br><span class="line">        <span class="comment"># |userId|tagsId|</span></span><br><span class="line">        <span class="comment"># +------+------+</span></span><br><span class="line">        <span class="comment"># |   898|    53|</span></span><br><span class="line">        <span class="comment"># |    29|    52|</span></span><br><span class="line">        <span class="comment"># |    92|    55|</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> final_df</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    appName = <span class="string">&#x27;通过kmeans算法计算PSM标签&#x27;</span></span><br><span class="line">    tag4Id = <span class="number">50</span></span><br><span class="line">    <span class="comment"># 创建标签计算对象</span></span><br><span class="line">    tagCpt = TagCptByKmeans(appName, tag4Id)</span><br><span class="line">    tagCpt.execute()</span><br></pre></td></tr></table></figure>

</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="https://liamjohnson-w.github.io">Jason</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://liamjohnson-w.github.io/2023/08/08/2023.08.08/">https://liamjohnson-w.github.io/2023/08/08/2023.08.08/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Spark%E9%A1%B9%E7%9B%AE/">Spark项目</a></div><div class="post_share"><div class="social-share" data-image="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/tx.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> Donate</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/08/09/2023.08.09/" title="【用户画像(八)】机器学习有监督学习通过决策树算法计算用户性别标签"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">【用户画像(八)】机器学习有监督学习通过决策树算法计算用户性别标签</div></div></a></div><div class="next-post pull-right"><a href="/2023/08/07/2023.08.07/" title="【用户画像(六)】Spark机器学习"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">【用户画像(六)】Spark机器学习</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2023/08/02/2023.08.02/" title="【用户画像(二)】Python操作ES(支持sql)及ES整合Hive,Spark,MySQL"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-02</div><div class="title">【用户画像(二)】Python操作ES(支持sql)及ES整合Hive,Spark,MySQL</div></div></a></div><div><a href="/2023/08/04/2023.08.04/" title="【用户画像(三)】匹配类标签计算(年龄,性别,职位)-附计算流程"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-04</div><div class="title">【用户画像(三)】匹配类标签计算(年龄,性别,职位)-附计算流程</div></div></a></div><div><a href="/2023/08/01/2023.08.01/" title="【用户画像(一)】技术选型及ElasticSearch与后台启动命令"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-01</div><div class="title">【用户画像(一)】技术选型及ElasticSearch与后台启动命令</div></div></a></div><div><a href="/2023/08/05/2023.08.05/" title="【用户画像(四)】封装基类分析类标签计算(销售额,支付方式)"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-05</div><div class="title">【用户画像(四)】封装基类分析类标签计算(销售额,支付方式)</div></div></a></div><div><a href="/2023/08/06/2023.08.06/" title="【用户画像(五)】挖掘类客户价值标签(RFM模型)"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-06</div><div class="title">【用户画像(五)】挖掘类客户价值标签(RFM模型)</div></div></a></div><div><a href="/2023/08/07/2023.08.07/" title="【用户画像(六)】Spark机器学习"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-07</div><div class="title">【用户画像(六)】Spark机器学习</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/tx.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Jason</div><div class="author-info__description">机器都在学习,你有什么理由不学习?</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">232</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">58</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/weiswift/"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/weiswift" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:1265019024@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">网站由Github服务器托管,感谢支持！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98KMeans%E7%AE%97%E6%B3%95"><span class="toc-number">1.</span> <span class="toc-text">数据挖掘KMeans算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#KMeans%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.1.</span> <span class="toc-text">KMeans介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6"><span class="toc-number">1.2.</span> <span class="toc-text">余弦相似度</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6"><span class="toc-number">1.2.1.</span> <span class="toc-text">什么是余弦相似度</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KMeans%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86"><span class="toc-number">1.3.</span> <span class="toc-text">KMeans算法原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KMeans%E7%AE%97%E6%B3%95%E7%89%B9%E7%82%B9"><span class="toc-number">1.4.</span> <span class="toc-text">KMeans算法特点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KMeans%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0"><span class="toc-number">1.5.</span> <span class="toc-text">KMeans模型评估</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KMeans%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.6.</span> <span class="toc-text">KMeans模型实现</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#KMeans%E8%AE%A1%E7%AE%97RFM%E6%A0%87%E7%AD%BE"><span class="toc-number">2.</span> <span class="toc-text">KMeans计算RFM标签</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFRFM%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.1.</span> <span class="toc-text">什么是RFM模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RFM%E6%A0%87%E7%AD%BE%E8%AE%A1%E7%AE%97%E6%B5%81%E7%A8%8B"><span class="toc-number">2.2.</span> <span class="toc-text">RFM标签计算流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RFM%E6%A0%87%E7%AD%BE%E8%AE%A1%E7%AE%97%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.3.</span> <span class="toc-text">RFM标签计算实现</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#KMeans%E8%AE%A1%E7%AE%97RFE%E6%A0%87%E7%AD%BE"><span class="toc-number">3.</span> <span class="toc-text">KMeans计算RFE标签</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFRFE%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.1.</span> <span class="toc-text">什么是RFE模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RFE%E6%A0%87%E7%AD%BE%E8%AE%A1%E7%AE%97%E6%B5%81%E7%A8%8B"><span class="toc-number">3.2.</span> <span class="toc-text">RFE标签计算流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RFE%E6%A0%87%E7%AD%BE%E8%AE%A1%E7%AE%97%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.3.</span> <span class="toc-text">RFE标签计算实现</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#KMeans%E8%AE%A1%E7%AE%97PSM%E6%A0%87%E7%AD%BE"><span class="toc-number">4.</span> <span class="toc-text">KMeans计算PSM标签</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFPSM%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.1.</span> <span class="toc-text">什么是PSM模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%87%E7%AD%BE%E8%AE%A1%E7%AE%97%E6%B5%81%E7%A8%8B"><span class="toc-number">4.2.</span> <span class="toc-text">标签计算流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%87%E7%AD%BE%E8%AE%A1%E7%AE%97%E5%AE%9E%E7%8E%B0"><span class="toc-number">4.3.</span> <span class="toc-text">标签计算实现</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/07/18/Project/" title="Jason Project Demo"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/pusheen1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Jason Project Demo"/></a><div class="content"><a class="title" href="/2025/07/18/Project/" title="Jason Project Demo">Jason Project Demo</a><time datetime="2025-07-17T16:00:00.000Z" title="Created 2025-07-18 00:00:00">2025-07-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/07/16/%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/" title="算法公式推导"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/pusheen2.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="算法公式推导"/></a><div class="content"><a class="title" href="/2025/07/16/%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/" title="算法公式推导">算法公式推导</a><time datetime="2025-07-15T16:00:00.000Z" title="Created 2025-07-16 00:00:00">2025-07-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/29/InterviewQuestions/" title="Jason Interview Note"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/pusheen121.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Jason Interview Note"/></a><div class="content"><a class="title" href="/2025/06/29/InterviewQuestions/" title="Jason Interview Note">Jason Interview Note</a><time datetime="2025-06-28T16:00:00.000Z" title="Created 2025-06-29 00:00:00">2025-06-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/22/DK67/" title="DK67双模切换"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/%E7%94%9F%E6%88%90%E7%8C%AB%E5%92%AA%E5%9B%BE%E7%89%87.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="DK67双模切换"/></a><div class="content"><a class="title" href="/2025/06/22/DK67/" title="DK67双模切换">DK67双模切换</a><time datetime="2025-06-21T16:00:00.000Z" title="Created 2025-06-22 00:00:00">2025-06-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/22/NLP_Base/" title="NLP自然语言处理"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/%E7%94%9F%E6%88%90%E7%8C%AB%E5%92%AA%E5%9B%BE%E7%89%87%20(2).png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="NLP自然语言处理"/></a><div class="content"><a class="title" href="/2025/06/22/NLP_Base/" title="NLP自然语言处理">NLP自然语言处理</a><time datetime="2025-06-21T16:00:00.000Z" title="Created 2025-06-22 00:00:00">2025-06-22</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Jason</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Welcome to Jason の <a target="_blank" rel="noopener" href="https://www.cnblogs.com/liam-sliversucks/">Blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? '' : ''

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div><canvas class="fireworks" mobile="true"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="true"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>