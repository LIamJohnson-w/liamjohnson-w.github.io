<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>【Flink】Flink算子及分区概念 | SilverSucks</title><meta name="author" content="Johnson Liam"><meta name="copyright" content="Johnson Liam"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="粥所周知, Flink程序由四部分构成, 运行环境 + Source + Transformation + Sink. 接下来一个个说.  运行环境批处理 获取批处理执行环境（用于测试&amp;#x2F;生产）   1ExecutionEnvironment env &amp;#x3D; ExecutionEnvironm"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://github.com/weiswift/2023/09/07/2023.09.07/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '【Flink】Flink算子及分区概念',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-09-10 20:33:56'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"> <script src="/live2d-widget/autoload.js"></script><script src="/live2d-widget/autoload.js"> </script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/img/pic.webp" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">222</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">58</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Links</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-gamepad"></i><span> Games</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/mikutap/"><i class="fa-fw fa fa-music"></i><span> MikuTap 初音未来</span></a></li><li><a class="site-page child" href="/starbattle/"><i class="fa-fw fa fa-space-shuttle"></i><span> StartBattle 星际大战</span></a></li><li><a class="site-page child" href="/2048/"><i class="fa-fw fa fa-flag"></i><span> 2048 经典游戏</span></a></li><li><a class="site-page child" href="/battlecity/"><i class="fa-fw fa fa-arrow-circle-left"></i><span> BattleCity 坦克大战</span></a></li><li><a class="site-page child" href="/pacman/"><i class="fa-fw fa fa-bolt"></i><span> PacMan  吃豆人</span></a></li><li><a class="site-page child" href="/tetris/"><i class="fa-fw fa fa-arrows-alt"></i><span> Tetris 俄罗斯方块</span></a></li><li><a class="site-page child" href="/smallcat/"><i class="fa-fw fa fa-paw"></i><span> CatchCat 困住小猫</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-leaf"></i><span> Moments</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/diary/"><i class="fa-fw fas fa-bookmark"></i><span> Diary</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fa fa-hourglass-half"></i><span> Gallery</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-podcast"></i><span> More</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags标签</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About关于</span></a></li><li><a class="site-page child" href="/messageboard/"><i class="fa-fw fas fa-bookmark"></i><span> Messageboard留言板</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s1.ax1x.com/2023/04/18/p9i6u5D.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="SilverSucks"><span class="site-name">SilverSucks</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Links</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-gamepad"></i><span> Games</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/mikutap/"><i class="fa-fw fa fa-music"></i><span> MikuTap 初音未来</span></a></li><li><a class="site-page child" href="/starbattle/"><i class="fa-fw fa fa-space-shuttle"></i><span> StartBattle 星际大战</span></a></li><li><a class="site-page child" href="/2048/"><i class="fa-fw fa fa-flag"></i><span> 2048 经典游戏</span></a></li><li><a class="site-page child" href="/battlecity/"><i class="fa-fw fa fa-arrow-circle-left"></i><span> BattleCity 坦克大战</span></a></li><li><a class="site-page child" href="/pacman/"><i class="fa-fw fa fa-bolt"></i><span> PacMan  吃豆人</span></a></li><li><a class="site-page child" href="/tetris/"><i class="fa-fw fa fa-arrows-alt"></i><span> Tetris 俄罗斯方块</span></a></li><li><a class="site-page child" href="/smallcat/"><i class="fa-fw fa fa-paw"></i><span> CatchCat 困住小猫</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-leaf"></i><span> Moments</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/diary/"><i class="fa-fw fas fa-bookmark"></i><span> Diary</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fa fa-hourglass-half"></i><span> Gallery</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-podcast"></i><span> More</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags标签</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About关于</span></a></li><li><a class="site-page child" href="/messageboard/"><i class="fa-fw fas fa-bookmark"></i><span> Messageboard留言板</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">【Flink】Flink算子及分区概念</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-09-06T16:00:00.000Z" title="Created 2023-09-07 00:00:00">2023-09-07</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-09-10T12:33:56.000Z" title="Updated 2023-09-10 20:33:56">2023-09-10</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="【Flink】Flink算子及分区概念"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote>
<p>粥所周知, Flink程序由四部分构成, 运行环境 + Source + Transformation + Sink.</p>
<p>接下来一个个说.</p>
</blockquote>
<h1 id="运行环境"><a href="#运行环境" class="headerlink" title="运行环境"></a>运行环境</h1><h2 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h2><ul>
<li><p>获取批处理执行环境（用于测试&#x2F;生产）</p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">ExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> ExecutionEnvironment.getExecutionEnvironment();</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="流处理"><a href="#流处理" class="headerlink" title="流处理"></a>流处理</h2><ul>
<li><p>获取流式处理执行环境（用于测试&#x2F;生产）</p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="流批一体"><a href="#流批一体" class="headerlink" title="流批一体"></a>流批一体</h2><ul>
<li><p>获取流批一体处理执行环境（用于测试&#x2F;生产）</p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"><span class="comment">// 设置为批处理模式</span></span><br><span class="line">env.setRuntimeMode(ExecutionMode.BATCH);</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="本地环境"><a href="#本地环境" class="headerlink" title="本地环境"></a>本地环境</h2><ul>
<li><p>创建本地执行环境（用于测试）</p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.createLocalEnvironment();</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="带有WebUI的本地环境"><a href="#带有WebUI的本地环境" class="headerlink" title="带有WebUI的本地环境"></a>带有WebUI的本地环境</h2><ul>
<li><p>创建带有webui的本地执行环境（用于测试）</p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">conf.setInteger(<span class="string">&quot;rest.port&quot;</span>,<span class="number">8081</span>);</span><br><span class="line"><span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.createLocalEnvironmentWithWebUI(conf);</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="执行模式"><a href="#执行模式" class="headerlink" title="执行模式"></a>执行模式</h1><blockquote>
<p>从Flink1.12.0版本起，Flink实现了API上的流批统一。DataStreamAPI新增了一个重要特性可以支持不同的执行模式，通过简单的设置就可以让一段Flink程序在流处理和批处理之间切换。这样一来，DataSet API也就没有存在的必要了。<br>执行模式的分类：</p>
<ul>
<li>流执行（STREAMING）模式。<br>  STREAMING模式是DataStream API最经典的模式，一般用于需要持续实时处理的无界数据流。在默认情况下，程序使用的就是STREAMING模式。</li>
<li>批执行（BATCH）模式。<br>  BATCH模式是专门用于批处理的执行模式，在这种模式下，Flink处理作业的方式类似于MapReduce框架。对于不会持续计算的有界数据，用这种模式处理会更方便。</li>
<li>自动（AUTOMATIC）模式。<br>  在AUTOMATIC模式下，将由程序根据输入数据源是否有界来自动选择执行模式。</li>
</ul>
</blockquote>
<h2 id="执行模式的配置方法"><a href="#执行模式的配置方法" class="headerlink" title="执行模式的配置方法"></a>执行模式的配置方法</h2><p>（以BATCH为例，默认是STREAMING模式）：</p>
<blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">通过命令行配置（在提交作业时，增加execution.runtime-mode参数，进行指定）</span></span><br><span class="line">bin/flink run -Dexecution.runtime-mode=BATCH ...</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 通过代码配置（在代码中调用setRuntimeMode方法指定）</span></span><br><span class="line"><span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment ();</span><br><span class="line">env.setRuntimeMode(RuntimeExecutionMode.BATCH);</span><br></pre></td></tr></table></figure>


</blockquote>
<blockquote>
<p><code>建议：不要在代码中配置，而是使用命令行。这同设置并行度是类似的在提交作业时指定参数可以更加灵活，同一段应用在程序写好之后，既可以用于批处理，又可以用于流处理而在代码中进行硬编码的方式的可扩展性比较差，一般都不推荐。</code></p>
</blockquote>
<h1 id="输入算子Source"><a href="#输入算子Source" class="headerlink" title="输入算子Source"></a>输入算子Source</h1><h2 id="输入算子总结Summary"><a href="#输入算子总结Summary" class="headerlink" title="输入算子总结Summary"></a>输入算子总结Summary</h2><blockquote>
<p>单并行算子如果显式设置&gt;1的并行度，会抛异常</p>
</blockquote>
<ul>
<li>使用<code>env.fromElements()</code>，这种方式也支持Tuple，自定义对象等复合形式<ul>
<li>DataStreamSource &lt;String&gt; words &#x3D; env.fromElements(“flink”, “hadoop”, “flink”);</li>
</ul>
</li>
<li>使用<code>env.fromCollection()</code>,这种方式支持多种Collection的具体类型，如List，Set，Queue<ul>
<li>非并行的Source(是一个单并行度的source算子)，可以将一个Collection作为参数传入到该方法中，返回一个DataStreamSource。<ul>
<li>List &lt;String&gt; dataList &#x3D; Arrays.asList(“a”, “b”, “a”, “c”);</li>
</ul>
</li>
</ul>
</li>
<li>使用<code>env.fromParallelCollection</code>所返回的source算子，是一个多并行度的source算子</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataStreamSource&lt;LongValue&gt; parallelCollection = env.fromParallelCollection(<span class="keyword">new</span> <span class="title class_">LongValueSequenceIterator</span>(<span class="number">1</span>, <span class="number">100</span>), TypeInformation.of(LongValue.class)).setParallelism(<span class="number">2</span>);</span><br></pre></td></tr></table></figure>

<ul>
<li><p>使用<code>env.generateSequence()</code>方法创建基于Sequence的DataStream</p>
<ul>
<li>并行的Source（并行度也可以通过调用该方法后，再调用setParallelism来设置）通过指定的起始值和结束值来生成数据序列流；<ul>
<li>DataStreamSource &lt;Long&gt; sequence &#x3D; env.generateSequence(1, 100);</li>
</ul>
</li>
</ul>
</li>
<li><p>使用<code>env.fromSequence()</code>方法创建基于开始和结束的DataStream</p>
<ul>
<li>final DataStreamSource<Long> sequence2 &#x3D; env.fromSequence(1L, 5L);</li>
</ul>
</li>
</ul>
<h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 使用env.fromElements()，这种方式也支持Tuple，自定义对象等复合形式</span></span><br><span class="line">DataStreamSource&lt;String&gt; words = env.fromElements(<span class="string">&quot;flink&quot;</span>, <span class="string">&quot;hadoop&quot;</span>, <span class="string">&quot;flink&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用env.fromCollection(),这种方式支持多种Collection的具体类型，如List，Set，Queue</span></span><br><span class="line"><span class="comment">// 非并行的Source，可以将一个Collection作为参数传入到该方法中，返回一个DataStreamSource。</span></span><br><span class="line">List&lt;String&gt; dataList = Arrays.asList(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;a&quot;</span>, <span class="string">&quot;c&quot;</span>);</span><br><span class="line"><span class="comment">// fromCollection方法所返回的source算子，是一个单并行度的source算子</span></span><br><span class="line">DataStreamSource&lt;String&gt; fromCollection = env.fromCollection(dataList)<span class="comment">/*.setParallelism(5)*/</span>;  <span class="comment">// 单并行算子如果显式设置&gt;1的并行度，会抛异常</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// fromParallelCollection所返回的source算子，是一个多并行度的source算子</span></span><br><span class="line">DataStreamSource&lt;LongValue&gt; parallelCollection = env.fromParallelCollection(<span class="keyword">new</span> <span class="title class_">LongValueSequenceIterator</span>(<span class="number">1</span>, <span class="number">100</span>), TypeInformation.of(LongValue.class)).setParallelism(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用env.generateSequence()方法创建基于Sequence的DataStream</span></span><br><span class="line"><span class="comment">// 并行的Source（并行度也可以通过调用该方法后，再调用setParallelism来设置）通过指定的起始值和结束值来生成数据序列流；</span></span><br><span class="line">DataStreamSource&lt;Long&gt; sequence = env.generateSequence(<span class="number">1</span>, <span class="number">100</span>);</span><br><span class="line">sequence.map(x -&gt; x - <span class="number">1</span>)<span class="comment">/*.print()*/</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用env.fromSequence()方法创建基于开始和结束的DataStream</span></span><br><span class="line"><span class="keyword">final</span> DataStreamSource&lt;Long&gt; sequence2 = env.fromSequence(<span class="number">1L</span>, <span class="number">5L</span>);</span><br><span class="line">sequence2.map(x -&gt; x - <span class="number">1</span>)<span class="comment">/*.print()*/</span>;</span><br></pre></td></tr></table></figure>

<h2 id="基于集合的Source"><a href="#基于集合的Source" class="headerlink" title="基于集合的Source"></a>基于集合的Source</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.github.sourceOperator;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.MapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CollectionSource</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">// 1, 创建带有WebUi的运行环境</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        conf.setInteger(<span class="string">&quot;rest.port&quot;</span>, <span class="number">8081</span>);</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.createLocalEnvironmentWithWebUI(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2, 构建source算子从集合中获取数据</span></span><br><span class="line">        List&lt;String&gt; list = Arrays.asList(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>, <span class="string">&quot;d&quot;</span>);</span><br><span class="line">        <span class="comment">// 创建单并行度集合数据源</span></span><br><span class="line">        DataStreamSource&lt;String&gt; listDS = env.fromCollection(list);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3, 处理数据 - 将每个单词都转为大写</span></span><br><span class="line">        listDS.map((MapFunction&lt;String, String&gt;) value -&gt; value.toUpperCase()).print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4, 提交执行</span></span><br><span class="line">        env.execute();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="基于Socket的Source"><a href="#基于Socket的Source" class="headerlink" title="基于Socket的Source"></a>基于Socket的Source</h2><blockquote>
<p>非并行的Source，DataStream API 支持从 Socket 套接字读取数据。只需要指定要从其中读取数据的主机和端口号即可。读取 Socket 套接字的数据源函数定义如下：</p>
<ul>
<li>socketTextStream(hostName, port)</li>
<li>socketTextStream(hostName, port, delimiter)：可指定分隔符，默认行分隔符是”\n”</li>
<li>socketTextStream(hostName, port, delimiter, maxRetry)：还可以指定 API 应该尝试获取数据的最大次数，默认最大重新连接次数为0。</li>
</ul>
</blockquote>
<h2 id="基于文件的Source"><a href="#基于文件的Source" class="headerlink" title="基于文件的Source"></a>基于文件的Source</h2><blockquote>
<p>基于文件的Source，本质上就是使用指定的FileInputFormat组件读取数据，可以指定TextInputFormat、CsvInputFormat、BinaryInputFormat等格式；底层都是ContinuousFileMonitoringFunction，这个类继承了RichSourceFunction，都是非并行的Source；</p>
<ul>
<li>readFile(FileInputFormat inputFormat, String filePath) 方法可以指定读取文件的FileInputFormat 格式，参数FileProcessingMode，可取值：<ul>
<li>PROCESS_ONCE，只读取文件中的数据一次，读取完成后，程序退出</li>
<li>PROCESS_CONTINUOUSLY，会一直监听指定的文件，文件的内容发生变化后，会将以前的内容和新的内容全部都读取出来，进而造成数据重复读取。</li>
</ul>
</li>
<li>readTextFile(String filePath) 可以从指定的目录或文件读取数据，默认使用的是TextInputFormat格式读取数据，还有一个重载的方法readTextFile(String filePath, String charsetName)可以传入读取文件指定的字符集，默认是UTF-8编码。该方法是一个有限的数据源，数据读完后，程序就会退出，不能一直运行。该方法底层调用的是readFile方法，FileProcessingMode为PROCESS_ONCE</li>
<li>readFile(fileInputFormat, path, watchType, interval, pathFilter, typeInfo) - 这是前两个方法内部调用的方法。它基于给定的 fileInputFormat 读取路径 path 上的文件。根据提供的 watchType 的不同，source 可能定期（每 interval 毫秒）监控路径上的新数据（watchType 为 FileProcessingMode.PROCESS_CONTINUOUSLY），或者处理一次当前路径中的数据然后退出（watchType 为 FileProcessingMode.PROCESS_ONCE)。使用 pathFilter，用户可以进一步排除正在处理的文件。</li>
</ul>
</blockquote>
<h2 id="第三方-Source-Kafka举例"><a href="#第三方-Source-Kafka举例" class="headerlink" title="第三方 Source(Kafka举例)"></a>第三方 Source(Kafka举例)</h2><blockquote>
<p>在实际生产环境中，为了保证flink可以高效地读取数据源中的数据，通常是跟一些分布式消息中件结合使用，例如Apache Kafka。Kafka的特点是分布式、多副本、高可用、高吞吐、可以记录偏移量等。Flink和Kafka整合可以高效的读取数据，并且可以保证Exactly Once（精确一次性语义）。</p>
<ul>
<li>添加依赖</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>Kafka Source 提供了构建类来创建 KafkaSource 的实例。构建 KafkaSource 来消费 “input-topic” 最早位点的数据， 使用消费组 “my-group”，并且将 Kafka 消息体反序列化为字符串：</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">KafkaSource&lt;String&gt; source = KafkaSource.&lt;String&gt;builder()</span><br><span class="line">   .setBootstrapServers(brokers)</span><br><span class="line">   .setTopics(<span class="string">&quot;input-topic&quot;</span>)</span><br><span class="line">   .setGroupId(<span class="string">&quot;my-group&quot;</span>)</span><br><span class="line">   .setStartingOffsets(OffsetsInitializer.earliest())</span><br><span class="line">   .setValueOnlyDeserializer(<span class="keyword">new</span> <span class="title class_">SimpleStringSchema</span>())</span><br><span class="line">   .build();</span><br><span class="line"></span><br><span class="line">env.fromSource(source, WatermarkStrategy.noWatermarks(), <span class="string">&quot;Kafka Source&quot;</span>);</span><br></pre></td></tr></table></figure>

<ul>
<li>以下属性在构建 KafkaSource 时是必须指定的：</li>
<li>Bootstrap server，通过 setBootstrapServers(String) 方法配置</li>
<li>消费者组 ID，通过 setGroupId(String) 配置</li>
<li>要订阅的 Topic &#x2F; Partition，</li>
<li>用于解析 Kafka 消息的反序列化器（Deserializer）</li>
<li>Topic &#x2F; Partition订阅</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Topic 列表，订阅 Topic 列表中所有 Partition 的消息：</span></span><br><span class="line">KafkaSource.builder().setTopics(<span class="string">&quot;topic-a&quot;</span>, <span class="string">&quot;topic-b&quot;</span>);</span><br><span class="line"><span class="comment">// 正则表达式匹配，订阅与正则表达式所匹配的 Topic 下的所有 Partition：</span></span><br><span class="line">KafkaSource.builder().setTopicPattern(<span class="string">&quot;topic.*&quot;</span>);</span><br><span class="line"><span class="comment">// Partition 列表，订阅指定的 Partition：</span></span><br><span class="line"><span class="keyword">final</span> HashSet&lt;TopicPartition&gt; partitionSet = <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;(Arrays.asList(</span><br><span class="line">   <span class="keyword">new</span> <span class="title class_">TopicPartition</span>(<span class="string">&quot;topic-a&quot;</span>, <span class="number">0</span>),    <span class="comment">// Partition 0 of topic &quot;topic-a&quot;</span></span><br><span class="line">   <span class="keyword">new</span> <span class="title class_">TopicPartition</span>(<span class="string">&quot;topic-b&quot;</span>, <span class="number">5</span>)));  <span class="comment">// Partition 5 of topic &quot;topic-b&quot;</span></span><br><span class="line">KafkaSource.builder().setPartitions(partitionSet);</span><br></pre></td></tr></table></figure>

<ul>
<li>消费解析</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 代码中需要提供一个反序列化器（Deserializer）来对Kafka的消息进行解析。 反序列化器通过setDeserializer(KafkaRecordDeserializationSchema)来指定，其中 KafkaRecordDeserializationSchema 定义了如何解析Kafka的ConsumerRecord。</span></span><br><span class="line"><span class="comment">// 如果只需要 Kafka 消息中的消息体（value）部分的数据，可以使用 KafkaSource 构建类中的 setValueOnlyDeserializer(DeserializationSchema) 方法，其中 DeserializationSchema 定义了如何解析 Kafka 消息体中的二进制数据。</span></span><br><span class="line"><span class="comment">// 也可使用 Kafka 提供的解析器 来解析 Kafka 消息体。例如使用 StringDeserializer 来将 Kafka 消息体解析成字符串：</span></span><br><span class="line">KafkaSource.&lt;String&gt;builder() .setDeserializer(KafkaRecordDeserializationSchema.valueOnly(StringDeserializer.class));</span><br></pre></td></tr></table></figure>

<ul>
<li>起始偏移量</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">KafkaSource.builder()</span><br><span class="line">   <span class="comment">// 从消费组提交的位点开始消费，不指定位点重置策略</span></span><br><span class="line">   .setStartingOffsets(OffsetsInitializer.committedOffsets())</span><br><span class="line">   <span class="comment">// 从消费组提交的位点开始消费，如果提交位点不存在，使用最早位点</span></span><br><span class="line">   .setStartingOffsets(OffsetsInitializer.committedOffsets(OffsetResetStrategy.EARLIEST))</span><br><span class="line">   <span class="comment">// 从时间戳大于等于指定时间的数据开始消费</span></span><br><span class="line">   .setStartingOffsets(OffsetsInitializer.timestamp(<span class="number">1592323200L</span>))</span><br><span class="line">   <span class="comment">// 从最早位点开始消费</span></span><br><span class="line">   .setStartingOffsets(OffsetsInitializer.earliest())</span><br><span class="line">   <span class="comment">// 从最末尾位点开始消费</span></span><br><span class="line">   .setStartingOffsets(OffsetsInitializer.latest());</span><br></pre></td></tr></table></figure>

<ul>
<li>动态分区检查</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 为了在不重启 Flink 作业的情况下处理 Topic 扩容或新建 Topic 等场景，可以将 Kafka Source 配置为在提供的 Topic / Partition 订阅模式下定期检查新分区。要启用动态分区检查，请将 partition.discovery.interval.ms 设置为非负值：</span></span><br><span class="line"><span class="comment">// 分区检查功能默认不开启。需要显式地设置分区检查间隔才能启用此功能。</span></span><br><span class="line">KafkaSource.builder()</span><br><span class="line">.setProperty(<span class="string">&quot;partition.discovery.interval.ms&quot;</span>, <span class="string">&quot;10000&quot;</span>); <span class="comment">// 每 10 秒检查一次新分区</span></span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="CodeDemo"><a href="#CodeDemo" class="headerlink" title="CodeDemo"></a>CodeDemo</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.github.sourceOperator;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javafx.beans.property.SimpleStringProperty;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.eventtime.WatermarkStrategy;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.serialization.SimpleStringSchema;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.connector.kafka.source.KafkaSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.connector.kafka.source.enumerator.initializer.OffsetsInitializer;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.parquet.format.OffsetIndex;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaSourceDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">// 1, 构建带有WebUI的运行环境</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        conf.setInteger(<span class="string">&quot;rest.port&quot;</span>, <span class="number">8081</span>);</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.createLocalEnvironmentWithWebUI(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2, 构建Kafka数据源Source</span></span><br><span class="line">        KafkaSource&lt;String&gt; kafkaSource = KafkaSource.&lt;String&gt;builder()</span><br><span class="line">                .setBootstrapServers(<span class="string">&quot;node1:9092&quot;</span>)</span><br><span class="line">                .setTopics(<span class="string">&quot;test&quot;</span>)</span><br><span class="line">                .setGroupId(<span class="string">&quot;test1&quot;</span>)</span><br><span class="line">                .setStartingOffsets(OffsetsInitializer.earliest())</span><br><span class="line">                .setValueOnlyDeserializer(<span class="keyword">new</span> <span class="title class_">SimpleStringSchema</span>())</span><br><span class="line">                .setProperty(<span class="string">&quot;auto.offset.commit&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">                .build();</span><br><span class="line">        DataStreamSource&lt;String&gt; kafkaDS = env.fromSource(kafkaSource, WatermarkStrategy.noWatermarks(), <span class="string">&quot;kafkaSource&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3, 处理数据</span></span><br><span class="line">        kafkaDS.print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4, 提交执行</span></span><br><span class="line">        env.execute();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="自定义Source-MySQL举例"><a href="#自定义Source-MySQL举例" class="headerlink" title="自定义Source(MySQL举例)"></a>自定义Source(MySQL举例)</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 可以实现   SourceFunction  或者 RichSourceFunction , 这两者都是非并行的source算子</span></span><br><span class="line"><span class="comment">// 也可实现   ParallelSourceFunction  或者 RichParallelSourceFunction , 这两者都是可并行的source算子</span></span><br><span class="line"><span class="comment">// 带 Rich的，都拥有 open() ,close() ,getRuntimeContext() 方法</span></span><br><span class="line"><span class="comment">// 带 Parallel的，都可多实例并行执行</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 都需要实现的方法：run()，作为数据源，所有数据的产生都在 run() 方法中实现</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>上面已经使用了自定义数据源和Flink自带的Kafka source，那么接下来就模仿着写一个从 MySQL 中读取数据的 Source。</p>
<ul>
<li>建表语句</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> database if <span class="keyword">not</span> <span class="keyword">exists</span> flinkdemo;</span><br><span class="line">use flinkdemo;</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> IF <span class="keyword">EXISTS</span> `<span class="keyword">user</span>`;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `<span class="keyword">user</span>`  (</span><br><span class="line"> `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line"> `username` <span class="type">varchar</span>(<span class="number">255</span>) <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line"> `password` <span class="type">varchar</span>(<span class="number">255</span>) <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line"> `name` <span class="type">varchar</span>(<span class="number">255</span>) <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line"> <span class="keyword">PRIMARY</span> KEY (`id`) <span class="keyword">USING</span> BTREE</span><br><span class="line">) ENGINE <span class="operator">=</span> InnoDB <span class="type">CHARACTER</span> <span class="keyword">SET</span> <span class="operator">=</span> utf8 <span class="keyword">COLLATE</span> <span class="operator">=</span> utf8_general_ci ROW_FORMAT <span class="operator">=</span> Compact;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="comment">-- Records of user</span></span><br><span class="line"><span class="comment">-- ----------------------------</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> `<span class="keyword">user</span>` <span class="keyword">VALUES</span> (<span class="number">10</span>, <span class="string">&#x27;dazhuang&#x27;</span>, <span class="string">&#x27;123456&#x27;</span>, <span class="string">&#x27;大壮&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> `<span class="keyword">user</span>` <span class="keyword">VALUES</span> (<span class="number">11</span>, <span class="string">&#x27;erya&#x27;</span>, <span class="string">&#x27;123456&#x27;</span>, <span class="string">&#x27;二丫&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> `<span class="keyword">user</span>` <span class="keyword">VALUES</span> (<span class="number">12</span>, <span class="string">&#x27;sanpang&#x27;</span>, <span class="string">&#x27;123456&#x27;</span>, <span class="string">&#x27;三胖&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SET</span> FOREIGN_KEY_CHECKS <span class="operator">=</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li>添加依赖</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定mysql-connector的依赖 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">version</span>&gt;</span>8.0.15<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="CodeDemo-1"><a href="#CodeDemo-1" class="headerlink" title="CodeDemo"></a>CodeDemo</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.github.sourceOperator;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson2.JSON;</span><br><span class="line"><span class="keyword">import</span> lombok.AllArgsConstructor;</span><br><span class="line"><span class="keyword">import</span> lombok.Data;</span><br><span class="line"><span class="keyword">import</span> lombok.NoArgsConstructor;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.Connection;</span><br><span class="line"><span class="keyword">import</span> java.sql.DriverManager;</span><br><span class="line"><span class="keyword">import</span> java.sql.PreparedStatement;</span><br><span class="line"><span class="keyword">import</span> java.sql.ResultSet;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomSource</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 自定义source读取MySQL中的数据</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="comment">// 1,创建Flink运行环境</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置并行度</span></span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">// 2, 创建Source算子</span></span><br><span class="line">        DataStreamSource&lt;UserInfo&gt; dataStreamSource = env.addSource(<span class="keyword">new</span> <span class="title class_">RichParallelSourceFunction</span>&lt;UserInfo&gt;() &#123;</span><br><span class="line">            <span class="comment">/**</span></span><br><span class="line"><span class="comment">             * 重写RichParallelSourceFunction中的 open, close方法</span></span><br><span class="line"><span class="comment">             * <span class="doctag">@param</span> parameters</span></span><br><span class="line"><span class="comment">             * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="keyword">private</span> <span class="type">Connection</span> <span class="variable">connection</span> <span class="operator">=</span> <span class="literal">null</span>;  <span class="comment">// 定义数据库连接对象</span></span><br><span class="line">            <span class="keyword">private</span> <span class="type">PreparedStatement</span> <span class="variable">stat</span> <span class="operator">=</span> <span class="literal">null</span>;  <span class="comment">// 定义preparedStatement对象</span></span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="comment">/**</span></span><br><span class="line"><span class="comment">                 * 使用open方法, 这个方法在实例化类的时候会执行一次, 比较适合用来做数据库连接</span></span><br><span class="line"><span class="comment">                 * open需要 1, 加载数据库驱动  2, 创建数据库连接  3, 准备preparedStatement对象</span></span><br><span class="line"><span class="comment">                 */</span></span><br><span class="line">                <span class="built_in">super</span>.open(parameters);</span><br><span class="line">                <span class="comment">// 1, 加载数据库驱动</span></span><br><span class="line">                Class.forName(<span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>);</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 2, 创建数据库连接</span></span><br><span class="line">                <span class="type">String</span> <span class="variable">url</span> <span class="operator">=</span> <span class="string">&quot;jdbc:mysql://node1:3306/flinkdemo?serverTimezone=UTC&amp;useSSL=false&quot;</span>;</span><br><span class="line">                <span class="built_in">this</span>.connection = DriverManager.getConnection(url, <span class="string">&quot;root&quot;</span>, <span class="string">&quot;123456&quot;</span>);</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 3, 创建预编译平台对象</span></span><br><span class="line">                <span class="type">String</span> <span class="variable">sql</span> <span class="operator">=</span> <span class="string">&quot;select id,username,password,name from user;&quot;</span>;</span><br><span class="line">                <span class="built_in">this</span>.stat = connection.prepareStatement(sql);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="comment">/**</span></span><br><span class="line"><span class="comment">                 * 使用close方法, 这个方法在销毁实例的时候会执行一次, 比较实用用来关闭连接</span></span><br><span class="line"><span class="comment">                 */</span></span><br><span class="line">                <span class="built_in">super</span>.close();</span><br><span class="line">                <span class="keyword">if</span> (<span class="built_in">this</span>.stat != <span class="literal">null</span>) <span class="built_in">this</span>.stat.close();</span><br><span class="line">                <span class="keyword">if</span> (<span class="built_in">this</span>.connection != <span class="literal">null</span>) <span class="built_in">this</span>.connection.close();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">(SourceContext&lt;UserInfo&gt; ctx)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="comment">// 执行查询SQL语句, 获取结果集</span></span><br><span class="line">                <span class="type">ResultSet</span> <span class="variable">resultSet</span> <span class="operator">=</span> stat.executeQuery();</span><br><span class="line">                <span class="keyword">while</span> (resultSet.next())&#123;</span><br><span class="line">                    ctx.collect(<span class="keyword">new</span> <span class="title class_">UserInfo</span>(</span><br><span class="line">                            resultSet.getString(<span class="string">&quot;id&quot;</span>),</span><br><span class="line">                            resultSet.getString(<span class="string">&quot;userName&quot;</span>),</span><br><span class="line">                            resultSet.getString(<span class="string">&quot;passWord&quot;</span>),</span><br><span class="line">                            resultSet.getString(<span class="string">&quot;name&quot;</span>)</span><br><span class="line">                    ));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">cancel</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).setParallelism(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3,处理数据 - 将对象转为Json字符串并打印</span></span><br><span class="line">        dataStreamSource.map(JSON::toJSONString).print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4, 提交执行</span></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Data</span></span><br><span class="line">    <span class="meta">@AllArgsConstructor</span></span><br><span class="line">    <span class="meta">@NoArgsConstructor</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">UserInfo</span>&#123;</span><br><span class="line">        <span class="keyword">private</span> String id;</span><br><span class="line">        <span class="keyword">private</span> String userName;</span><br><span class="line">        <span class="keyword">private</span> String passWord;</span><br><span class="line">        <span class="keyword">private</span> String name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="转换算子Transformation"><a href="#转换算子Transformation" class="headerlink" title="转换算子Transformation"></a>转换算子Transformation</h1><h2 id="转换算子"><a href="#转换算子" class="headerlink" title="转换算子"></a>转换算子</h2><blockquote>
<p>Flink中的算子，是对DataStream进行操作，返回一个新的DataStream的过程。Transformation 过程，是将一个或多个DataStream 转换为新的 DataStream，可以将多个转换组合成复杂的数据流拓扑。</p>
<p>Transformation：指数据转换的各种操作。有 map &#x2F; flatMap &#x2F; filter &#x2F; keyBy &#x2F; reduce &#x2F; fold &#x2F; aggregations &#x2F; window &#x2F; windowAll &#x2F; union &#x2F; window join &#x2F; split &#x2F; select &#x2F; project 等，可以将数据转换计算成你想要的数据。</p>
</blockquote>
<h2 id="map映射：DataStream→DataStream"><a href="#map映射：DataStream→DataStream" class="headerlink" title="map映射：DataStream→DataStream"></a>map映射：DataStream→DataStream</h2><p>DataStream.map(MapFunction&lt;T, R&gt; mapper)</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;T&gt; 输入元素的数据类型.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;O&gt; 输出元素的数据类型.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Public</span></span><br><span class="line"><span class="meta">@FunctionalInterface</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">MapFunction</span>&lt;T, O&gt; <span class="keyword">extends</span> <span class="title class_">Function</span>, Serializable &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * The mapping method. Takes an element from the input data set and transforms it into exactly</span></span><br><span class="line"><span class="comment">     * one element.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> 输入元素的数据类型.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 输出元素的数据类型.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception This method may throw exceptions. Throwing an exception will cause the</span></span><br><span class="line"><span class="comment">     *     operation to fail and may trigger recovery.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    O <span class="title function_">map</span><span class="params">(T value)</span> <span class="keyword">throws</span> Exception;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="flatmap扁平化映射：DataStream→DataStream"><a href="#flatmap扁平化映射：DataStream→DataStream" class="headerlink" title="flatmap扁平化映射：DataStream→DataStream"></a>flatmap扁平化映射：DataStream→DataStream</h2><p>DataStream.flatMap(FlatMapFunction&lt;T, R&gt; flatMapper)</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;T&gt; 输入元素的数据类型.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;O&gt; 输出元素的数据类型.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Public</span></span><br><span class="line"><span class="meta">@FunctionalInterface</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">FlatMapFunction</span>&lt;T, O&gt; <span class="keyword">extends</span> <span class="title class_">Function</span>, Serializable &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * The core method of the FlatMapFunction. Takes an element from the input data set and</span></span><br><span class="line"><span class="comment">     * transforms it into zero, one, or more elements.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> 输入元素的数据类型.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> out 返回元素收集器</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception This method may throw exceptions. Throwing an exception will cause the</span></span><br><span class="line"><span class="comment">     *     operation to fail and may trigger recovery.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">flatMap</span><span class="params">(T value, Collector&lt;O&gt; out)</span> <span class="keyword">throws</span> Exception;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="filter过滤：DataStream→DataStream"><a href="#filter过滤：DataStream→DataStream" class="headerlink" title="filter过滤：DataStream→DataStream"></a>filter过滤：DataStream→DataStream</h2><p>DataStream.filter(FilterFunction<T> filter)</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;T&gt; 输入元素的数据类型</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Public</span></span><br><span class="line"><span class="meta">@FunctionalInterface</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">FilterFunction</span>&lt;T&gt; <span class="keyword">extends</span> <span class="title class_">Function</span>, Serializable &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * The filter function that evaluates the predicate.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * &lt;p&gt;&lt;strong&gt;IMPORTANT:&lt;/strong&gt; The system assumes that the function does not modify the</span></span><br><span class="line"><span class="comment">     * elements on which the predicate is applied. Violating this assumption can lead to incorrect</span></span><br><span class="line"><span class="comment">     * results.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> value 输入元素的数据类型</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 返回值如果为True该元素就保留，返回值如果为False该就过滤掉</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception This method may throw exceptions. Throwing an exception will cause the</span></span><br><span class="line"><span class="comment">     *     operation to fail and may trigger recovery.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="type">boolean</span> <span class="title function_">filter</span><span class="params">(T value)</span> <span class="keyword">throws</span> Exception;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="keyBy按key分组：DataStream→KeyedStream"><a href="#keyBy按key分组：DataStream→KeyedStream" class="headerlink" title="keyBy按key分组：DataStream→KeyedStream"></a>keyBy按key分组：DataStream→KeyedStream</h2><p>DataStream.keyBy(KeySelector&lt;T, K&gt; key)</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;IN&gt; 输入元素，并从该元素中抽取key</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;KEY&gt; key的数据类型.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Public</span></span><br><span class="line"><span class="meta">@FunctionalInterface</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">KeySelector</span>&lt;IN, KEY&gt; <span class="keyword">extends</span> <span class="title class_">Function</span>, Serializable &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> value The object to get the key from.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> The extracted key.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception Throwing an exception will cause the execution of the respective task to</span></span><br><span class="line"><span class="comment">     *     fail, and trigger recovery or cancellation of the program.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    KEY <span class="title function_">getKey</span><span class="params">(IN value)</span> <span class="keyword">throws</span> Exception;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/***************** 单个字段keyBy ********************/</span></span><br><span class="line"><span class="comment">//用字段位置(已过期)</span></span><br><span class="line">wordAndOne.keyBy(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//用字段表达式</span></span><br><span class="line">wordAndOne.keyBy(v -&gt; v.f0)</span><br><span class="line">    </span><br><span class="line"><span class="comment">/***************** 多个字段keyBy ********************/</span>    </span><br><span class="line"><span class="comment">//用字段位置（已过期）</span></span><br><span class="line">wordAndOne.keyBy(<span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//用KeySelector</span></span><br><span class="line">wordAndOne.keyBy(<span class="keyword">new</span> <span class="title class_">KeySelector</span>&lt;Tuple2&lt;String, Integer&gt;, Tuple2&lt;String, Integer&gt;&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Tuple2&lt;String, Integer&gt; <span class="title function_">getKey</span><span class="params">(Tuple2&lt;String, Integer&gt; value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">return</span> Tuple2.of(value.f0, value.f1);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">// 用lambda简化</span></span><br><span class="line">wordAndOne.keyBy(</span><br><span class="line">        (KeySelector&lt;Tuple2&lt;String, Integer&gt;, Tuple2&lt;String, Integer&gt;&gt;) value -&gt;</span><br><span class="line">                Tuple2.of(value.f0, value.f1)</span><br><span class="line">); </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/***************** POJO方式 ********************/</span>   </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PeopleCount</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String province;</span><br><span class="line">    <span class="keyword">private</span> String city;</span><br><span class="line">    <span class="keyword">private</span> Integer counts;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">PeopleCount</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//省略其他代码。。。</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 单个字段</span></span><br><span class="line">source.keyBy(a -&gt; a.getProvince());</span><br><span class="line">source.keyBy(PeopleCount::getProvince);</span><br><span class="line"><span class="comment">// 多个字段</span></span><br><span class="line">source.keyBy(<span class="keyword">new</span> <span class="title class_">KeySelector</span>&lt;PeopleCount, Tuple2&lt;String, String&gt;&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Tuple2&lt;String, String&gt; <span class="title function_">getKey</span><span class="params">(PeopleCount value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">return</span> Tuple2.of(value.getProvince(), value.getCity());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">map.keyBy(</span><br><span class="line">        (KeySelector&lt;PeopleCount, Tuple2&lt;String, String&gt;&gt;) value -&gt;</span><br><span class="line">                Tuple2.of(value.getProvince(), value.getCity())</span><br><span class="line">); </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="简单聚合：KeyedStream→DataStream"><a href="#简单聚合：KeyedStream→DataStream" class="headerlink" title="简单聚合：KeyedStream→DataStream"></a>简单聚合：KeyedStream→DataStream</h2><blockquote>
<ul>
<li>sum()：在输入流上，对指定的字段做叠加求和的操作。</li>
<li>min()：在输入流上，对指定的字段求最小值。</li>
<li>max()：在输入流上，对指定的字段求最大值。</li>
<li>minBy()：与 min()类似，在输入流上针对指定字段求最小值。不同的是，min()只计算指定字段的最小值，其他字段会保留最初第一个数据的值；而 minBy()则会返回包含字段最小值的整条数据。</li>
<li>maxBy()：与 max()类似，在输入流上针对指定字段求最大值。两者区别与min()&#x2F;minBy()完全一致。</li>
</ul>
</blockquote>
<h2 id="reduce归约：KeyedStream→DataSream"><a href="#reduce归约：KeyedStream→DataSream" class="headerlink" title="reduce归约：KeyedStream→DataSream"></a>reduce归约：KeyedStream→DataSream</h2><p>KeyedStream.reduce(ReduceFunction<T> reducer)</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;T&gt; 输入元素的数据类型.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Public</span></span><br><span class="line"><span class="meta">@FunctionalInterface</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ReduceFunction</span>&lt;T&gt; <span class="keyword">extends</span> <span class="title class_">Function</span>, Serializable &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * The core method of ReduceFunction, combining two values into one value of the same type. The</span></span><br><span class="line"><span class="comment">     * reduce function is consecutively applied to all values of a group until only a single value</span></span><br><span class="line"><span class="comment">     * remains.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> value1 The first value to combine.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> value2 The second value to combine.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> The combined value of both input values.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception This method may throw exceptions. Throwing an exception will cause the</span></span><br><span class="line"><span class="comment">     *     operation to fail and may trigger recovery.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    T <span class="title function_">reduce</span><span class="params">(T value1, T value2)</span> <span class="keyword">throws</span> Exception;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="转换算子Operator"><a href="#转换算子Operator" class="headerlink" title="转换算子Operator"></a>转换算子Operator</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.github.transformation;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> io.github.pojo.Order;</span><br><span class="line"><span class="keyword">import</span> org.apache.avro.data.Json;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.FlatMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.ReduceFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple4;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.KeyedStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson2.JSON;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.ProcessFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"><span class="keyword">import</span> scala.math.BigInt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KeyByOperator</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">// 1, 构建运行环境</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2, 构建source算子获取数据</span></span><br><span class="line">        DataStreamSource&lt;String&gt; streamSource = env.readTextFile(<span class="string">&quot;/Users/Liguibin/Desktop/opt/Java/FlinkCode/src/main/resources/order.csv&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3-1, 将获取到的数据封装至pojo中, 输入的数据是String类型, 返回的数据是Order对象</span></span><br><span class="line">        SingleOutputStreamOperator&lt;Order&gt; orderDS = streamSource.flatMap(</span><br><span class="line">                (FlatMapFunction&lt;String, Order&gt;) (value, out) -&gt; out.collect(<span class="keyword">new</span> <span class="title class_">Order</span>(</span><br><span class="line">                        value.split(<span class="string">&quot;,&quot;</span>)[<span class="number">0</span>],</span><br><span class="line">                        BigInt.apply(value.split(<span class="string">&quot;,&quot;</span>)[<span class="number">1</span>]),</span><br><span class="line">                        Double.parseDouble(value.split(<span class="string">&quot;,&quot;</span>)[<span class="number">2</span>]),</span><br><span class="line">                        value.split(<span class="string">&quot;,&quot;</span>)[<span class="number">3</span>])))</span><br><span class="line">                .returns(Order.class);</span><br><span class="line">        <span class="comment">// 3-2 将获取到的数据封装至四元组中</span></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 如果将数据切分封装到元组中, 需要重写flatMap方法, out.collect(new Tuple&lt;&gt;(元组中四个元素))</span></span><br><span class="line"><span class="comment">         * 如果FLatMap写成为Lambda表达式, 后面必须要跟returns(Types.Tuple(Types.字段类型 ....))</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        SingleOutputStreamOperator&lt;Tuple4&lt;String, BigInt, Double, String&gt;&gt; tuple4DS = streamSource.flatMap(<span class="keyword">new</span> <span class="title class_">FlatMapFunction</span>&lt;String, Tuple4&lt;String, BigInt, Double, String&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">flatMap</span><span class="params">(String value, Collector&lt;Tuple4&lt;String, BigInt, Double, String&gt;&gt; out)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                out.collect(<span class="keyword">new</span> <span class="title class_">Tuple4</span>&lt;&gt;(</span><br><span class="line">                        value.split(<span class="string">&quot;,&quot;</span>)[<span class="number">0</span>],</span><br><span class="line">                        BigInt.apply(value.split(<span class="string">&quot;,&quot;</span>)[<span class="number">1</span>]),</span><br><span class="line">                        Double.parseDouble(value.split(<span class="string">&quot;,&quot;</span>)[<span class="number">2</span>]),</span><br><span class="line">                        value.split(<span class="string">&quot;,&quot;</span>)[<span class="number">3</span>]));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4, 使用keyBy算子分发数据(按照用户的id进行分发)</span></span><br><span class="line">        <span class="comment">// KeyedStream&lt;Tuple4&lt;String, BigInt, Double, String&gt;, Tuple&gt; keyedStream1 = tupleDS.keyBy(0);</span></span><br><span class="line">        <span class="comment">// KeyedStream&lt;Tuple4&lt;String, BigInt, Double, String&gt;, String&gt; keyedStream1 = tuple4DS.keyBy(t -&gt; t.f0);</span></span><br><span class="line">        <span class="comment">// KeyedStream&lt;Order, String&gt; keyedStream1 = orderDS.keyBy(o -&gt; o.getUserId());</span></span><br><span class="line">        KeyedStream&lt;Order, String&gt; keyedStream = orderDS.keyBy(Order::getUserId);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5-1 sum 求金额求和</span></span><br><span class="line"><span class="comment">//        keyedStream.sum(&quot;money&quot;).print(&quot;sum求金额总和&quot;);</span></span><br><span class="line">        <span class="comment">// 5-2 min求每个用户最小的消费金额</span></span><br><span class="line"><span class="comment">//        keyedStream.minBy(&quot;money&quot;).print(&quot;min求每个用户最小的消费金额&quot;);</span></span><br><span class="line">        <span class="comment">// 5-3 使用Reduce规约计算 (求金额的最小值 )</span></span><br><span class="line"><span class="comment">//        keyedStream.reduce(new ReduceFunction&lt;Order&gt;() &#123;</span></span><br><span class="line"><span class="comment">//            @Override</span></span><br><span class="line"><span class="comment">//            public Order reduce(Order value1, Order value2) throws Exception &#123;</span></span><br><span class="line"><span class="comment">//                if (value1.getMoney() &gt; value2.getMoney())return value2;</span></span><br><span class="line"><span class="comment">//                else return value1;</span></span><br><span class="line"><span class="comment">//            &#125;</span></span><br><span class="line"><span class="comment">//        &#125;).print(&quot;使用Reduce规约计算&quot;);</span></span><br><span class="line">        <span class="comment">// 5-4 使用stream processAPI</span></span><br><span class="line">        keyedStream.process(<span class="keyword">new</span> <span class="title class_">ProcessFunction</span>&lt;Order, String&gt;() &#123;</span><br><span class="line">            <span class="comment">/**</span></span><br><span class="line"><span class="comment">             * order 是入参, String 是返回值参数的类型</span></span><br><span class="line"><span class="comment">             * <span class="doctag">@param</span> value</span></span><br><span class="line"><span class="comment">             * <span class="doctag">@param</span> ctx  上下文运行环境, Context 背景语境上下文</span></span><br><span class="line"><span class="comment">             * <span class="doctag">@param</span> out</span></span><br><span class="line"><span class="comment">             * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">processElement</span><span class="params">(Order value, Context ctx, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                System.out.println(ctx.timestamp());  <span class="comment">// 没获取到时间后续再说(略,服了</span></span><br><span class="line">                System.out.println(JSON.toJSONString(value));  <span class="comment">// 将一个个传入的对象打印为Json字符串</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6, 提交任务并执行</span></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="物理分区"><a href="#物理分区" class="headerlink" title="物理分区"></a>物理分区</h1><h2 id="GLOBAL分区"><a href="#GLOBAL分区" class="headerlink" title="GLOBAL分区"></a>GLOBAL分区</h2><blockquote>
<p>GlobalPartitioner 分区器会将上游所有元素都发送到下游的第一个算子实例上(SubTask Id &#x3D; 0)：</p>
</blockquote>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/blog/image-20230908154757654.png"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@PublicEvolving</span></span><br><span class="line"><span class="keyword">public</span> DataStream&lt;T&gt; <span class="title function_">global</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> setConnectionType(<span class="keyword">new</span> <span class="title class_">GlobalPartitioner</span>&lt;T&gt;());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Partitioner that sends all elements to the downstream operator with subtask ID=0.</span></span><br><span class="line"><span class="comment"> * 分区器将所有上游元素发送到下游ID=0（第一个）的算子中</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;T&gt; Type of the elements in the Stream being partitioned</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Internal</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">GlobalPartitioner</span>&lt;T&gt; <span class="keyword">extends</span> <span class="title class_">StreamPartitioner</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">serialVersionUID</span> <span class="operator">=</span> <span class="number">1L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">selectChannel</span><span class="params">(SerializationDelegate&lt;StreamRecord&lt;T&gt;&gt; record)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> StreamPartitioner&lt;T&gt; <span class="title function_">copy</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> SubtaskStateMapper <span class="title function_">getDownstreamSubtaskStateMapper</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> SubtaskStateMapper.FIRST;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isPointwise</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;GLOBAL&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="FORWARD分区"><a href="#FORWARD分区" class="headerlink" title="FORWARD分区"></a>FORWARD分区</h2><blockquote>
<p>与 GlobalPartitioner 实现相同，但它只会将数据输出到本地运行的下游算子的第一个实例，而非全局。在上下游的算子没有指定分区器的情况下，如果上下游的算子并行度一致，则使用ForwardPartitioner，否则使用 RebalancePartitioner，对于ForwardPartitioner，必须保证上下游算子并行度一致，否则会抛出异常。</p>
</blockquote>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/blog/image-20230908155130162.png"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Sets the partitioning of the &#123;<span class="doctag">@link</span> DataStream&#125; so that the output elements are forwarded to</span></span><br><span class="line"><span class="comment"> * the local subtask of the next operation.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> The DataStream with forward partitioning set.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> DataStream&lt;T&gt; <span class="title function_">forward</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> setConnectionType(<span class="keyword">new</span> <span class="title class_">ForwardPartitioner</span>&lt;T&gt;());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Partitioner that forwards elements only to the locally running downstream operation.</span></span><br><span class="line"><span class="comment"> * 分区器将元素发送至本地运行的下游算子，上游与下游并行度必须一致</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;T&gt; Type of the elements in the Stream</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Internal</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ForwardPartitioner</span>&lt;T&gt; <span class="keyword">extends</span> <span class="title class_">StreamPartitioner</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">serialVersionUID</span> <span class="operator">=</span> <span class="number">1L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">selectChannel</span><span class="params">(SerializationDelegate&lt;StreamRecord&lt;T&gt;&gt; record)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> StreamPartitioner&lt;T&gt; <span class="title function_">copy</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isPointwise</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;FORWARD&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> SubtaskStateMapper <span class="title function_">getDownstreamSubtaskStateMapper</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> SubtaskStateMapper.UNSUPPORTED;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> SubtaskStateMapper <span class="title function_">getUpstreamSubtaskStateMapper</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> SubtaskStateMapper.UNSUPPORTED;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="BROADCAST分区"><a href="#BROADCAST分区" class="headerlink" title="BROADCAST分区"></a>BROADCAST分区</h2><p>广播分区将上游数据集输出到下游Operator的每个实例中。适合于大数据集Join小数据集的场景。</p>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/blog/image-20230908155538126.png"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Sets the partitioning of the &#123;<span class="doctag">@link</span> DataStream&#125; so that the output elements are broadcasted</span></span><br><span class="line"><span class="comment"> * to every parallel instance of the next operation.</span></span><br><span class="line"><span class="comment"> * 将上游所有元素复制多份发送至下游的所有算子中</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> The DataStream with broadcast partitioning set.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> DataStream&lt;T&gt; <span class="title function_">broadcast</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> setConnectionType(<span class="keyword">new</span> <span class="title class_">BroadcastPartitioner</span>&lt;T&gt;());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Partitioner that selects all the output channels.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;T&gt; Type of the elements in the Stream being broadcast</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Internal</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BroadcastPartitioner</span>&lt;T&gt; <span class="keyword">extends</span> <span class="title class_">StreamPartitioner</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">serialVersionUID</span> <span class="operator">=</span> <span class="number">1L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Note: Broadcast mode could be handled directly for all the output channels in record writer,</span></span><br><span class="line"><span class="comment">     * so it is no need to select channels via this method.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">selectChannel</span><span class="params">(SerializationDelegate&lt;StreamRecord&lt;T&gt;&gt; record)</span> &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">UnsupportedOperationException</span>(</span><br><span class="line">                <span class="string">&quot;Broadcast partitioner does not support select channels.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> SubtaskStateMapper <span class="title function_">getUpstreamSubtaskStateMapper</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> SubtaskStateMapper.UNSUPPORTED;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> SubtaskStateMapper <span class="title function_">getDownstreamSubtaskStateMapper</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> SubtaskStateMapper.UNSUPPORTED;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isBroadcast</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> StreamPartitioner&lt;T&gt; <span class="title function_">copy</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isPointwise</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;BROADCAST&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="SHUFFLE分区"><a href="#SHUFFLE分区" class="headerlink" title="SHUFFLE分区"></a>SHUFFLE分区</h2><p>随机分区服从均匀分布（uniform distribution），所以可以把流中的数据随机打乱，均匀地传递到下游任务分区，因为是完全随机的，所以对于同样的输入数据, 每次执行得到的结果也不会相同。</p>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/blog/image-20230908155812273.png"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Sets the partitioning of the &#123;<span class="doctag">@link</span> DataStream&#125; so that the output elements are shuffled</span></span><br><span class="line"><span class="comment"> * uniformly randomly to the next operation.</span></span><br><span class="line"><span class="comment"> * 将上游算子中的所有元素随机发送至下游算子中</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> The DataStream with shuffle partitioning set.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@PublicEvolving</span></span><br><span class="line"><span class="keyword">public</span> DataStream&lt;T&gt; <span class="title function_">shuffle</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> setConnectionType(<span class="keyword">new</span> <span class="title class_">ShufflePartitioner</span>&lt;T&gt;());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Partitioner that distributes the data equally by selecting one output channel randomly.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;T&gt; Type of the Tuple</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Internal</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ShufflePartitioner</span>&lt;T&gt; <span class="keyword">extends</span> <span class="title class_">StreamPartitioner</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">serialVersionUID</span> <span class="operator">=</span> <span class="number">1L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">Random</span> <span class="variable">random</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Random</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">selectChannel</span><span class="params">(SerializationDelegate&lt;StreamRecord&lt;T&gt;&gt; record)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> random.nextInt(numberOfChannels);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> SubtaskStateMapper <span class="title function_">getDownstreamSubtaskStateMapper</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> SubtaskStateMapper.ROUND_ROBIN;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> StreamPartitioner&lt;T&gt; <span class="title function_">copy</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">ShufflePartitioner</span>&lt;T&gt;();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isPointwise</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;SHUFFLE&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="REBALANCE分区"><a href="#REBALANCE分区" class="headerlink" title="REBALANCE分区"></a>REBALANCE分区</h2><blockquote>
<p>基于上下游算子的并行度，将元素循环的分配到下游算子的某几个实例上。以上游算子并行度为 2，而下游算子并行度为 4 为例，当使用 RebalancePartitioner时，上游每个实例会轮询发给下游的 4 个实例。但是当使用 RescalePartitioner 时，上游每个实例只需轮询发给下游 2 个实例。因为 Channel 个数变少了，Subpartition 的 Buffer 填充速度能变快，能提高网络效率。当上游的数据比较均匀时，且上下游的并发数成比例时，可以使用 RescalePartitioner 替换 RebalancePartitioner。</p>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/blog/image-20230908160749682.png"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Sets the partitioning of the &#123;<span class="doctag">@link</span> DataStream&#125; so that the output elements are distributed</span></span><br><span class="line"><span class="comment"> * evenly to a subset of instances of the next operation in a round-robin fashion.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;The subset of downstream operations to which the upstream operation sends elements depends</span></span><br><span class="line"><span class="comment"> * on the degree of parallelism of both the upstream and downstream operation. For example, if</span></span><br><span class="line"><span class="comment"> * the upstream operation has parallelism 2 and the downstream operation has parallelism 4, then</span></span><br><span class="line"><span class="comment"> * one upstream operation would distribute elements to two downstream operations while the other</span></span><br><span class="line"><span class="comment"> * upstream operation would distribute to the other two downstream operations. If, on the other</span></span><br><span class="line"><span class="comment"> * hand, the downstream operation has parallelism 2 while the upstream operation has parallelism</span></span><br><span class="line"><span class="comment"> * 4 then two upstream operations will distribute to one downstream operation while the other</span></span><br><span class="line"><span class="comment"> * two upstream operations will distribute to the other downstream operations.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;In cases where the different parallelisms are not multiples of each other one or several</span></span><br><span class="line"><span class="comment"> * downstream operations will have a differing number of inputs from upstream operations.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> The DataStream with rescale partitioning set.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@PublicEvolving</span></span><br><span class="line"><span class="keyword">public</span> DataStream&lt;T&gt; <span class="title function_">rescale</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> setConnectionType(<span class="keyword">new</span> <span class="title class_">RescalePartitioner</span>&lt;T&gt;());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Partitioner that distributes the data equally by cycling through the output channels. This</span></span><br><span class="line"><span class="comment"> * distributes only to a subset of downstream nodes because &#123;<span class="doctag">@link</span></span></span><br><span class="line"><span class="comment"> * org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator&#125; instantiates a &#123;<span class="doctag">@link</span></span></span><br><span class="line"><span class="comment"> * DistributionPattern#POINTWISE&#125; distribution pattern when encountering &#123;<span class="doctag">@code</span> RescalePartitioner&#125;.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;The subset of downstream operations to which the upstream operation sends elements depends on</span></span><br><span class="line"><span class="comment"> * the degree of parallelism of both the upstream and downstream operation. For example, if the</span></span><br><span class="line"><span class="comment"> * upstream operation has parallelism 2 and the downstream operation has parallelism 4, then one</span></span><br><span class="line"><span class="comment"> * upstream operation would distribute elements to two downstream operations while the other</span></span><br><span class="line"><span class="comment"> * upstream operation would distribute to the other two downstream operations. If, on the other</span></span><br><span class="line"><span class="comment"> * hand, the downstream operation has parallelism 2 while the upstream operation has parallelism 4</span></span><br><span class="line"><span class="comment"> * then two upstream operations will distribute to one downstream operation while the other two</span></span><br><span class="line"><span class="comment"> * upstream operations will distribute to the other downstream operations.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;In cases where the different parallelisms are not multiples of each other one or several</span></span><br><span class="line"><span class="comment"> * downstream operations will have a differing number of inputs from upstream operations.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;T&gt; Type of the elements in the Stream being rescaled</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Internal</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RescalePartitioner</span>&lt;T&gt; <span class="keyword">extends</span> <span class="title class_">StreamPartitioner</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">serialVersionUID</span> <span class="operator">=</span> <span class="number">1L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="variable">nextChannelToSendTo</span> <span class="operator">=</span> -<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">selectChannel</span><span class="params">(SerializationDelegate&lt;StreamRecord&lt;T&gt;&gt; record)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (++nextChannelToSendTo &gt;= numberOfChannels) &#123;</span><br><span class="line">            nextChannelToSendTo = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> nextChannelToSendTo;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> SubtaskStateMapper <span class="title function_">getDownstreamSubtaskStateMapper</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> SubtaskStateMapper.UNSUPPORTED;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> SubtaskStateMapper <span class="title function_">getUpstreamSubtaskStateMapper</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> SubtaskStateMapper.UNSUPPORTED;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> StreamPartitioner&lt;T&gt; <span class="title function_">copy</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;RESCALE&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isPointwise</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</blockquote>
<h2 id="CUSTOM分区"><a href="#CUSTOM分区" class="headerlink" title="CUSTOM分区"></a>CUSTOM分区</h2><p>自定义实现元素要发送到相对应的下游算子实例上</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Partitions a DataStream on the key returned by the selector, using a custom partitioner. This</span></span><br><span class="line"><span class="comment"> * method takes the key selector to get the key to partition on, and a partitioner that accepts</span></span><br><span class="line"><span class="comment"> * the key type.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;Note: This method works only on single field keys, i.e. the selector cannot return tuples</span></span><br><span class="line"><span class="comment"> * of fields.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> partitioner The partitioner to assign partitions to keys.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> keySelector The KeySelector with which the DataStream is partitioned.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> The partitioned DataStream.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@see</span> KeySelector</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> &lt;K&gt; DataStream&lt;T&gt; <span class="title function_">partitionCustom</span><span class="params">(</span></span><br><span class="line"><span class="params">        Partitioner&lt;K&gt; partitioner, KeySelector&lt;T, K&gt; keySelector)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> setConnectionType(</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">CustomPartitionerWrapper</span>&lt;&gt;(clean(partitioner), clean(keySelector)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.github.pratitioner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson2.JSON;</span><br><span class="line"><span class="keyword">import</span> io.github.pojo.Order;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.FlatMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.Partitioner;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"><span class="keyword">import</span> scala.math.BigInt;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomPartitioner</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1, 构建Flink运行环境</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        conf.setInteger(<span class="string">&quot;rest.port&quot;</span>, <span class="number">8081</span>);</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.createLocalEnvironment();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2, 构建source算子获取数据</span></span><br><span class="line">        DataStreamSource&lt;String&gt; streamSource = env.socketTextStream(<span class="string">&quot;node1&quot;</span>, <span class="number">9999</span>);</span><br><span class="line">        <span class="comment">// 3, 将获取到的数据封装至pojo中(订单实体类)</span></span><br><span class="line">        SingleOutputStreamOperator&lt;Order&gt; orderDS = streamSource.flatMap((FlatMapFunction&lt;String, Order&gt;) (value, out) -&gt; out.collect(<span class="keyword">new</span> <span class="title class_">Order</span>(</span><br><span class="line">                value.split(<span class="string">&quot;,&quot;</span>)[<span class="number">0</span>],</span><br><span class="line">                BigInt.apply(value.split(<span class="string">&quot;,&quot;</span>)[<span class="number">1</span>]),</span><br><span class="line">                Double.valueOf(value.split(<span class="string">&quot;,&quot;</span>)[<span class="number">2</span>]),</span><br><span class="line">                value.split(<span class="string">&quot;,&quot;</span>)[<span class="number">3</span>]</span><br><span class="line">        ))).returns(Order.class).setParallelism(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4, 进行自定义重分区</span></span><br><span class="line">        <span class="comment">// partitionCustom自定义分区方法</span></span><br><span class="line">        <span class="comment">// 第一个参数 Partitioner：实现分区器，如：将奇数发给0号分区，将偶数发给1号分区</span></span><br><span class="line">        <span class="comment">// 第二个参数 KeySelector：指定分区字段</span></span><br><span class="line">        orderDS.partitionCustom(<span class="keyword">new</span> <span class="title class_">MyCustomPartitioner</span>(), Order::getUserId)</span><br><span class="line">                .map(JSON::toJSONString)</span><br><span class="line">                .setParallelism(<span class="number">3</span>)</span><br><span class="line">                .print().setParallelism(<span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">MyCustomPartitioner</span> <span class="keyword">implements</span> <span class="title class_">Partitioner</span>&lt;String&gt; &#123;</span><br><span class="line">        <span class="comment">// 把包含001的userId发送到下游第一个算子中</span></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">partition</span><span class="params">(String key, <span class="type">int</span> numPartitions)</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (key.contains(<span class="string">&quot;001&quot;</span>))&#123;</span><br><span class="line">                System.out.println(key + <span class="string">&quot;:发送到第一个分区&quot;</span>);</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span>;  <span class="comment">// 这里相当于把数据下发到下游第一个算子中了</span></span><br><span class="line">            &#125;<span class="keyword">else</span> <span class="keyword">return</span> <span class="number">1</span>; <span class="comment">// 把其他的数据都发送至第二个算子中</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="输出算子Sink"><a href="#输出算子Sink" class="headerlink" title="输出算子Sink"></a>输出算子Sink</h1><h2 id="FileSink"><a href="#FileSink" class="headerlink" title="FileSink"></a>FileSink</h2><p>场景描述：</p>
<blockquote>
<ul>
<li>大数据业务场景中，经常有一种场景：外部数据发送到kafka中，Flink作为中间件消费kafka数据并进行业务处理；处理完成之后的数据可能还需要写入到数据库或者文件系统中，比如写入hdfs中。</li>
<li>FileSink就可以用来将分区文件写入到支持 Flink FileSystem 接口的文件系统中，支持Exactly-Once语义。</li>
<li>这种sink实现的****Exactly-Once****都是基于Flink checkpoint来实现的两阶段提交模式来保证的，主要应用在实时数仓、topic拆分、基于小时分析处理等场景下。</li>
</ul>
</blockquote>
<p>实现原理：</p>
<blockquote>
<p><img src="http://lesson-pic.oss-cn-hangzhou.aliyuncs.com/pics/image-20230904122702767.png" alt="image-20230904122702767"></p>
<ul>
<li>Bucket：FileSink可向由Flink FileSystem抽象支持的文件系统写入分区文件（因为是流式写入，数据被视为无界）。该分区行为可配，默认按时间，具体来说每小时写入一个Bucket，该Bucket包括若干文件，内容是这一小时间隔内流中收到的所有record。</li>
<li>PartFile：每个Bucket内部分为多个PartFile来存储输出数据，该Bucket生命周期内接收到数据的sink的每个子任务至少有一个PartFile。</li>
<li>FileSink 支持行编码（Row-encoded）和批量编码（Bulk-encoded，比如 Parquet）格式。</li>
</ul>
</blockquote>
<p>配置详解：</p>
<blockquote>
<ul>
<li><p>1-PartFile：每个Bucket内部分为多个部分文件，该Bucket内接收到数据的sink的每个子任务至少有一个PartFile。而额外文件滚动由可配的滚动策略决定。</p>
<ul>
<li>生命周期：在每个活跃的Bucket期间，每个Writer的子任务在任何时候都只会有一个单独的In-progress PartFile，但可有多个Peding和Finished状态文件。<ul>
<li>In-progress ：当前文件正在写入中</li>
<li>Pending ：当处于 In-progress 状态的文件关闭（closed）了，就变为 Pending 状态</li>
<li>Finished ：在成功的 Checkpoint 后，Pending 状态将变为 Finished 状态,处于 Finished 状态的文件不会再被修改，可以被下游系统安全地读取。</li>
</ul>
</li>
<li>命名规则：<ul>
<li>In-progress &#x2F; Pending：part-<uid>-<partFileIndex>.inprogress.uid</li>
<li>Finished：part-<uid>-<partFileIndex> 当 Sink Subtask 实例化时，它的 uid 是一个分配给 Subtask 的随机 ID 值。这个 uid 不具有容错机制，所以当 Subtask 从故障恢复时，uid 会重新生成</li>
<li>Flink 允许用户给 Part 文件名添加一个前缀和&#x2F;或后缀。 使用 OutputFileConfig 来完成。</li>
</ul>
</li>
<li>注意：使用 FileSink 时需要启用 Checkpoint ，每次做 Checkpoint 时写入完成。如果 Checkpoint 被禁用，部分文件（part file）将永远处于 ‘in-progress’ 或 ‘pending’ 状态，下游系统无法安全地读取。</li>
</ul>
</li>
<li><p>2-序列化编码：FileSink 支持行编码格式和批量编码格式（ 比如：Apache Parquet） 。</p>
<ul>
<li><p>FileSink.forRowFormat(basePath, rowEncoder)</p>
<ul>
<li><p>必须配置项：</p>
<ul>
<li>输出数据的BasePath</li>
<li>序列化每行数据写入PartFile的Encoder</li>
</ul>
</li>
<li><p>使用RowFormatBuilder可选配置项：</p>
<ul>
<li>自定义RollingPolicy：默认使用DefaultRollingPolicy来滚动文件，可自定义bucketCheckInterval</li>
<li>默认1分钟。该值单位为毫秒，指定按时间滚动文件间隔时间</li>
</ul>
</li>
<li><pre><code class="java">  FileSink sink  = FileSink
      .forRowFormat(new Path(outputPath), new SimpleStringEncoder[String](&quot;UTF-8&quot;))
      .withRollingPolicy(
      DefaultRollingPolicy.builder()
              .withRolloverInterval(Duration.ofMinutes(15))
              .withInactivityInterval(Duration.ofMinutes(5))
              .withMaxPartSize(MemorySize.ofMebiBytes(1))
              .build())
      .build()
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
</code></pre>
</li>
</ul>
</li>
<li><p>FileSink.forBulkFormat(basePath, bulkWriterFactory)</p>
<ul>
<li>Bulk-encoded 的 Sink 的创建和 Row-encoded 的相似，但不需要指定 Encoder，而是需要指定 BulkWriter.Factory。 BulkWriter 定义了如何添加和刷新新数据以及如何最终确定一批记录使用哪种编码字符集的逻辑。</li>
<li>需要相关依赖</li>
</ul>
</li>
</ul>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">```xml</span><br><span class="line"> &lt;!-- 应用FileSink功能所需要的依赖 --&gt;</span><br><span class="line"> &lt;dependency&gt;</span><br><span class="line">     &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">     &lt;artifactId&gt;flink-parquet&lt;/artifactId&gt;</span><br><span class="line">     &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt;</span><br><span class="line"> &lt;/dependency&gt;</span><br><span class="line"> &lt;dependency&gt;</span><br><span class="line">     &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">     &lt;artifactId&gt;flink-avro&lt;/artifactId&gt;</span><br><span class="line">     &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt;</span><br><span class="line"> &lt;/dependency&gt;</span><br><span class="line"> &lt;dependency&gt;</span><br><span class="line">     &lt;groupId&gt;org.apache.parquet&lt;/groupId&gt;</span><br><span class="line">     &lt;artifactId&gt;parquet-avro&lt;/artifactId&gt;</span><br><span class="line">     &lt;version&gt;$&#123;parquet-avro&#125;&lt;/version&gt;</span><br><span class="line"> &lt;/dependency&gt;</span><br></pre></td></tr></table></figure></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 三种实现方式</span><br><span class="line"></span><br><span class="line">  - 根据schema将数据写成parquet格式</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. 先定义GenericRecord的数据模式</span></span><br><span class="line"><span class="type">Schema</span> <span class="variable">schema</span> <span class="operator">=</span> SchemaBuilder.builder()</span><br><span class="line">        .record(<span class="string">&quot;DataRecord&quot;</span>)</span><br><span class="line">        .namespace(<span class="string">&quot;cn.itcast.flink.avro.schema&quot;</span>)</span><br><span class="line">        .fields()</span><br><span class="line">        .requiredInt(<span class="string">&quot;gid&quot;</span>)</span><br><span class="line">        .requiredLong(<span class="string">&quot;ts&quot;</span>)</span><br><span class="line">        .requiredString(<span class="string">&quot;eventId&quot;</span>)</span><br><span class="line">        .requiredString(<span class="string">&quot;sessionId&quot;</span>)</span><br><span class="line">        .name(<span class="string">&quot;eventInfo&quot;</span>)</span><br><span class="line">        .type()</span><br><span class="line">        .map()</span><br><span class="line">        .values()</span><br><span class="line">        .type(<span class="string">&quot;string&quot;</span>)</span><br><span class="line">        .noDefault()</span><br><span class="line">        .endRecord();</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 构造好一个数据流</span></span><br><span class="line">DataStreamSource&lt;EventLog&gt; streamSource = env.addSource(<span class="keyword">new</span> <span class="title class_">MySourceFunction</span>());</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 2. 通过定义好的schema模式，来得到一个parquetWriter</span></span><br><span class="line">ParquetWriterFactory&lt;GenericRecord&gt; writerFactory = AvroParquetWriters.forGenericRecord(schema);</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 3. 利用生成好的parquetWriter，来构造一个 支持列式输出parquet文件的 sink算子</span></span><br><span class="line">FileSink&lt;GenericRecord&gt; sink1 = FileSink.forBulkFormat(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;d:/filesink/bulkformat&quot;</span>), writerFactory)</span><br><span class="line">        .withBucketAssigner(<span class="keyword">new</span> <span class="title class_">DateTimeBucketAssigner</span>&lt;GenericRecord&gt;(<span class="string">&quot;yyyy-MM-dd--HH&quot;</span>))</span><br><span class="line">        .withRollingPolicy(OnCheckpointRollingPolicy.build())</span><br><span class="line">        .withOutputFileConfig(OutputFileConfig.builder().withPartPrefix(<span class="string">&quot;itcast&quot;</span>).withPartSuffix(<span class="string">&quot;.parquet&quot;</span>).build())</span><br><span class="line">        .build();</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 4. 将自定义javabean的流，转成 上述sink算子中parquetWriter所需要的  GenericRecord流</span></span><br><span class="line">SingleOutputStreamOperator&lt;GenericRecord&gt; recordStream = streamSource</span><br><span class="line">        .map((MapFunction&lt;EventLog, GenericRecord&gt;) eventLog -&gt; &#123;</span><br><span class="line">            <span class="comment">// 构造一个Record对象</span></span><br><span class="line">            GenericData.<span class="type">Record</span> <span class="variable">record</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">GenericData</span>.Record(schema);</span><br><span class="line"> </span><br><span class="line">            <span class="comment">// 将数据填入record</span></span><br><span class="line">            record.put(<span class="string">&quot;gid&quot;</span>, (<span class="type">int</span>) eventLog.getGuid());</span><br><span class="line">            record.put(<span class="string">&quot;eventId&quot;</span>, eventLog.getEventId());</span><br><span class="line">            record.put(<span class="string">&quot;ts&quot;</span>, eventLog.getTimeStamp());</span><br><span class="line">            record.put(<span class="string">&quot;sessionId&quot;</span>, eventLog.getSessionId());</span><br><span class="line">            record.put(<span class="string">&quot;eventInfo&quot;</span>, eventLog.getEventInfo());</span><br><span class="line"> </span><br><span class="line">            <span class="keyword">return</span> record;</span><br><span class="line">        &#125;).returns(<span class="keyword">new</span> <span class="title class_">GenericRecordAvroTypeInfo</span>(schema));  <span class="comment">// 由于avro的相关类、对象需要用avro的序列化器，所以需要显式指定AvroTypeInfo来提供AvroSerializer</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">// 5. 输出数据</span></span><br><span class="line">recordStream.sinkTo(sink1).uid(<span class="string">&quot;fileSink&quot;</span>);</span><br><span class="line"> </span><br><span class="line">env.execute();</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- 传入特定JavaBean类class，它就能通过调用传入的类上的特定方法，来获得Schema对象</span><br><span class="line">- 传入普通JavaBean,然后工具可以自己通过反射手段来获取用户的普通JavaBean中的包名、类名、字段名、字段类型等信息，来翻译成一个符合Avro要求的Schema。</span><br></pre></td></tr></table></figure>

<ul>
<li>3-桶分配策略<ul>
<li>FileSink使用BucketAssigner来确定每条输入的数据应该被放入哪个Bucket，默认情况下，DateTimeBucketAssigner 基于系统默认时区每小时创建一个桶。</li>
<li>Flink 有两个内置的 BucketAssigners ：<ul>
<li>DateTimeBucketAssigner：默认基于时间的分配器</li>
<li>BasePathBucketAssigner：将所有部分文件（part file）存储在基本路径中的分配器（单个全局桶）</li>
</ul>
</li>
</ul>
</li>
<li>4-滚动策略<ul>
<li>滚动策略 RollingPolicy 定义了指定的文件在何时关闭（closed）并将其变为 Pending 状态，随后变为 Finished 状态。处于 Pending 状态的文件会在下一次 Checkpoint 时变为 Finished 状态，通过设置 Checkpoint 间隔时间，可以控制部分文件（part file）对下游读取者可用的速度、大小和数量。</li>
<li>Flink 有两个内置的滚动策略：<ul>
<li>DefaultRollingPolicy</li>
<li>OnCheckpointRollingPolicy</li>
</ul>
</li>
<li>注意：使用Bulk Encoding时，文件滚动就只能使用OnCheckpointRollingPolicy的策略，该策略在每次checkpoint时滚动part-file。</li>
</ul>
</li>
</ul>
</blockquote>
<p>文件合并：</p>
<p>在 Flink1.15 之后为了快速滚动，并且避免小文件的操作，添加了 compact 功能，可以在 checkpoint 的时候进行合并。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">FileSink&lt;Integer&gt; fileSink=</span><br><span class="line">        FileSink.forRowFormat(<span class="keyword">new</span> <span class="title class_">Path</span>(path),<span class="keyword">new</span> <span class="title class_">SimpleStringEncoder</span>&lt;Integer&gt;())</span><br><span class="line">                .enableCompact(</span><br><span class="line">                        FileCompactStrategy.Builder.newBuilder()</span><br><span class="line">                                .setNumCompactThreads(<span class="number">1024</span>)</span><br><span class="line">                                .enableCompactionOnCheckpoint(<span class="number">5</span>)</span><br><span class="line">                                .build(),</span><br><span class="line">                        <span class="keyword">new</span> <span class="title class_">RecordWiseFileCompactor</span>&lt;&gt;(</span><br><span class="line">                                <span class="keyword">new</span> <span class="title class_">DecoderBasedReader</span>.Factory&lt;&gt;(SimpleStringDecoder::<span class="keyword">new</span>)))</span><br><span class="line">                .build();</span><br></pre></td></tr></table></figure>

<blockquote>
<ul>
<li>参数设置<ul>
<li>setNumcCompactThreads：设置合并的线程数</li>
<li>setSizeThreshold：设置大小的阈值（小于这个大小的会被合并）</li>
<li>enableCompactionOnCheckpoint：多少个 checkpoint 信号来了，会进行一次 compact</li>
<li>如果开启了 Compaction，那么必须在 source.sinkTo(fileSink)的时候添加 uid：source.sinkTo(fileSink).uid(“fileSink”);</li>
</ul>
</li>
</ul>
</blockquote>
<h2 id="KafkaSink"><a href="#KafkaSink" class="headerlink" title="KafkaSink"></a>KafkaSink</h2><p>Flink 与 Kafka 的连接器提供了端到端的精确一次（exactly once）语义保证，这在实际项目中是最高级别的一致性保证。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. 构造一个kafka的sink算子</span></span><br><span class="line">KafkaSink&lt;String&gt; kafkaSink = KafkaSink.&lt;String&gt;builder()</span><br><span class="line">        .setBootstrapServers(<span class="string">&quot;node1.itcast.cn:9092,node2.itcast.cn:9092&quot;</span>)</span><br><span class="line">        .setRecordSerializer(KafkaRecordSerializationSchema.&lt;String&gt;builder()</span><br><span class="line">                .setTopic(<span class="string">&quot;event-log&quot;</span>)</span><br><span class="line">                .setValueSerializationSchema(<span class="keyword">new</span> <span class="title class_">SimpleStringSchema</span>())</span><br><span class="line">                .build()</span><br><span class="line">        )</span><br><span class="line">        .setDeliverGuarantee(DeliveryGuarantee.AT_LEAST_ONCE)</span><br><span class="line">        .build();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 把数据流输出到构造好的sink算子</span></span><br><span class="line">streamSource</span><br><span class="line">        .map(JSON::toJSONString).disableChaining()</span><br><span class="line">        .sinkTo(kafkaSink);</span><br><span class="line"></span><br><span class="line">env.execute();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果使用DeliveryGuarantee.EXACTLY_ONCE 的语义保证，则需要使用 setTransactionalIdPrefix(String)，如：</span></span><br><span class="line"><span class="comment">// .setDeliveryGuarantee(DeliveryGuarantee.EXACTLY_ONCE)</span></span><br><span class="line"><span class="comment">// .setTransactionalIdPrefix(&quot;itcast-&quot; + RandomUtils.nextInt(1, 100))</span></span><br><span class="line"><span class="comment">// .setProperty(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG , &quot;36000&quot;)</span></span><br></pre></td></tr></table></figure>

<h2 id="JDBCSink"><a href="#JDBCSink" class="headerlink" title="JDBCSink"></a>JDBCSink</h2><ul>
<li>不保证Exactly-Once</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">SinkFunction&lt;EventLog&gt; jdbcSink = JdbcSink.sink(</span><br><span class="line">        <span class="string">&quot;insert into t_eventlog values (?,?,?,?,?) on duplicate key update sessionId=?,eventId=?,ts=?,eventInfo=? &quot;</span>,</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">JdbcStatementBuilder</span>&lt;EventLog&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">accept</span><span class="params">(PreparedStatement preparedStatement, EventLog eventLog)</span> <span class="keyword">throws</span> SQLException &#123;</span><br><span class="line">                preparedStatement.setLong(<span class="number">1</span>, eventLog.getGuid());</span><br><span class="line">                preparedStatement.setString(<span class="number">2</span>, eventLog.getSessionId());</span><br><span class="line">                preparedStatement.setString(<span class="number">3</span>, eventLog.getEventId());</span><br><span class="line">                preparedStatement.setLong(<span class="number">4</span>, eventLog.getTimeStamp());</span><br><span class="line">                preparedStatement.setString(<span class="number">5</span>, JSON.toJSONString(eventLog.getEventInfo()));</span><br><span class="line"></span><br><span class="line">                preparedStatement.setString(<span class="number">6</span>, eventLog.getSessionId());</span><br><span class="line">                preparedStatement.setString(<span class="number">7</span>, eventLog.getEventId());</span><br><span class="line">                preparedStatement.setLong(<span class="number">8</span>, eventLog.getTimeStamp());</span><br><span class="line">                preparedStatement.setString(<span class="number">9</span>, JSON.toJSONString(eventLog.getEventInfo()));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        JdbcExecutionOptions.builder()</span><br><span class="line">                .withMaxRetries(<span class="number">3</span>)</span><br><span class="line">                .withBatchSize(<span class="number">1</span>)</span><br><span class="line">                .build(),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">JdbcConnectionOptions</span>.JdbcConnectionOptionsBuilder()</span><br><span class="line">                .withUrl(<span class="string">&quot;jdbc:mysql://node1:3306/test?serverTimezone=Asia/Shanghai&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;</span>)</span><br><span class="line">                .withUsername(<span class="string">&quot;root&quot;</span>)</span><br><span class="line">                .withPassword(<span class="string">&quot;123456&quot;</span>)</span><br><span class="line">                .build()</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出数据</span></span><br><span class="line">streamSource.addSink(jdbcSink);</span><br><span class="line"></span><br><span class="line">env.execute();</span><br></pre></td></tr></table></figure>

<ul>
<li>保证Exactly-Once</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">SinkFunction&lt;EventLog&gt; exactlyOnceSink = JdbcSink.exactlyOnceSink(</span><br><span class="line">        <span class="string">&quot;insert into t_eventlog values (?,?,?,?,?) on duplicate key update           sessionId=?,eventId=?,ts=?,eventInfo=? &quot;</span>,</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">JdbcStatementBuilder</span>&lt;EventLog&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">accept</span><span class="params">(PreparedStatement preparedStatement, EventLog eventLog)</span> <span class="keyword">throws</span> SQLException &#123;</span><br><span class="line">                preparedStatement.setLong(<span class="number">1</span>, eventLog.getGuid());</span><br><span class="line">                preparedStatement.setString(<span class="number">2</span>, eventLog.getSessionId());</span><br><span class="line">                preparedStatement.setString(<span class="number">3</span>, eventLog.getEventId());</span><br><span class="line">                preparedStatement.setLong(<span class="number">4</span>, eventLog.getTimeStamp());</span><br><span class="line">                preparedStatement.setString(<span class="number">5</span>, JSON.toJSONString(eventLog.getEventInfo()));</span><br><span class="line"></span><br><span class="line">                preparedStatement.setString(<span class="number">6</span>, eventLog.getSessionId());</span><br><span class="line">                preparedStatement.setString(<span class="number">7</span>, eventLog.getEventId());</span><br><span class="line">                preparedStatement.setLong(<span class="number">8</span>, eventLog.getTimeStamp());</span><br><span class="line">                preparedStatement.setString(<span class="number">9</span>, JSON.toJSONString(eventLog.getEventInfo()));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        JdbcExecutionOptions.builder()</span><br><span class="line">                .withMaxRetries(<span class="number">3</span>)</span><br><span class="line">                .withBatchSize(<span class="number">1</span>)</span><br><span class="line">                .build(),</span><br><span class="line">        JdbcExactlyOnceOptions.builder()</span><br><span class="line">                <span class="comment">// mysql不支持同一个连接上存在并行的多个事务，必须把该参数设置为true</span></span><br><span class="line">                .withTransactionPerConnection(<span class="literal">true</span>)</span><br><span class="line">                .build(),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">SerializableSupplier</span>&lt;XADataSource&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> XADataSource <span class="title function_">get</span><span class="params">()</span> &#123;</span><br><span class="line">                <span class="comment">// XADataSource就是jdbc连接，不过它是支持分布式事务的连接</span></span><br><span class="line">                <span class="comment">// 而且它的构造方法，不同的数据库构造方法不同</span></span><br><span class="line">                <span class="type">MysqlXADataSource</span> <span class="variable">xaDataSource</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MysqlXADataSource</span>();</span><br><span class="line">                xaDataSource.setUrl(<span class="string">&quot;jdbc:mysql://node1:3306/test?serverTimezone=Asia/Shanghai&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;</span>);</span><br><span class="line">                xaDataSource.setUser(<span class="string">&quot;root&quot;</span>);</span><br><span class="line">                xaDataSource.setPassword(<span class="string">&quot;123456&quot;</span>);</span><br><span class="line">                <span class="keyword">return</span> xaDataSource;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出数据</span></span><br><span class="line">streamSource.addSink(exactlyOnceSink);</span><br><span class="line"></span><br><span class="line">env.execute();</span><br></pre></td></tr></table></figure>

















</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="https://github.com/weiswift">Johnson Liam</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://github.com/weiswift/2023/09/07/2023.09.07/">https://github.com/weiswift/2023/09/07/2023.09.07/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Java/">Java</a><a class="post-meta__tags" href="/tags/Flink/">Flink</a></div><div class="post_share"><div class="social-share" data-image="https://wei-blog.oss-cn-beijing.aliyuncs.com/img/pic.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> Donate</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/09/08/2023.09.08/" title="【Flink】FlinkSQL及Flink四大基石"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">【Flink】FlinkSQL及Flink四大基石</div></div></a></div><div class="next-post pull-right"><a href="/2023/09/06/2023.09.06/" title="【Flink】Flink作业提交流程及Java编程模型之WordCount"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">【Flink】Flink作业提交流程及Java编程模型之WordCount</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2023/09/06/2023.09.06/" title="【Flink】Flink作业提交流程及Java编程模型之WordCount"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-06</div><div class="title">【Flink】Flink作业提交流程及Java编程模型之WordCount</div></div></a></div><div><a href="/2023/09/08/2023.09.08/" title="【Flink】FlinkSQL及Flink四大基石"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-08</div><div class="title">【Flink】FlinkSQL及Flink四大基石</div></div></a></div><div><a href="/2023/09/11/2023.09.11/" title="【Flink】Flink水印机制与快照机制"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-11</div><div class="title">【Flink】Flink水印机制与快照机制</div></div></a></div><div><a href="/2023/09/12/2023.09.12/" title="【Flink】FlinkSQL| 状态编程| 自定义函数"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-12</div><div class="title">【Flink】FlinkSQL| 状态编程| 自定义函数</div></div></a></div><div><a href="/2023/05/03/2023.04.24/" title="Java基础复习（上）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-03</div><div class="title">Java基础复习（上）</div></div></a></div><div><a href="/2023/05/03/2023.04.27/" title="Java面向对象"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-03</div><div class="title">Java面向对象</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/img/pic.webp" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Johnson Liam</div><div class="author-info__description">机器都在学习,你有什么理由不学习?</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">222</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">58</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><a id="card-info-btn" href="https://github.com/weiswift/"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/weiswift" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:1265019024@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">网站由Github服务器托管,感谢支持！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83"><span class="toc-number">1.</span> <span class="toc-text">运行环境</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%B9%E5%A4%84%E7%90%86"><span class="toc-number">1.1.</span> <span class="toc-text">批处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B5%81%E5%A4%84%E7%90%86"><span class="toc-number">1.2.</span> <span class="toc-text">流处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B5%81%E6%89%B9%E4%B8%80%E4%BD%93"><span class="toc-number">1.3.</span> <span class="toc-text">流批一体</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%AC%E5%9C%B0%E7%8E%AF%E5%A2%83"><span class="toc-number">1.4.</span> <span class="toc-text">本地环境</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%A6%E6%9C%89WebUI%E7%9A%84%E6%9C%AC%E5%9C%B0%E7%8E%AF%E5%A2%83"><span class="toc-number">1.5.</span> <span class="toc-text">带有WebUI的本地环境</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="toc-number">2.</span> <span class="toc-text">执行模式</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%BC%8F%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%B9%E6%B3%95"><span class="toc-number">2.1.</span> <span class="toc-text">执行模式的配置方法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%BE%93%E5%85%A5%E7%AE%97%E5%AD%90Source"><span class="toc-number">3.</span> <span class="toc-text">输入算子Source</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BE%93%E5%85%A5%E7%AE%97%E5%AD%90%E6%80%BB%E7%BB%93Summary"><span class="toc-number">3.1.</span> <span class="toc-text">输入算子总结Summary</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Example"><span class="toc-number">3.2.</span> <span class="toc-text">Example</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E9%9B%86%E5%90%88%E7%9A%84Source"><span class="toc-number">3.3.</span> <span class="toc-text">基于集合的Source</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8ESocket%E7%9A%84Source"><span class="toc-number">3.4.</span> <span class="toc-text">基于Socket的Source</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E6%96%87%E4%BB%B6%E7%9A%84Source"><span class="toc-number">3.5.</span> <span class="toc-text">基于文件的Source</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E6%96%B9-Source-Kafka%E4%B8%BE%E4%BE%8B"><span class="toc-number">3.6.</span> <span class="toc-text">第三方 Source(Kafka举例)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#CodeDemo"><span class="toc-number">3.6.1.</span> <span class="toc-text">CodeDemo</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89Source-MySQL%E4%B8%BE%E4%BE%8B"><span class="toc-number">3.7.</span> <span class="toc-text">自定义Source(MySQL举例)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#CodeDemo-1"><span class="toc-number">3.7.1.</span> <span class="toc-text">CodeDemo</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90Transformation"><span class="toc-number">4.</span> <span class="toc-text">转换算子Transformation</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90"><span class="toc-number">4.1.</span> <span class="toc-text">转换算子</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#map%E6%98%A0%E5%B0%84%EF%BC%9ADataStream%E2%86%92DataStream"><span class="toc-number">4.2.</span> <span class="toc-text">map映射：DataStream→DataStream</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#flatmap%E6%89%81%E5%B9%B3%E5%8C%96%E6%98%A0%E5%B0%84%EF%BC%9ADataStream%E2%86%92DataStream"><span class="toc-number">4.3.</span> <span class="toc-text">flatmap扁平化映射：DataStream→DataStream</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#filter%E8%BF%87%E6%BB%A4%EF%BC%9ADataStream%E2%86%92DataStream"><span class="toc-number">4.4.</span> <span class="toc-text">filter过滤：DataStream→DataStream</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#keyBy%E6%8C%89key%E5%88%86%E7%BB%84%EF%BC%9ADataStream%E2%86%92KeyedStream"><span class="toc-number">4.5.</span> <span class="toc-text">keyBy按key分组：DataStream→KeyedStream</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%80%E5%8D%95%E8%81%9A%E5%90%88%EF%BC%9AKeyedStream%E2%86%92DataStream"><span class="toc-number">4.6.</span> <span class="toc-text">简单聚合：KeyedStream→DataStream</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#reduce%E5%BD%92%E7%BA%A6%EF%BC%9AKeyedStream%E2%86%92DataSream"><span class="toc-number">4.7.</span> <span class="toc-text">reduce归约：KeyedStream→DataSream</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90Operator"><span class="toc-number">4.8.</span> <span class="toc-text">转换算子Operator</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%89%A9%E7%90%86%E5%88%86%E5%8C%BA"><span class="toc-number">5.</span> <span class="toc-text">物理分区</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#GLOBAL%E5%88%86%E5%8C%BA"><span class="toc-number">5.1.</span> <span class="toc-text">GLOBAL分区</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#FORWARD%E5%88%86%E5%8C%BA"><span class="toc-number">5.2.</span> <span class="toc-text">FORWARD分区</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BROADCAST%E5%88%86%E5%8C%BA"><span class="toc-number">5.3.</span> <span class="toc-text">BROADCAST分区</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SHUFFLE%E5%88%86%E5%8C%BA"><span class="toc-number">5.4.</span> <span class="toc-text">SHUFFLE分区</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#REBALANCE%E5%88%86%E5%8C%BA"><span class="toc-number">5.5.</span> <span class="toc-text">REBALANCE分区</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CUSTOM%E5%88%86%E5%8C%BA"><span class="toc-number">5.6.</span> <span class="toc-text">CUSTOM分区</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Demo"><span class="toc-number">5.7.</span> <span class="toc-text">Demo</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%BE%93%E5%87%BA%E7%AE%97%E5%AD%90Sink"><span class="toc-number">6.</span> <span class="toc-text">输出算子Sink</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#FileSink"><span class="toc-number">6.1.</span> <span class="toc-text">FileSink</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KafkaSink"><span class="toc-number">6.2.</span> <span class="toc-text">KafkaSink</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#JDBCSink"><span class="toc-number">6.3.</span> <span class="toc-text">JDBCSink</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/06/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" title="机器学习"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250605114200229.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="机器学习"/></a><div class="content"><a class="title" href="/2025/06/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" title="机器学习">机器学习</a><time datetime="2025-06-03T16:00:00.000Z" title="Created 2025-06-04 00:00:00">2025-06-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/03/2025.06.03/" title="OLLAMA"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250603132906789.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="OLLAMA"/></a><div class="content"><a class="title" href="/2025/06/03/2025.06.03/" title="OLLAMA">OLLAMA</a><time datetime="2025-06-02T16:00:00.000Z" title="Created 2025-06-03 00:00:00">2025-06-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/05/10/2025.05.10/" title="Mozi病毒样本分析"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250604210840482.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Mozi病毒样本分析"/></a><div class="content"><a class="title" href="/2025/05/10/2025.05.10/" title="Mozi病毒样本分析">Mozi病毒样本分析</a><time datetime="2025-05-09T16:00:00.000Z" title="Created 2025-05-10 00:00:00">2025-05-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/04/28/2025.04.28/" title="P2P通信"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250604211011599.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="P2P通信"/></a><div class="content"><a class="title" href="/2025/04/28/2025.04.28/" title="P2P通信">P2P通信</a><time datetime="2025-04-27T16:00:00.000Z" title="Created 2025-04-28 00:00:00">2025-04-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/03/21/2025.03.21/" title="记录一次磁盘坏掉排查过程"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250604203833317.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="记录一次磁盘坏掉排查过程"/></a><div class="content"><a class="title" href="/2025/03/21/2025.03.21/" title="记录一次磁盘坏掉排查过程">记录一次磁盘坏掉排查过程</a><time datetime="2025-03-20T16:00:00.000Z" title="Created 2025-03-21 00:00:00">2025-03-21</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Johnson Liam</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Welcome to 小威の <a target="_blank" rel="noopener" href="https://www.cnblogs.com/liam-sliversucks/">Blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><canvas class="fireworks" mobile="true"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="true"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>