<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Fine-Tuning | All wisdom begins with memory.</title><meta name="author" content="李俊泽"><meta name="copyright" content="李俊泽"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="P01_大模型微调的主要方式【掌握】1、大模型Prompt-Tuning方法1.1 NLP任务四种范式 第一范式：基于传统机器学习模型 第二范式：基于深度学习 第三范式：基于预训练模型+fine-tuning 第四范式：预训练模型+Prompt+预测  1.2 Fine-Tuning(微调)Fine"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://liamjohnson-w.github.io/2025/11/02/Fine-Tuning/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Fine-Tuning',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-11-02 00:31:54'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"> <script src="/live2d-widget/autoload.js"></script><script src="/live2d-widget/autoload.js"> </script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/tx.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">240</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">58</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Links</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-gamepad"></i><span> Games</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/mikutap/"><i class="fa-fw fa fa-music"></i><span> MikuTap 初音未来</span></a></li><li><a class="site-page child" href="/starbattle/"><i class="fa-fw fa fa-space-shuttle"></i><span> StartBattle 星际大战</span></a></li><li><a class="site-page child" href="/2048/"><i class="fa-fw fa fa-flag"></i><span> 2048 经典游戏</span></a></li><li><a class="site-page child" href="/battlecity/"><i class="fa-fw fa fa-arrow-circle-left"></i><span> BattleCity 坦克大战</span></a></li><li><a class="site-page child" href="/pacman/"><i class="fa-fw fa fa-bolt"></i><span> PacMan  吃豆人</span></a></li><li><a class="site-page child" href="/tetris/"><i class="fa-fw fa fa-arrows-alt"></i><span> Tetris 俄罗斯方块</span></a></li><li><a class="site-page child" href="/smallcat/"><i class="fa-fw fa fa-paw"></i><span> CatchCat 困住小猫</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-leaf"></i><span> Moments</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/diary/"><i class="fa-fw fas fa-bookmark"></i><span> Diary</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fa fa-hourglass-half"></i><span> Gallery</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-podcast"></i><span> More</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags标签</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About关于</span></a></li><li><a class="site-page child" href="/messageboard/"><i class="fa-fw fas fa-bookmark"></i><span> Messageboard留言板</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/cat111.png')"><nav id="nav"><span id="blog-info"><a href="/" title="All wisdom begins with memory."><span class="site-name">All wisdom begins with memory.</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Links</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-gamepad"></i><span> Games</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/mikutap/"><i class="fa-fw fa fa-music"></i><span> MikuTap 初音未来</span></a></li><li><a class="site-page child" href="/starbattle/"><i class="fa-fw fa fa-space-shuttle"></i><span> StartBattle 星际大战</span></a></li><li><a class="site-page child" href="/2048/"><i class="fa-fw fa fa-flag"></i><span> 2048 经典游戏</span></a></li><li><a class="site-page child" href="/battlecity/"><i class="fa-fw fa fa-arrow-circle-left"></i><span> BattleCity 坦克大战</span></a></li><li><a class="site-page child" href="/pacman/"><i class="fa-fw fa fa-bolt"></i><span> PacMan  吃豆人</span></a></li><li><a class="site-page child" href="/tetris/"><i class="fa-fw fa fa-arrows-alt"></i><span> Tetris 俄罗斯方块</span></a></li><li><a class="site-page child" href="/smallcat/"><i class="fa-fw fa fa-paw"></i><span> CatchCat 困住小猫</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-leaf"></i><span> Moments</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/diary/"><i class="fa-fw fas fa-bookmark"></i><span> Diary</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fa fa-hourglass-half"></i><span> Gallery</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-podcast"></i><span> More</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags标签</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About关于</span></a></li><li><a class="site-page child" href="/messageboard/"><i class="fa-fw fas fa-bookmark"></i><span> Messageboard留言板</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Fine-Tuning</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-11-01T16:00:00.000Z" title="Created 2025-11-02 00:00:00">2025-11-02</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-11-01T16:31:54.441Z" title="Updated 2025-11-02 00:31:54">2025-11-02</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Fine-Tuning"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="P01-大模型微调的主要方式【掌握】"><a href="#P01-大模型微调的主要方式【掌握】" class="headerlink" title="P01_大模型微调的主要方式【掌握】"></a>P01_大模型微调的主要方式【掌握】</h1><h2 id="1、大模型Prompt-Tuning方法"><a href="#1、大模型Prompt-Tuning方法" class="headerlink" title="1、大模型Prompt-Tuning方法"></a>1、大模型Prompt-Tuning方法</h2><h3 id="1-1-NLP任务四种范式"><a href="#1-1-NLP任务四种范式" class="headerlink" title="1.1 NLP任务四种范式"></a>1.1 NLP任务四种范式</h3><ul>
<li>第一范式：基于传统机器学习模型</li>
<li>第二范式：基于深度学习</li>
<li>第三范式：基于预训练模型+fine-tuning</li>
<li>第四范式：预训练模型+Prompt+预测</li>
</ul>
<h3 id="1-2-Fine-Tuning-微调"><a href="#1-2-Fine-Tuning-微调" class="headerlink" title="1.2 Fine-Tuning(微调)"></a>1.2 Fine-Tuning(微调)</h3><p>Fine-Tuning基本思想：使用小规模的特定任务文本继续训练预训练语言模型。</p>
<p>Fine-Tuning问题：</p>
<ul>
<li>所需的Fine-Tuning量取决于预训练语料库和任务特定语料库之间的相似性。如果两者相似，可能只需要少量的Fine-Tuning，如果两者不相似，则可能需要更多的Fine-Tuning，并且效果不明显。</li>
<li>成本高</li>
</ul>
<p>Prompt-Tuning的基本思想：通过添加模板的方法将任务目标转化为与预训练目标相似的形式（如MLM），避免引入额外的参数的同时，最大化利用模型的预训练知识。</p>
<p>Prompt-Tuning主要解决传统Fine-Tuning方式的两个痛点：</p>
<ul>
<li>**降低语义偏差：**预训练任务主要以MLM为主，而下游任务则重新引入新的训练参数，因此两个阶段目标差异较大。因此需要解决Pre-Training和Fine-Tuning之间的Gap。</li>
<li>**避免过拟合：**由于Fine-Tuning阶段需要引入新的参数适配相应任务，因此在样本数量有限的情况下容易发生过拟合，降低模型泛化能力。因此需要解决预训练模型的过拟合能力。</li>
</ul>
<h3 id="1-3-Prompt-Tuning-提示微调"><a href="#1-3-Prompt-Tuning-提示微调" class="headerlink" title="1.3 Prompt-Tuning(提示微调)"></a>1.3 Prompt-Tuning(提示微调)</h3><p>（1）什么是Prompt?</p>
<p>即提示词</p>
<p>（2）Prompt-Tuing的本质</p>
<p>Fine-Tuning的本质：&#x3D;&#x3D;调整预训练模型，让预训练模型去迁就下游任务。&#x3D;&#x3D;</p>
<p>Prompt-Tuing的本质：&#x3D;&#x3D;让下游任务去迁就预训练模型，将Fine-tuning的下游任务目标转换为Pre-training的任务。&#x3D;&#x3D;</p>
<p>（3）Fine-Tuning和Prompt-Tuing对比</p>
<table>
<thead>
<tr>
<th>特征</th>
<th>Fine-tuning (模型迁就任务)</th>
<th>Prompt Tuning (任务迁就模型)</th>
</tr>
</thead>
<tbody><tr>
<td><strong>核心操作</strong></td>
<td><strong>修改</strong>预训练模型的参数，使其适应下游任务的数据和目标</td>
<td>调整少量参数（如软提示向量）或仅依赖输入设计（提示工程）</td>
</tr>
<tr>
<td><strong>模型状态</strong></td>
<td><strong>发生变化</strong>，学习新的特定任务知识</td>
<td><strong>保持不变</strong>，利用已有的通用知识</td>
</tr>
<tr>
<td><strong>任务目标</strong></td>
<td>直接学习下游任务的特定目标函数</td>
<td>将下游任务目标<strong>重构</strong>为预训练模型更擅长的形式（如生成、补全）</td>
</tr>
<tr>
<td><strong>资源消耗</strong></td>
<td>通常需要<strong>大量计算资源</strong>进行训练，为每个任务存储一个模型副本</td>
<td><strong>计算资源消耗极少</strong>，只需存储和处理 Prompt</td>
</tr>
<tr>
<td><strong>目的</strong></td>
<td><strong>深度适应</strong>特定任务，可能牺牲通用性，但通常性能上限高</td>
<td><strong>高效利用</strong>预训练模型的通用能力，在资源有限时效果显著，泛化性好</td>
</tr>
</tbody></table>
<h3 id="1-4-Prompt-Tuning技术发展历程"><a href="#1-4-Prompt-Tuning技术发展历程" class="headerlink" title="1.4 Prompt-Tuning技术发展历程"></a>1.4 Prompt-Tuning技术发展历程</h3><p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/1-3-8.png" alt="1-3-8"></p>
<h3 id="1-5-面向超大规模语言模型的Prompt-Tuning"><a href="#1-5-面向超大规模语言模型的Prompt-Tuning" class="headerlink" title="1.5 面向超大规模语言模型的Prompt-Tuning"></a>1.5 面向超大规模语言模型的Prompt-Tuning</h3><p>特点：模型的 <strong>参数量足够大</strong>，训练过程中使用了<strong>足够多的语料</strong>，同时设计的<strong>预训练任务足够有效</strong>。</p>
<p>效果：只需要设计合适的模板或指令即可以<strong>实现免参数训练的零样本学习</strong> 。</p>
<p>类型：</p>
<ul>
<li>In-Context Learning（上下文学习）：通过上下文示例（demonstrations）让模型理解任务，而<strong>无需显式训练</strong>。</li>
<li>Instruction-Tuning（指令微调）：在已有的预训练语言模型基础上，收集大量的成对数据（指令，期望输出），对模型进行额外的<strong>监督微调</strong>，让它学会遵循人类自然语言指令完成任务。</li>
<li>Chain-of-Thought（思维链）：一种改进的提示策略，用于提高 LLM 在复杂推理任务中的性能。<strong>方法就是相比于之前的上下文学习多了中间的推导过程提示。</strong></li>
</ul>
<h3 id="1-6-面向小规模语言模型的Prompt-Tuning"><a href="#1-6-面向小规模语言模型的Prompt-Tuning" class="headerlink" title="1.6 面向小规模语言模型的Prompt-Tuning"></a>1.6 面向小规模语言模型的Prompt-Tuning</h3><h4 id="1-6-1-Prompt-Tuning的鼻祖—PET模型"><a href="#1-6-1-Prompt-Tuning的鼻祖—PET模型" class="headerlink" title="1.6.1 Prompt-Tuning的鼻祖—PET模型"></a>1.6.1 Prompt-Tuning的鼻祖—PET模型</h4><p>（1）PET模型的核心思想：&#x3D;&#x3D;将下游任务重构为预训练模型最熟悉的“完形填空”问题，从而利用语言模型对文本的理解能力，最终通过少量示例训练获得较好的下游性能。&#x3D;&#x3D;</p>
<p>（2）方法：通过设计自然语言模式（pattern）和标签词映射（verbalizer），将输入句子转换为带有[MASK]位置的文本，例如“这个电影很[MASK]。”，然后用预训练语言模型（如BERT）预测[MASK]位置的词，再通过verbalizer转换来完成分类任务。</p>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250814224811173.png" alt="image-20250814224811173"></p>
<p>（3）PVP组件</p>
<ul>
<li><strong>Pattern（Template）</strong> ：记作T，为额外添加的带有<code>[mask]</code>标记的短文本，用于引出不同任务的预测词。</li>
<li><strong>Verbalizer</strong> ：记作V, 即标签词的映射，对于具体的分类任务，需要选择指定的标签词（label word）。</li>
</ul>
<p>（4）人工设计PVP的缺陷</p>
<ul>
<li>采用人工构建的方法成本高，需要与领域任务相关的先验知识</li>
<li>人工设计的Pattern和Verbalizer不能保证获得最优解，训练不稳定，不同的PVP对结果产生的差异明显，方差大</li>
<li>人工构建的Pattern和Verbalizer使得Prompt-Tuning与MLM在语义和分布上依然存在差异</li>
</ul>
<h4 id="1-6-2-Prompt-Oriented-Fine-Tuning"><a href="#1-6-2-Prompt-Oriented-Fine-Tuning" class="headerlink" title="1.6.2 Prompt-Oriented Fine-Tuning"></a>1.6.2 Prompt-Oriented Fine-Tuning</h4><p>（1）本质：<strong>本将目标任务转换为适应预训练模型的预训练任务，以适应预训练模型的学习体系。</strong></p>
<p>（2）类型</p>
<p>根据提示的类型不同，POFT方法主要分成三种类型：</p>
<ul>
<li>离散提示：也叫硬模版，其提示是由真实的自然语言单词或符号组成，直接拼接到输入中。</li>
<li>连续提示：&#x3D;&#x3D;也叫软模板，提示不是实际的单词，而是<strong>可训练的向量</strong>，插入到输入 embedding 序列中。&#x3D;&#x3D;</li>
<li>混合提示：同时使用<strong>人工可读的离散 token</strong>和<strong>可训练的连续向量</strong>。</li>
</ul>
<p>按照训练时参数更新的范围不同，POFT方法主要分成三种类型：</p>
<ul>
<li>全量微调（Full Fine-Tuning）：模型所有参数都参与更新，包括预训练模型参数和下游任务层参数。如PET模型。</li>
<li>部分参数微调（Partial Fine-Tuning）：只更新预训练模型中的一部分参数，比如高层 transformer block、某些 attention 层或特定模块，其余参数冻结。如Adapter Tuning。</li>
<li>仅提示参数微调（Prompt-Only Tuning）：&#x3D;&#x3D;冻结原始预训练模型参数，只训练 prompt 参数。如P-tuning、Prompt Tuning等&#x3D;&#x3D;。</li>
</ul>
<p>（3）PET中使用的POFT：&#x3D;&#x3D;硬模板+ 全量微调&#x3D;&#x3D;</p>
<p>全量微调：成本高，要求数据量大</p>
<p>硬模版：人工构建成本高、不同PVP对结果产生的差异明显、与MLM训练任务不完全一致</p>
<h4 id="1-6-3-Soft-Prompt及微调方法"><a href="#1-6-3-Soft-Prompt及微调方法" class="headerlink" title="1.6.3 Soft Prompt及微调方法"></a>1.6.3 Soft Prompt及微调方法</h4><h5 id="1-6-3-1-连续提示模板"><a href="#1-6-3-1-连续提示模板" class="headerlink" title="1.6.3.1 连续提示模板"></a>1.6.3.1 连续提示模板</h5><p>Soft Prompt (连续提示) ：是指通过给模型输入一个可参数化的提示模板，从而引导模型生成符合特定要求的文本。</p>
<p>特点：</p>
<ul>
<li>将模板变为可训练的参数，不同的样本可以在连续的向量空间中寻找合适的伪标记，同时也增加模型的泛化能力。</li>
<li>连续法需要引入少量的参数并在训练时进行参数更新，但预训练模型参数是不变的，变的是prompt token对应的词向量（Word Embedding）表征及其他引入的少量参数。</li>
</ul>
<h5 id="1-6-3-2-Prompt-Tuning（NLG任务）"><a href="#1-6-3-2-Prompt-Tuning（NLG任务）" class="headerlink" title="1.6.3.2 Prompt Tuning（NLG任务）"></a>1.6.3.2 Prompt Tuning（NLG任务）</h5><p>（1）方法：为每一个输入文本假设一个固定前缀提示，该提示表由神经网络参数化，并在下游任务微调时进行更新，整个过程中预训练的大模型参数被冻结。</p>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250818154810642.png" alt="image-20250818154810642"></p>
<p>（2）特点</p>
<ul>
<li>优点：<ul>
<li>大模型的微调新范式</li>
<li>模型参数规模大了之后，可以将大模型参数固定，指定附加参数来适配下游任务，而且适配性能基本和全参数微调相当。</li>
</ul>
</li>
<li>缺点：<ul>
<li>在小样本学习场景上表现不太行</li>
<li>收敛速度比较慢</li>
<li>调参比较复杂</li>
</ul>
</li>
</ul>
<h5 id="1-6-3-3-P-tuning（NLU任务）"><a href="#1-6-3-3-P-tuning（NLU任务）" class="headerlink" title="1.6.3.3 P-tuning（NLU任务）"></a>1.6.3.3 P-tuning（NLU任务）</h5><p>（1）P-tuning 的核心思想是：用一个小的可训练模块把一组“连续提示向量”生成并插入到原始输入 embedding 中，令<strong>冻结的预训练模型</strong>在下游任务上产生正确输出，训练时仅更新 prompt encoder（或提示向量），从而实现低成本高效的调优。</p>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250818163852423.png" alt="image-20250818163852423"></p>
<p>（2）<strong>P-tuning的特点</strong>：</p>
<ul>
<li>优点：<ul>
<li>引入了一个 LSTM +MLP模块对 soft prompt 进行建模，能捕捉 token 之间的顺序和语义关系</li>
<li>改进了离散 prompt的不稳定性问题，收敛速度更快</li>
</ul>
</li>
<li>缺点<ul>
<li>仅放在输入层时，对模型内部深层表征的影响有限，面对一些需要深层表示调整的 NLU&#x2F;序列标注任务表现并不稳定或不足</li>
<li>在中小模型（100M–1B）表现较差</li>
</ul>
</li>
</ul>
<p>（3）<strong>P-Tuning v2的核心思想</strong>：在模型的每一层都应用连续的 prompts 并对 prompts 参数进行更新优化</p>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/1-3-9.png" alt="img"></p>
<p>注意：P-Tuning v2中，在一些任务中，引入一个重参数化的编码器（如MLP，多层感知机）可以对提示向量进行非线性变换，提升模型性能。但是，研究发现其效果因任务而异，因此在P-Tuning v2中，是否使用重参数化需要根据具体任务进行选择。</p>
<ul>
<li>使用重参数化：使用MLP对前缀嵌入进行转换（对应于Prefix-Tuning）</li>
<li>不使用重参数化：直接使用前缀嵌入（对应于P-Tuning v2）</li>
</ul>
<p>（4）<strong>P-tuning v2的特点</strong>：</p>
<ul>
<li>优点：<ul>
<li>把 soft prompts 注入每层，能在多种规模与任务上接近全量微调效果</li>
</ul>
</li>
<li>缺点<ul>
<li>深层 prompt 或长 soft prompt 会占用较多 token &#x2F; 输入空间</li>
<li>P-tuning 的 soft prompt 是针对每个下游任务独立训练的，无法直接迁移到其他任务上使用</li>
</ul>
</li>
</ul>
<p>（5）<strong>P-tuning v1与P-tuning v2对比</strong></p>
<table>
<thead>
<tr>
<th>对比        维度</th>
<th><strong>P-tuning v1</strong></th>
<th><strong>P-tuning v2</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>提出时间</strong></td>
<td>2021（原始 P-tuning）</td>
<td>2022（P-tuning v2）</td>
</tr>
<tr>
<td><strong>核心思路</strong></td>
<td>在输入 embedding 层前插入连续可训练的 <strong>prompt embeddings</strong>，通过 LSTM&#x2F;MLP 对伪标记编码，优化这些参数以适配下游任务</td>
<td>在 <strong>Transformer 每一层</strong> 注入可训练的 <strong>layer-wise prompts</strong>（类似 prefix-tuning），直接与各层隐状态交互</td>
</tr>
<tr>
<td><strong>插入位置</strong></td>
<td>仅作用于 <strong>embedding 层</strong>（输入端）</td>
<td>作用于 <strong>每一层 Transformer</strong>（layer-wise prompt）</td>
</tr>
<tr>
<td><strong>参数规模</strong></td>
<td>较少（仅输入 prompt 参数）</td>
<td>略多于 v1（每层都有 prompt 参数），但仍远小于全量微调</td>
</tr>
<tr>
<td><strong>表达能力</strong></td>
<td>容易受限，难以在小数据任务中获得与全量微调接近的性能</td>
<td>表达能力更强，性能更接近甚至超越全量微调</td>
</tr>
<tr>
<td><strong>训练方式</strong></td>
<td>仅优化 prompt encoder 参数，其余预训练模型参数冻结</td>
<td>冻结预训练模型主干，优化每层的 prompt 参数</td>
</tr>
<tr>
<td><strong>初始化方式</strong></td>
<td>通常从 vocab embedding 随机或用任务相关词初始化</td>
<td>通常随机初始化，也可借助任务先验初始化</td>
</tr>
<tr>
<td><strong>依赖组件</strong></td>
<td>需要 <strong>Prompt Encoder</strong>（如 LSTM&#x2F;MLP）来生成连续模板向量</td>
<td>不需要复杂 Prompt Encoder，直接将可训练向量作为 prefix 注入每层</td>
</tr>
<tr>
<td><strong>优点</strong></td>
<td>参数量小、实现简单、易迁移到不同任务</td>
<td>表达能力强、在低资源场景下性能稳定、接近全量微调效果</td>
</tr>
<tr>
<td><strong>缺点</strong></td>
<td>对复杂任务适配能力不足，深层信息利用不充分</td>
<td>参数量稍大，实现比 v1 复杂，需要改造模型结构</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>对计算资源和任务复杂度要求低的场景</td>
<td>更复杂、对性能要求高或低资源任务中替代全量微调</td>
</tr>
</tbody></table>
<h5 id="1-6-3-4-PPT（Pre-trained-Prompt-Tuning）"><a href="#1-6-3-4-PPT（Pre-trained-Prompt-Tuning）" class="headerlink" title="1.6.3.4 PPT（Pre-trained Prompt Tuning）"></a>1.6.3.4 PPT（Pre-trained Prompt Tuning）</h5><p>（1）PPT 的核心思想：对连续提示模板也进行预训练——先让这些连续提示在大量无标注的预训练语料进行预训练（注意，预训练过程中，Pre-train-model参数固定不变，只改变soft prompt），然后将其加载到对应下游任务的PLM上进行微调后使用。</p>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250818173316706.png" alt="image-20250818173316706"></p>
<p>（2）<strong>PPT的特点</strong>：</p>
<ul>
<li>优点：<ul>
<li>预训练soft-prompt带来了 小样本学习场景上的显著提升</li>
<li>缓解了prompt-tuning收敛慢的问题</li>
</ul>
</li>
<li>缺点<ul>
<li>高度依赖于源任务集的覆盖度与多样性(一旦目标任务与预训练时用到的源任务在分布、格式或语义上差异较大，通用提示 𝑃就难以提供有效的初始引导，导致下游微调效果大幅下降)</li>
</ul>
</li>
</ul>
<h2 id="2、大模型PEFT微调方法【掌握】"><a href="#2、大模型PEFT微调方法【掌握】" class="headerlink" title="2、大模型PEFT微调方法【掌握】"></a>2、大模型PEFT微调方法【掌握】</h2><p>（1）参数高效微调方法（Parameter-Efficient Fine-Tuning，PEFT）特点：</p>
<ul>
<li><p><strong>PEFT 方法仅微调少量或额外的模型参数，固定大部分预训练参数，大大降低了计算和存储成本</strong></p>
</li>
<li><p><strong>最先进的 PEFT 技术也能实现了与全量微调相当的性能</strong></p>
</li>
</ul>
<p>（2）类型</p>
<ul>
<li><strong>Prefix&#x2F;Prompt-Tuning</strong>：在模型的输入或隐层添加 $k$个额外可训练的前缀 tokens（这些前缀是连续的伪 tokens，不对应真实的 tokens），只训练这些前缀参数；</li>
<li><strong>Adapter-Tuning</strong>：将较小的神经网络层或模块插入预训练模型的每一层，这些新插入的神经模块称为 adapter（适配器），下游任务微调时也只训练这些适配器参数；</li>
<li><strong>LoRA</strong>：通过学习小参数的低秩矩阵来近似模型权重矩阵 $W$的参数更新，训练时只优化低秩矩阵参数。</li>
</ul>
<h3 id="2-1-Prefix-Tuning"><a href="#2-1-Prefix-Tuning" class="headerlink" title="2.1 Prefix Tuning"></a>2.1 Prefix Tuning</h3><p>（1）做法：在模型的输入或隐层添加 $k$个额外可训练的前缀 tokens（这些前缀是连续的伪 tokens，不对应真实的 tokens），只训练这些前缀参数</p>
<p>（2）具体实现流程如下：</p>
<p>1）<strong>确定任务与基模型</strong></p>
<ul>
<li>任务：条件生成（如摘要、表格到文本、对话）或 seq2seq。</li>
<li>选模型：GPT-2&#x2F;decoder-only 或 BART&#x2F;T5（encoder-decoder）。</li>
</ul>
<p>2）<strong>设计 prefix 配置</strong></p>
<ul>
<li>决定 <code>num_prefix</code>（每层的虚拟 token 数，常见 10–100），以及是否对所有层都使用 prefix（论文对每层都用了 prefix，但可做只对部分层）。</li>
</ul>
<p>3）<strong>构造可训练参数（初始化）</strong></p>
<p>原始论文中为每层创建一个可以训练的矩阵$P_θ$ ，作为前缀向量拼接到原向量中。但是论文中提出直接优化 $P_θ$ 会导致训练不稳定，可以通过一个更小的矩阵 $P_w$和一个更大的前馈神经网络$MLP_θ$ 对$P_θ$ 进行重参数化: $P_θ[i,:]&#x3D;MLP_θ(P_w[i,:])$ 。</p>
<p>所以目前实际实现时，通常会先训练一个 <code>(num_layers, num_prefix, hidden_dim)</code> 的 prefix embedding，然后通过一个小的 MLP 投影成 <code>(num_layers, num_prefix, 2 * head_dim * num_heads)</code>，再 reshape 成 <code>(num_layers, num_heads, num_prefix, head_dim)</code>，分别拆成 K 和 V。因此需要创建一个可训练的矩阵 $P_θ$  ，以及一个MLP模型。</p>
<p>4）<strong>修改模型前向（插入 prefix）</strong></p>
<ul>
<li>在 Transformer 的每一层注意力里，将 prefix 对应的 key&#x2F;value 拼接到原始的 key&#x2F;value——这样后续 token 可以像“看到真实 tokens”一样 attend 到 prefix，然后一起进行训练。</li>
</ul>
<p>5）<strong>训练设置</strong></p>
<ul>
<li>冻结原模型参数（<code>requires_grad=False</code>），只对 prefix 参数做优化。</li>
<li>损失函数通常是标准的交叉熵，训练器只更新 prefix。</li>
</ul>
<p>6）<strong>推理</strong></p>
<ul>
<li>推理时把训练好的 prefix 附加到每层（同训练时），然后用常见的解码策略进行生成。</li>
</ul>
<p>（3）<strong>Prefix Tuning的特点</strong>：</p>
<ul>
<li>优点：<ul>
<li>只训练少量 prefix 参数，相对全量微调的存储和训练成本低。</li>
<li>不同任务只需切换 prefix，无需保存多个完整模型。</li>
</ul>
</li>
<li>缺点<ul>
<li>小模型表现差：在 BERT-base 等小模型上效果不佳</li>
<li>需在每层注入 prefix，会占用输入序列的长度</li>
<li>在判别式任务上常逊于 LoRA、P-Tuning v2</li>
</ul>
</li>
</ul>
<p>（4）Prefix Tuning与P-Tuning v1和v2的区别</p>
<p>1）<strong>目标任务</strong></p>
<ul>
<li><p>Prefix-Tuning：主要面向<strong>生成类任务</strong>（table→text、summarization、GPT-2&#x2F;BART 等场景），论文强调在生成上用少量参数达到接近微调的效果。</p>
</li>
<li><p>P-Tuning v1和v2：主要针对<strong>NLU（分类、序列标注、QA 等）</strong>，目标是让 prompt-only 方法在 NLU 上也能普遍接近微调的性能。</p>
</li>
</ul>
<p>2）<strong>注入位置</strong></p>
<ul>
<li>P-tuning v1：只在输入 embedding 处（相当于在输入序列前加若干soft prompt 的 embedding）。</li>
<li>Prefix Tuning &#x2F; P-tuning v2：在 Transformer 每一层的中都进行注入。</li>
</ul>
<p>3）<strong>注入形式</strong></p>
<ul>
<li><p>Prefix Tuning和P-tuning v2：将前缀token直接作用到注意力机制计算的 &#x3D;&#x3D;key&#x2F;value&#x3D;&#x3D;上，然后进行注意力计算。</p>
</li>
<li><p>P-tuning v1是将原始embedding+prompt embedding组成的新输入后送入下一层。</p>
</li>
</ul>
<p>4）<strong>参数化方式</strong></p>
<ul>
<li>Prefix Tuning：原始论文中直接优化每层的“past key&#x2F;value”向量（通常把这些向量当作要学习的参数矩阵）；另外，也提出生成一个初始向量，再通过MLP进行投影效果更好。</li>
<li>P-tuning v1：通过 prompt encoder优化一组输入级别的 embedding。</li>
<li>P-tuning v2：提出了可选的 reparameterization（用小网络如MLP把少量可训练参数映射成每层的完整 prompt），利于参数共享、稳定训练并在层数很多时控制参数量。如果不用reparameterization则直接使用embedding的结果。</li>
</ul>
<p>5）<strong>效果</strong></p>
<ul>
<li>P-tuning v1：对 decoder-only、encoder-decoder 都可用，但效果和适用性有限（因为只在输入层）。</li>
<li>Prefix Tuning 与 P-tuning v2：更适合需要深层修改注意力的信息流的任务（对 decoder-only 和 encoder-decoder 都能做扩展，且在很多任务上性能更好）。</li>
</ul>
<h3 id="2-2-Adapter-Tuning"><a href="#2-2-Adapter-Tuning" class="headerlink" title="2.2 Adapter Tuning"></a>2.2 Adapter Tuning</h3><p>（1）做法：在预训练模型内部的网络层之间添加新的网络层或模块来适配下游任务</p>
<p>（2）Series Adapter的适配器结构和与 Transformer 的集成结构：</p>
<img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250818181655276.png" alt="image-20250818181655276" style="zoom:67%;" />

<p>（3）<strong>Adapter Tuning的特点</strong>：</p>
<ul>
<li>优点：<ul>
<li>只训练少量 adapter 参数，相对全量微调的存储和训练成本低。</li>
<li>可以为多个任务保存不同的 adapter，而共享一个大模型。</li>
<li>多个任务的 adapters 可以在推理时进行切换或融合，提升迁移和泛化能力。</li>
</ul>
</li>
<li>缺点<ul>
<li>因为大部分参数被冻结，adapter 的容量有限，对复杂任务或需要大规模参数调整的任务可能效果不如全量微调。</li>
<li>Adapter 的维度大小（瓶颈层大小）、插入位置等超参数对性能影响较大，调参复杂度较高。</li>
<li>PLM 基础上添加适配器层会引入额外的计算，带来推理延迟问题</li>
</ul>
</li>
</ul>
<h3 id="2-3-LoRA"><a href="#2-3-LoRA" class="headerlink" title="2.3 LoRA"></a>2.3 LoRA</h3><p>（1）补充知识——秩</p>
<ul>
<li>1）什么叫做秩？</li>
</ul>
<p><strong>矩阵中所有行向量（或列向量）所张成的向量空间的维数</strong>。</p>
<p>换句话说，秩衡量了矩阵里有多少个 <strong>线性无关的行&#x2F;列</strong>。如果把矩阵看成是很多向量的集合，那么秩就是这些向量中最多能取出的互不依赖的数量。</p>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250816174459601.png" alt="image-20250816174459601"></p>
<ul>
<li><p>2）秩的几种等价定义</p>
<ul>
<li><p>行秩：矩阵中线性无关的行向量个数</p>
</li>
<li><p>列秩：矩阵中线性无关的列向量个数</p>
</li>
<li><p>基本定理：<strong>行秩 &#x3D; 列秩</strong>，这个共同的数就是矩阵的秩。</p>
</li>
</ul>
</li>
<li><p>3）秩的直观理解</p>
</li>
</ul>
<p>秩 &#x3D; 有效信息量，秩越高，矩阵包含的独立信息越多。</p>
<p>（2）做法：在预训练语言模型（PLM）的特定线性层（如自注意力机制中的 Q、K、V 投影层和前馈网络）旁边，并行地注入一对小的、可训练的低秩分解矩阵，而冻结 PLM 的原有参数。</p>
<p>低秩适应：对大型模型的权重矩阵进行隐式的低秩转换，也就是：通过一个较低维度的表示来近似表示一个高维矩阵或数据集。</p>
<p>（3）基本原理：LoRA技术冻结预训练模型的权重，并在每个Transformer块中注入可训练层（称为秩分解矩阵），即在模型的Linear层的旁边增加一个“旁支”A和B。其中，A将数据从d维降到r维，这个r是LoRA的秩，是一个重要的超参数；B将数据从r维升到d维，B部分的参数初始为0。模型训练结束后，需要将A+B部分的参数与原大模型的参数合并在一起使用。</p>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250819103825320.png" alt="image-20250819103825320"></p>
<p>（4）<strong>LoRA的特点</strong>：</p>
<ul>
<li>优点：<ul>
<li>只训练极少参数，相对全量微调的存储和训练成本低。</li>
<li>效果接近全参数微调，且保留原模型能力。</li>
<li>不同任务的 LoRA 模块可插拔，便于多任务部署。</li>
</ul>
</li>
<li>缺点<ul>
<li>LoRA 本质是用低秩分解逼近权重更新矩阵，这对参数空间的表达能力有限制，可能无法拟合某些复杂任务所需的高秩变化。</li>
<li>LoRA 通常加在 attention 的投影矩阵（Wq&#x2F;Wv）上，但不同任务可能对位置敏感，选择不好会影响性能。</li>
</ul>
</li>
</ul>
<h3 id="2-4-QLoRA"><a href="#2-4-QLoRA" class="headerlink" title="2.4 QLoRA"></a>2.4 QLoRA</h3><p>（1）核心思想是：<strong>通过对预训练语言模型（PLM）进行量化（通常是 4-bit NormalFloat），并结合 LoRA 技术进行微调，从而在极低的内存消耗下，仍然能够高效地微调巨型语言模型，同时保持甚至超越全量 16-bit LoRA 的性能。</strong></p>
<p>（2）核心创新点</p>
<ul>
<li>高效低精度量化（NF4 量化）：NF4 采用了非均匀的数值分布映射，更好地保留了原始权重的细微差异，使得在极低精度下仍能保持接近 FP16 的模型性能。</li>
<li>采用双量化和分页优化器，进一步减少显存占用。</li>
<li>在量化后的冻结PLM上，<strong>LoRA的微调机制保持不变</strong>。</li>
</ul>
<p>（3）<strong>QLoRA的特点</strong></p>
<ul>
<li>优点：<ul>
<li>极低的内存消耗。这是 QLoRA 最显著的优势。可以将训练巨型模型的内存需求降低 3-4 倍，使得在单张消费级 GPU 上（如 24GB VRAM 的 RTX 3090&#x2F;4090）微调 65B 甚至 70B 参数的模型成为可能。</li>
<li>性能优异：尽管进行了 4-bit 量化，但由于 16-bit 的 LoRA 权重和优化器状态，QLoRA 在许多任务上能够保持与 16-bit LoRA 甚至全量微调相媲美的性能。</li>
<li>训练速度快：由于只训练少量参数且内存效率高，训练速度非常快。</li>
</ul>
</li>
<li>缺点<ul>
<li>虽然 NF4 优化了精度，但极端任务或敏感任务可能仍受 4-bit 量化影响。</li>
<li>由于量化和分页机制的存在，训练和问题调试会比标准 LoRA 更复杂。</li>
</ul>
</li>
</ul>
<h1 id="基于GPT2的医疗问诊机器人"><a href="#基于GPT2的医疗问诊机器人" class="headerlink" title="基于GPT2的医疗问诊机器人"></a>基于GPT2的医疗问诊机器人</h1><hr>
<h2 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h2><ul>
<li>理解医疗问诊机器人的开发背景.</li>
<li>了解企业中聊天机器人的应用场景</li>
<li>掌握基于GPT2模型搭建医疗问诊机器人的实现过程</li>
</ul>
<hr>
<h2 id="1-项目介绍"><a href="#1-项目介绍" class="headerlink" title="1. 项目介绍"></a>1. 项目介绍</h2><h3 id="1-1-项目背景"><a href="#1-1-项目背景" class="headerlink" title="1.1 项目背景"></a>1.1 项目背景</h3><ul>
<li>本项目基于医疗领域数据构建了智能医疗问答系统,目的是为为用户提供准确、高效、优质的医疗问答服务。</li>
</ul>
<h3 id="1-2-环境准备"><a href="#1-2-环境准备" class="headerlink" title="1.2 环境准备"></a>1.2 环境准备</h3><ul>
<li>python&#x3D;&#x3D;3.10</li>
<li>transformers&#x3D;&#x3D;4.40.2</li>
<li>torch&#x3D;&#x3D;2.5.1+cu121</li>
</ul>
<h3 id="1-3-项目整体结构"><a href="#1-3-项目整体结构" class="headerlink" title="1.3 项目整体结构"></a>1.3 项目整体结构</h3><p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250819201622040.png" alt="image-20250819201622040"></p>
<hr>
<p><strong>整体代码结构：</strong></p>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250817174320793.png" alt="image-20250817174320793"></p>
<h2 id="2-数据处理"><a href="#2-数据处理" class="headerlink" title="2. 数据处理"></a>2. 数据处理</h2><h3 id="2-1-数据介绍"><a href="#2-1-数据介绍" class="headerlink" title="2.1 数据介绍"></a>2.1 数据介绍</h3><ul>
<li>数据存放位置：llm_tuning&#x2F;Gpt2_Chatbot&#x2F;data</li>
<li>data文件夹中存有原始训练语料为train.txt。train.txt的格式如下，每段闲聊之间间隔一行，格式如下：</li>
</ul>
<figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">帕金森叠加综合征的辅助治疗有些什么？</span><br><span class="line">综合治疗；康复训练；生活护理指导；低频重复经颅磁刺激治疗</span><br><span class="line"></span><br><span class="line">卵巢癌肉瘤的影像学检查有些什么？</span><br><span class="line">超声漏诊；声像图；MR检查；肿物超声；术前超声；CT检查</span><br></pre></td></tr></table></figure>

<h3 id="2-2-数据处理"><a href="#2-2-数据处理" class="headerlink" title="2.2 数据处理"></a>2.2 数据处理</h3><ul>
<li>目的：将中文文本数据处理成模型能够识别的张量形式，并将上述文本进行张量的转换</li>
<li>实现过程：<ul>
<li>运行preprocess.py，对data&#x2F;train.txt对话语料进行tokenize，然后进行序列化保存到data&#x2F;train.pkl。train.pkl中序列化的对象的类型为List[List],记录对话列表中,每个对话包含的token。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="2-2-1-配置文件"><a href="#2-2-1-配置文件" class="headerlink" title="2.2.1 配置文件"></a>2.2.1 配置文件</h4><ul>
<li>代码路径：llm_tuning&#x2F;Gpt2_Chatbot&#x2F;parameter_config.py</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">base_dir = os.path.dirname(os.path.abspath(__file__))</span><br><span class="line"><span class="comment"># print(f&#x27;base_dir--&gt;&#123;base_dir&#125;&#x27;)</span></span><br><span class="line"><span class="comment"># base_dir2 = os.getcwd()  # 错误的写法，这种写法会随着调用位置改变而变化</span></span><br><span class="line"><span class="comment"># print(f&#x27;base_dir2--&gt;&#123;base_dir2&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ParameterConfig</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">        <span class="comment"># self.device = torch.device(&#x27;mps&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)</span></span><br><span class="line">        <span class="comment"># 词典路径：在vocab文件夹里面</span></span><br><span class="line">        self.vocab_path = os.path.join(base_dir, <span class="string">&#x27;vocab/vocab.txt&#x27;</span>)</span><br><span class="line">        <span class="comment"># 训练文件路径</span></span><br><span class="line">        self.train_txt_path = os.path.join(base_dir, <span class="string">&#x27;data/medical_train.txt&#x27;</span>)</span><br><span class="line">        self.train_path = os.path.join(base_dir, <span class="string">&#x27;data/medical_train.pkl&#x27;</span>)</span><br><span class="line">        <span class="comment"># 验证数据文件路径</span></span><br><span class="line">        self.valid_txt_path = os.path.join(base_dir, <span class="string">&#x27;data/medical_valid.txt&#x27;</span>)</span><br><span class="line">        self.valid_path = os.path.join(base_dir, <span class="string">&#x27;data/medical_valid.pkl&#x27;</span>)</span><br><span class="line">        <span class="comment"># 模型配置文件</span></span><br><span class="line">        self.config_json = os.path.join(base_dir, <span class="string">&#x27;config/config.json&#x27;</span>)</span><br><span class="line">        <span class="comment"># 模型保存路径</span></span><br><span class="line">        self.save_model_path = os.path.join(base_dir, <span class="string">&#x27;save_model&#x27;</span>)</span><br><span class="line">        <span class="comment"># 如果你有预训练模型就写上路径（我们本次没有直接运用GPT2预训练好的模型，而是仅只用了该模型的框架）</span></span><br><span class="line">        self.pretrained_model = <span class="string">&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 保存对话语料</span></span><br><span class="line">        self.save_samples_path = os.path.join(base_dir, <span class="string">&#x27;sample&#x27;</span>)</span><br><span class="line">        <span class="comment"># 忽略一些字符：句子需要长度补齐，针对补的部分，没有意义，所以一般不进行梯度更新</span></span><br><span class="line">        self.ignore_index = -<span class="number">100</span></span><br><span class="line">        <span class="comment"># 历史对话句子的长度</span></span><br><span class="line">        self.max_history_len = <span class="number">3</span>  <span class="comment"># &quot;dialogue history的最大长度&quot;</span></span><br><span class="line">        <span class="comment"># 每一个完整对话的句子最大长度</span></span><br><span class="line">        self.max_len = <span class="number">300</span>  <span class="comment"># &#x27;每个utterance的最大长度,超过指定长度则进行截断,默认25&#x27;</span></span><br><span class="line">        self.repetition_penalty = <span class="number">5.0</span>  <span class="comment"># &quot;重复惩罚参数，若生成的对话重复性较高，可适当提高该参数&quot;</span></span><br><span class="line">        self.topk = <span class="number">2</span>  <span class="comment"># &#x27;保留概率最高的topk个token。默认4&#x27;</span></span><br><span class="line">        self.topp = <span class="number">0.7</span>  <span class="comment"># &#x27;保留累积概率top个token。默认0.7&#x27;</span></span><br><span class="line">        self.batch_size = <span class="number">8</span>  <span class="comment"># 一个批次几个样本</span></span><br><span class="line">        self.epochs = <span class="number">4</span>  <span class="comment"># 训练几轮</span></span><br><span class="line">        self.loss_step = <span class="number">100</span>  <span class="comment"># 多少步汇报一次loss</span></span><br><span class="line">        self.lr = <span class="number">2.6e-5</span></span><br><span class="line">        <span class="comment"># eps，为了增加数值计算的稳定性而加到分母里的项，其为了防止在实现中除以零</span></span><br><span class="line">        self.eps = <span class="number">1.0e-09</span></span><br><span class="line">        self.max_grad_norm = <span class="number">2.0</span></span><br><span class="line">        self.gradient_accumulation_steps = <span class="number">4</span>  <span class="comment"># 梯度累积的步数</span></span><br><span class="line">        <span class="comment"># 使用Warmup预热学习率的方式,即先用最初的小学习率训练，然后每个step增大一点点，直到达到最初设置的比较大的学习率时（注：此时预热学习率完成），采用最初设置的学习率进行训练（注：预热学习率完成后的训练过程，学习率是衰减的），有助于使模型收敛速度变快，效果更佳。默认.warmup_steps = 4000</span></span><br><span class="line">        self.warmup_steps = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    pc = ParameterConfig()</span><br><span class="line">    <span class="built_in">print</span>(pc.train_path)</span><br><span class="line">    <span class="built_in">print</span>(pc.device)</span><br></pre></td></tr></table></figure>



<h4 id="2-2-1-数据张量转换"><a href="#2-2-1-数据张量转换" class="headerlink" title="2.2.1 数据张量转换"></a>2.2.1 数据张量转换</h4><ul>
<li>步骤</li>
</ul>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250819211546708.png" alt="image-20250819211546708"></p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">1.</span> <span class="string">加载分词器</span></span><br><span class="line"><span class="attr">2.</span> <span class="string">读取数据，拆分出每段对话</span></span><br><span class="line"><span class="attr">3.</span> <span class="string">对每段对话进行处理（拼接问题和答案）， 并进行编码</span></span><br><span class="line"><span class="attr">4.</span> <span class="string">保存处理好的列表</span></span><br></pre></td></tr></table></figure>

<ul>
<li>代码路径：llm_tuning&#x2F;Gpt2_Chatbot&#x2F;data_preprocess&#x2F;preprocess.py</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertTokenizer</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> Gpt2_Chatbot.parameter_config <span class="keyword">import</span> ParameterConfig</span><br><span class="line"></span><br><span class="line">pc = ParameterConfig()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_preprocess</span>(<span class="params">txt_path, save_path</span>):</span><br><span class="line">    <span class="comment"># 1. 加载分词器</span></span><br><span class="line">    <span class="comment"># 第一种方式：使用预训练的分词器</span></span><br><span class="line">    <span class="comment"># tokenizer = BertTokenizer.from_pretrained(&#x27;gpt2&#x27;)</span></span><br><span class="line">    <span class="comment"># 第二种方式：使用本地的分词器</span></span><br><span class="line">    tokenizer = BertTokenizer.from_pretrained(pc.vocab_path)</span><br><span class="line">    <span class="comment"># print(f&#x27;tokenizer.vocab_size--&gt;&#123;tokenizer.vocab_size&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># 特殊字符</span></span><br><span class="line">    <span class="comment"># print(f&#x27;tokenizer.special_tokens_map--&gt;&#123;tokenizer.special_tokens_map&#125;&#x27;)</span></span><br><span class="line">    sep_id = tokenizer.sep_token_id</span><br><span class="line">    cls_id = tokenizer.cls_token_id</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;sep_id--&gt;<span class="subst">&#123;sep_id&#125;</span>, cls_id--&gt;<span class="subst">&#123;cls_id&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 读取数据，拆分出每段对话</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(txt_path, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        data = f.read()</span><br><span class="line">    <span class="comment"># print(f&#x27;data--&gt;&#123;data&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># 切分数据</span></span><br><span class="line">    data_list = data.split(<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;data_list--&gt;<span class="subst">&#123;<span class="built_in">len</span>(data_list)&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="comment"># print(f&#x27;data_list[0]--&gt;&#123;data_list[0]&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 对每段对话进行处理（拼接问题和答案）， 并进行编码</span></span><br><span class="line">    <span class="comment"># 将每段对话处理成：[CLS]帕金森叠加。。些什么？[SEP]综合治疗；康复。。。重复经颅磁刺激治疗[SEP]</span></span><br><span class="line">    dialogue_list = []  <span class="comment"># 存储每段对话</span></span><br><span class="line">    <span class="keyword">for</span> dialogue <span class="keyword">in</span> data_list:</span><br><span class="line">        <span class="comment"># 对每段对话进行拆分，获取问题和答案</span></span><br><span class="line">        qa_list = dialogue.split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">        <span class="comment"># 初始化input_ids列表，存储编码后的数据</span></span><br><span class="line">        input_ids = [cls_id]</span><br><span class="line">        <span class="keyword">for</span> sentence <span class="keyword">in</span> qa_list:</span><br><span class="line">            <span class="comment"># add_special_tokens=False 表示不添加特殊字符</span></span><br><span class="line">            input_ids += tokenizer.encode(sentence, add_special_tokens=<span class="literal">False</span>)</span><br><span class="line">            input_ids.append(sep_id)</span><br><span class="line">        <span class="comment"># print(f&#x27;input_ids--&gt;&#123;input_ids&#125;&#x27;)</span></span><br><span class="line">        dialogue_list.append(input_ids)</span><br><span class="line">        <span class="comment"># break</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;dialogue_list--&gt;<span class="subst">&#123;<span class="built_in">len</span>(dialogue_list)&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="comment"># 4. 保存处理好的列表</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(save_path, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        pickle.dump(dialogue_list, f)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    data_preprocess(pc.train_txt_path, pc.train_path)</span><br><span class="line">    data_preprocess(pc.valid_txt_path, pc.valid_path)</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="2-2-2-获取dataloader"><a href="#2-2-2-获取dataloader" class="headerlink" title="2.2.2 获取dataloader"></a>2.2.2 获取dataloader</h4><h5 id="（1）封装Dataset对象"><a href="#（1）封装Dataset对象" class="headerlink" title="（1）封装Dataset对象"></a>（1）封装Dataset对象</h5><ul>
<li>代码路径：llm_tuning&#x2F;Gpt2_Chatbot&#x2F;data_preprocess&#x2F;dataset.py</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> Gpt2_Chatbot.parameter_config <span class="keyword">import</span> ParameterConfig</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data_list</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        初始化函数，用于设置数据集</span></span><br><span class="line"><span class="string">        :param data_list: 输入列表，就是preprocess中处理好的数据列表</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(MyDataset, self).__init__()</span><br><span class="line">        self.data_list = data_list</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):  <span class="comment"># 获取数据集大小</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data_list)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):  <span class="comment"># 根据索引返回数据</span></span><br><span class="line">        <span class="keyword">return</span> self.data_list[index]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    pc = ParameterConfig()</span><br><span class="line">    <span class="comment"># 加载保存的数据</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(pc.train_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        train_data_list = pickle.load(f)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;train_data_list--&gt;<span class="subst">&#123;<span class="built_in">len</span>(train_data_list)&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="comment"># 初始化对象</span></span><br><span class="line">    mydataset = MyDataset(train_data_list)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;数据集的长度--&gt;<span class="subst">&#123;mydataset.__len__()&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;数据集的长度--&gt;<span class="subst">&#123;<span class="built_in">len</span>(mydataset)&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;数据集的第一个数据--&gt;<span class="subst">&#123;mydataset.__getitem__(<span class="number">0</span>)&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;数据集的第一个数据--&gt;<span class="subst">&#123;mydataset[<span class="number">0</span>]&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h5 id="（2）封装DataLoader对象"><a href="#（2）封装DataLoader对象" class="headerlink" title="（2）封装DataLoader对象"></a>（2）封装DataLoader对象</h5><ul>
<li>代码路径：&#x2F;home&#x2F;user&#x2F;ProjectStudy&#x2F;Gpt2_Chatbot&#x2F;data_preprocess&#x2F;dataloader.py</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn.utils.rnn <span class="keyword">import</span> pad_sequence</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> Gpt2_Chatbot.data_preprocess.dataset <span class="keyword">import</span> MyDataset</span><br><span class="line"><span class="keyword">from</span> Gpt2_Chatbot.parameter_config <span class="keyword">import</span> ParameterConfig</span><br><span class="line"></span><br><span class="line">pc = ParameterConfig()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">batch_data</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    自定义collate_fn函数，用于将数据集中的数据进行批处理</span></span><br><span class="line"><span class="string">    :param batch_data: 每个批次中的样本</span></span><br><span class="line"><span class="string">    :return: 处理好的，可以送到模型中的数据。需要包括输入和输出（标签）。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 1. 将数据转成张量</span></span><br><span class="line">    batch_data = [torch.tensor(data) <span class="keyword">for</span> data <span class="keyword">in</span> batch_data]</span><br><span class="line">    <span class="comment"># print(f&#x27;batch_data--&gt;&#123;batch_data&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;batch_data[0]--&gt;&#123;batch_data[0].shape&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;batch_data[1]--&gt;&#123;batch_data[1].shape&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 对批次数据的数据进行长度统一</span></span><br><span class="line">    <span class="comment"># 使用 pad_sequence 对批次内的数据长度进行统一，统一的方式就是将该批次内最大的句子的长度作为该批次数据的长度，其他句子长度不足的，用填充值进行填充</span></span><br><span class="line">    <span class="comment"># batch_first=True 表示返回的张量的形状为(batch_size, max_len)</span></span><br><span class="line">    <span class="comment"># 对于输入数据 padding_value为填充的数字，这里为0</span></span><br><span class="line">    input_ids = pad_sequence(batch_data, batch_first=<span class="literal">True</span>, padding_value=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># print(f&#x27;input_ids--&gt;&#123;input_ids&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;input_ids[0]--&gt;&#123;input_ids[0].shape&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;input_ids[1]--&gt;&#123;input_ids[1].shape&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 注意：对于标签来说，需要将标签的填充值设置为-100，这样在计算损失函数的时候，忽略掉填充值对应的位置的预测结果。</span></span><br><span class="line">    labels = pad_sequence(batch_data, batch_first=<span class="literal">True</span>, padding_value=-<span class="number">100</span>)</span><br><span class="line">    <span class="keyword">return</span> input_ids, labels</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_data_loader</span>(<span class="params">train_path, valid_path</span>):</span><br><span class="line">    <span class="comment"># 训练集</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(train_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        train_data_list = pickle.load(f)</span><br><span class="line">    <span class="comment"># print(f&#x27;train_data_list--&gt;&#123;len(train_data_list)&#125;&#x27;)</span></span><br><span class="line">    train_dataset = MyDataset(train_data_list)</span><br><span class="line"></span><br><span class="line">    train_dataloader = DataLoader(train_dataset,</span><br><span class="line">                                  batch_size=pc.batch_size,</span><br><span class="line">                                  shuffle=<span class="literal">False</span>,  <span class="comment"># 在代码开发时，设置为False，在训练时，设置为True</span></span><br><span class="line">                                  collate_fn=collate_fn,</span><br><span class="line">                                  drop_last=<span class="literal">True</span>)  <span class="comment"># 如果最后剩下的数据不足一个batch_size的数据，则忽略</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 验证集</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(valid_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        valid_data_list = pickle.load(f)</span><br><span class="line">    valid_dataset = MyDataset(valid_data_list)</span><br><span class="line"></span><br><span class="line">    valid_dataloader = DataLoader(valid_dataset,</span><br><span class="line">                                  batch_size=pc.batch_size,</span><br><span class="line">                                  shuffle=<span class="literal">False</span>,  <span class="comment"># 在代码开发时，设置为False，在训练时，设置为True</span></span><br><span class="line">                                  collate_fn=collate_fn,</span><br><span class="line">                                  drop_last=<span class="literal">True</span>)  <span class="comment"># 如果最后剩下的数据不足一个batch_size的数据，则忽略</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_dataloader, valid_dataloader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    train_dataloader, valid_dataloader = get_data_loader(pc.train_path, pc.valid_path)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;训练集的长度--&gt;<span class="subst">&#123;<span class="built_in">len</span>(train_dataloader)&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;验证集的长度--&gt;<span class="subst">&#123;<span class="built_in">len</span>(valid_dataloader)&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># for i, data in enumerate(train_dataloader):</span></span><br><span class="line">    <span class="comment">#     print(f&#x27;第&#123;i&#125;个batch的数据--&gt;&#123;data&#125;&#x27;)</span></span><br><span class="line">    <span class="comment">#     break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, (input_ids, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataloader):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;input_ids--&gt;<span class="subst">&#123;input_ids.shape&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;labels--&gt;<span class="subst">&#123;labels.shape&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;input_ids--&gt;<span class="subst">&#123;input_ids&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;labels--&gt;<span class="subst">&#123;labels&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="3-模型搭建"><a href="#3-模型搭建" class="headerlink" title="3. 模型搭建"></a>3. 模型搭建</h2><h3 id="3-1-模型架构介绍"><a href="#3-1-模型架构介绍" class="headerlink" title="3.1 模型架构介绍"></a>3.1 模型架构介绍</h3><p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20251102002757498.png" alt="image-20251102002757498"></p>
<ul>
<li><p>模型架构解析：</p>
<ul>
<li>输入层：词嵌入层：WordEmbedding +位置嵌入层：PositionEmbedding</li>
<li>中间层：Transformer的Decoder模块—12层</li>
<li>输出层：LayerNorm层 + 线性全连接层</li>
</ul>
</li>
<li><p>模型主要参数简介(详见模型的config.json文件):</p>
<ul>
<li>n_embd: 768</li>
<li>n_head: 12</li>
<li>n_layer: 12</li>
<li>n_positions: 1024</li>
<li>vocab_size: 13317</li>
</ul>
</li>
</ul>
<hr>
<h3 id="3-2-GPT2模型准备"><a href="#3-2-GPT2模型准备" class="headerlink" title="3.2 GPT2模型准备"></a>3.2 GPT2模型准备</h3><ul>
<li>本次项目使用GPT2的预训练模型，因此不需要额外搭建Model类，下面代码是如何直接加载使用GPT2预训练模型</li>
<li>代码示例:</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> GPT2LMHeadModel, GPT2Config</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> Gpt2_Chatbot.parameter_config <span class="keyword">import</span> ParameterConfig</span><br><span class="line"></span><br><span class="line">params = ParameterConfig()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建模型</span></span><br><span class="line"><span class="keyword">if</span> params.pretrained_model:</span><br><span class="line">    <span class="comment"># 加载预训练模型</span></span><br><span class="line">	model = GPT2LMHeadModel.from_pretrained(params.pretrained_model)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 初始化模型</span></span><br><span class="line">	model_config = GPT2Config.from_json_file(params.config_json)</span><br><span class="line">	model = GPT2LMHeadModel(config=model_config)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model)</span><br></pre></td></tr></table></figure>

<ul>
<li>如果使用第二种方式，需要配置模型的参数</li>
<li>注意：&#x3D;&#x3D;这里指的参数并不是模型的权重！&#x3D;&#x3D;</li>
</ul>
<p>位置：llm_tuning&#x2F;Gpt2_Chatbot&#x2F;config&#x2F;config.json</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;activation_function&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gelu_new&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;architectures&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="string">&quot;GPT2LMHeadModel&quot;</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;attn_pdrop&quot;</span><span class="punctuation">:</span> <span class="number">0.1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;bos_token_id&quot;</span><span class="punctuation">:</span> <span class="number">50256</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;embd_pdrop&quot;</span><span class="punctuation">:</span> <span class="number">0.1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;eos_token_id&quot;</span><span class="punctuation">:</span> <span class="number">50256</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;gradient_checkpointing&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;initializer_range&quot;</span><span class="punctuation">:</span> <span class="number">0.02</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;layer_norm_epsilon&quot;</span><span class="punctuation">:</span> <span class="number">1e-05</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;model_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gpt2&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;n_ctx&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;n_embd&quot;</span><span class="punctuation">:</span> <span class="number">768</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;n_head&quot;</span><span class="punctuation">:</span> <span class="number">12</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;n_inner&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;n_layer&quot;</span><span class="punctuation">:</span> <span class="number">12</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;n_positions&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;output_past&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;resid_pdrop&quot;</span><span class="punctuation">:</span> <span class="number">0.1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;summary_activation&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;summary_first_dropout&quot;</span><span class="punctuation">:</span> <span class="number">0.1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;summary_proj_to_labels&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;summary_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;cls_index&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;summary_use_proj&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;task_specific_params&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;text-generation&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;do_sample&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;max_length&quot;</span><span class="punctuation">:</span> <span class="number">400</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;tokenizer_class&quot;</span><span class="punctuation">:</span> <span class="string">&quot;BertTokenizer&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;transformers_version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;4.2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;use_cache&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;vocab_size&quot;</span><span class="punctuation">:</span> <span class="number">13317</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>



<h2 id="4-模型训练和验证"><a href="#4-模型训练和验证" class="headerlink" title="4. 模型训练和验证"></a>4. 模型训练和验证</h2><h3 id="代码介绍"><a href="#代码介绍" class="headerlink" title="代码介绍"></a>代码介绍</h3><p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250821210441953.png" alt="image-20250821210441953"></p>
<h3 id="代码位置"><a href="#代码位置" class="headerlink" title="代码位置"></a>代码位置</h3><ul>
<li><p>训练主函数：llm_tuning&#x2F;Gpt2_Chatbot&#x2F;train.py</p>
</li>
<li><p>辅助工具类：llm_tuning&#x2F;Gpt2_Chatbot&#x2F;functions_tools.py</p>
</li>
</ul>
<hr>
<h3 id="模型调用"><a href="#模型调用" class="headerlink" title="模型调用"></a>模型调用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;input_ids--&gt;<span class="subst">&#123;input_ids.shape&#125;</span>&#x27;</span>)  <span class="comment"># [8, 49]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;labels--&gt;<span class="subst">&#123;labels.shape&#125;</span>&#x27;</span>)  <span class="comment"># [8, 49]</span></span><br><span class="line"><span class="comment"># 1.将数据送入模型，得到预测结果和损失</span></span><br><span class="line">input_ids = input_ids.to(pc.device)</span><br><span class="line">labels = labels.to(pc.device)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">在调用大模型时，如果输入里包括了labels参数，此时输出结果里会直接拿到loss损失；如果输入里只有input_ids，此时输出结果里不会含有loss损失</span></span><br><span class="line"><span class="string">在计算损失时，模型内部会将 logits/labels 自动做位移对齐（logits[..., :-1, :]和labels[..., 1:]），所以我们就可以在处理模型的输入和标签时，它们的实际token是一样的。另外，使用损失计算方式是交叉熵损失CrossEntropyLoss，计算损失时会自动忽略-100。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">outputs = model(input_ids, labels=labels)</span><br><span class="line"><span class="comment"># print(f&#x27;outputs--&gt;&#123;outputs&#125;&#x27;)  # 输出结果中包括 loss 和 logits 和 past_key_values</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;outputs--&gt;<span class="subst">&#123;outputs.keys()&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;logits--&gt;<span class="subst">&#123;outputs.logits.shape&#125;</span>&#x27;</span>)  <span class="comment"># [8, 49, 13317]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;loss--&gt;<span class="subst">&#123;outputs.loss&#125;</span>&#x27;</span>)  <span class="comment"># 9.59468364</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="训练技巧"><a href="#训练技巧" class="headerlink" title="训练技巧"></a>训练技巧</h3><p>&#x3D;&#x3D;（1）学习率预热&#x3D;&#x3D;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">优化点：学习率预热</span></span><br><span class="line"><span class="string">学习率预热的目的：让模型在初始阶段更快的使用数据，避免训练过程中学习率过大或过小带来训练不稳定或者收敛速度太慢的问题，从而提高模型训练效果和泛化性能</span></span><br><span class="line"><span class="string">实现方式：在初始阶段，将学习率从较小的值逐步增加到预设的初始值，然后按照我们设定的训练策略逐渐变小。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">get_linear_schedule_with_warmup: 使用这个方法来实现学习率预热，它的方式是从0以线性的方式增大到预设的学习率，然后再以线性的方式逐渐降低到0</span></span><br><span class="line"><span class="string">参数： optimizer：优化器对象</span></span><br><span class="line"><span class="string">num_warmup_steps：预热步数，指的是从0增加到预设的学习率所需的步数</span></span><br><span class="line"><span class="string">num_training_steps: 指的是整个训练过程的总的步数，确切来说在给定的数据集上，参数更新的次数。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># total_steps = len(train_dataloader) * pc.epochs  # 不进行梯度累积时，总的训练步数</span></span><br><span class="line">total_steps = <span class="built_in">len</span>(train_dataloader) * pc.epochs / pc.gradient_accumulation_steps  <span class="comment"># 进行梯度累积时，总的训练步数</span></span><br><span class="line">scheduler = get_linear_schedule_with_warmup(optimizer,</span><br><span class="line">                                            num_warmup_steps=pc.warmup_steps,</span><br><span class="line">                                            num_training_steps=total_steps)</span><br></pre></td></tr></table></figure>

<p>&#x3D;&#x3D;（2）梯度累积&#x3D;&#x3D;</p>
<p>梯度累积的作用：在显卡资源有限，不能训练大的batch_size时，可以使用梯度累积的方式，来实现大的batch_size效果。</p>
<p>比如显卡只能支持batch_size为2，如果想训练batch_size为8，则需要将梯度累积的步数设置为4。</p>
<p>具体使用的方式如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">pc.gradient_accumulation_steps = 4 梯度累积的步数</span></span><br><span class="line"><span class="string">如果设置了梯度累积的步数，并且大于1，此时则需要对损失进行缩放</span></span><br><span class="line"><span class="string">原因：因为在累积的步数内，损失和梯度都会进行累积，而不是在每次批次结束之后立即更新权重，通过损失除以梯度累积的步数进行缩放，可以使最终得到的结果和实际应用大的batch_size得到的结果一致</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">if</span> pc.gradient_accumulation_steps &gt; <span class="number">1</span>:</span><br><span class="line">    loss = loss / pc.gradient_accumulation_steps  <span class="comment"># 对loss进行缩放</span></span><br><span class="line"><span class="comment"># 反向传播（梯度计算）</span></span><br><span class="line">loss.backward()</span><br><span class="line"><span class="comment"># 在到达梯度累积的步数之后，执行参数更新</span></span><br><span class="line"><span class="keyword">if</span> (batch_idx + <span class="number">1</span>) % pc.gradient_accumulation_steps == <span class="number">0</span>:</span><br><span class="line">    <span class="comment"># 梯度更新（参数更新）</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    <span class="comment"># 学习率更新</span></span><br><span class="line">    scheduler.step()</span><br><span class="line">    <span class="comment"># 梯度清零</span></span><br><span class="line">    optimizer.zero_grad()</span><br></pre></td></tr></table></figure>



<p>&#x3D;&#x3D;（3）梯度裁剪&#x3D;&#x3D;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 梯度裁剪</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        作用： 当max_norm/total_norm &lt; 1时，将梯度乘以缩放系数，从而防止梯度过大带来梯度爆炸或者训练不稳定</span></span><br><span class="line"><span class="string">        使用方式：torch.nn.utils.clip_grad_norm_()</span></span><br><span class="line"><span class="string">        参数：parameters:模型的参数；max_norm：最大的梯度范数，总的梯度范数超过这个值之后，就会进行梯度裁剪</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=pc.max_grad_norm)   </span><br></pre></td></tr></table></figure>

<h3 id="trian-py代码"><a href="#trian-py代码" class="headerlink" title="trian.py代码"></a>trian.py代码</h3><p>&#x3D;&#x3D;注意点：需要将代码里的没有必要的print、break注释掉；需要将dataloader中，shuffle设置为True！！！&#x3D;&#x3D;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os.path</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> AdamW</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> GPT2LMHeadModel, GPT2Config, BertTokenizer, get_linear_schedule_with_warmup</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> Gpt2_Chatbot.data_preprocess.dataloader <span class="keyword">import</span> get_data_loader</span><br><span class="line"><span class="keyword">from</span> Gpt2_Chatbot.functions_tools <span class="keyword">import</span> calculate_acc</span><br><span class="line"><span class="keyword">from</span> Gpt2_Chatbot.parameter_config <span class="keyword">import</span> ParameterConfig</span><br><span class="line"></span><br><span class="line">pc = ParameterConfig()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_epoch</span>(<span class="params">model, train_dataloader, optimizer, scheduler, epoch</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    :param model: 模型</span></span><br><span class="line"><span class="string">    :param train_dataloader: 训练集的dataloader</span></span><br><span class="line"><span class="string">    :param optimizer: 优化器</span></span><br><span class="line"><span class="string">    :param scheduler: 学习率预热的对象</span></span><br><span class="line"><span class="string">    :param epoch: 轮次</span></span><br><span class="line"><span class="string">    :return: 平均损失和平均准确率</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch:<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span> 开始训练...&quot;</span>)</span><br><span class="line">    <span class="comment"># 指明模型训练</span></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="comment"># 设置一些日志参数</span></span><br><span class="line">    epoch_start_time = datetime.now()</span><br><span class="line">    total_loss = <span class="number">0</span>  <span class="comment"># 记录整个epoch的loss之和</span></span><br><span class="line">    total_correct_num = <span class="number">0</span>  <span class="comment"># 记录整个epoch的预测正确的word的数量</span></span><br><span class="line">    total_predict_num = <span class="number">0</span>  <span class="comment"># 记录整个epoch的预测的word的总数量</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开始训练，遍历数据集</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (input_ids, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(train_dataloader)):</span><br><span class="line">        <span class="comment"># print(f&#x27;input_ids--&gt;&#123;input_ids.shape&#125;&#x27;)  # [8, 49]</span></span><br><span class="line">        <span class="comment"># print(f&#x27;labels--&gt;&#123;labels.shape&#125;&#x27;)  # [8, 49]</span></span><br><span class="line">        <span class="comment"># 1.将数据送入模型，得到预测结果和损失</span></span><br><span class="line">        input_ids = input_ids.to(pc.device)</span><br><span class="line">        labels = labels.to(pc.device)</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        在调用大模型时，如果输入里包括了labels参数，此时输出结果里会直接拿到loss损失；如果输入里只有input_ids，此时输出结果里不会含有loss损失</span></span><br><span class="line"><span class="string">        在计算损失时，模型内部会将 logits/labels 自动做位移对齐（logits[..., :-1, :]和labels[..., 1:]），所以我们就可以在处理模型的输入和标签时，它们的实际token是一样的。另外，使用损失计算方式是交叉熵损失CrossEntropyLoss，计算损失时会自动忽略-100。</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        outputs = model(input_ids, labels=labels)</span><br><span class="line">        <span class="comment"># print(f&#x27;outputs--&gt;&#123;outputs&#125;&#x27;)  # 输出结果中包括 loss 和 logits 和 past_key_values</span></span><br><span class="line">        <span class="comment"># print(f&#x27;outputs--&gt;&#123;outputs.keys()&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;logits--&gt;&#123;outputs.logits.shape&#125;&#x27;)  # [8, 49, 13317]</span></span><br><span class="line">        <span class="comment"># print(f&#x27;loss--&gt;&#123;outputs.loss&#125;&#x27;)  # 9.59468364</span></span><br><span class="line">        logits = outputs.logits</span><br><span class="line">        loss = outputs.loss</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 累加当前损失到总损失中</span></span><br><span class="line">        total_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2.进行训练</span></span><br><span class="line">        <span class="comment"># # 反向传播（梯度计算）</span></span><br><span class="line">        <span class="comment"># loss.backward()</span></span><br><span class="line">        <span class="comment"># # 梯度更新（参数更新）</span></span><br><span class="line">        <span class="comment"># optimizer.step()</span></span><br><span class="line">        <span class="comment"># # 学习率更新</span></span><br><span class="line">        <span class="comment"># scheduler.step()</span></span><br><span class="line">        <span class="comment"># # 梯度清零</span></span><br><span class="line">        <span class="comment"># optimizer.zero_grad()</span></span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        pc.gradient_accumulation_steps = 4 梯度累积的步数</span></span><br><span class="line"><span class="string">        如果设置了梯度累积的步数，并且大于1，此时则需要对损失进行缩放</span></span><br><span class="line"><span class="string">        原因：因为在累积的步数内，损失和梯度都会进行累积，而不是在每次批次结束之后立即更新权重，通过损失除以梯度累积的步数进行缩放，可以使最终得到的结果和实际应用大的batch_size得到的结果一致</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> pc.gradient_accumulation_steps &gt; <span class="number">1</span>:</span><br><span class="line">            loss = loss / pc.gradient_accumulation_steps  <span class="comment"># 对loss进行缩放</span></span><br><span class="line">        <span class="comment"># 反向传播（梯度计算）</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># 梯度裁剪</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        作用： 当max_norm/total_norm &lt; 1时，将梯度乘以缩放系数，从而防止梯度过大带来梯度爆炸或者训练不稳定</span></span><br><span class="line"><span class="string">        使用方式：torch.nn.utils.clip_grad_norm_()</span></span><br><span class="line"><span class="string">        参数：parameters:模型的参数；max_norm：最大的梯度范数，总的梯度范数超过这个值之后，就会进行梯度裁剪</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=pc.max_grad_norm)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 在到达梯度累积的步数之后，执行参数更新</span></span><br><span class="line">        <span class="keyword">if</span> (batch_idx + <span class="number">1</span>) % pc.gradient_accumulation_steps == <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 梯度更新（参数更新）</span></span><br><span class="line">            optimizer.step()</span><br><span class="line">            <span class="comment"># 学习率更新</span></span><br><span class="line">            scheduler.step()</span><br><span class="line">            <span class="comment"># 梯度清零</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3.统计指标并打印</span></span><br><span class="line">        <span class="comment"># 统计该batch的预测token的正确数与总数</span></span><br><span class="line">        batch_correct_num, batch_total_num = calculate_acc(logits, labels, ignore_index=pc.ignore_index)</span><br><span class="line">        <span class="comment"># print(f&#x27;batch_correct_num--&gt;&#123;batch_correct_num&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;batch_total_num--&gt;&#123;batch_total_num&#125;&#x27;)</span></span><br><span class="line">        total_correct_num += batch_correct_num</span><br><span class="line">        total_predict_num += batch_total_num</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每隔 pc.loss_step 批次打印一次训练结果</span></span><br><span class="line">        <span class="keyword">if</span> (batch_idx + <span class="number">1</span>) % pc.loss_step == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;epoch: <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>, batch: <span class="subst">&#123;batch_idx+<span class="number">1</span>&#125;</span>, &#x27;</span></span><br><span class="line">                  <span class="string">f&#x27;loss: <span class="subst">&#123;loss.item() * pc.gradient_accumulation_steps&#125;</span>, &#x27;</span></span><br><span class="line">                  <span class="string">f&#x27;batch_acc: <span class="subst">&#123;batch_correct_num/batch_total_num&#125;</span>, lr: <span class="subst">&#123;scheduler.get_last_lr()[<span class="number">0</span>]&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 整个轮次训练完成后，统计整个epoch的指标</span></span><br><span class="line">    epoch_mean_loss = total_loss / <span class="built_in">len</span>(train_dataloader)</span><br><span class="line">    epoch_mean_acc = total_correct_num / total_predict_num</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;第<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>轮次训练结束，平均的损失为<span class="subst">&#123;epoch_mean_loss&#125;</span>，平均的准确率为<span class="subst">&#123;epoch_mean_acc&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;完成本轮次训练所花时间为: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(datetime.now() - epoch_start_time))</span><br><span class="line">    <span class="keyword">return</span> epoch_mean_loss, epoch_mean_acc</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">valid_epoch</span>(<span class="params">model, valid_dataloader, epoch</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    :param model: 模型</span></span><br><span class="line"><span class="string">    :param valid_dataloader: 验证集的dataloader</span></span><br><span class="line"><span class="string">    :param epoch: 轮次</span></span><br><span class="line"><span class="string">    :return: 平均损失和平均准确率</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch:<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span> 开始评估...&quot;</span>)</span><br><span class="line">    <span class="comment"># 指明模型评估模式</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="comment"># 设置一些日志参数</span></span><br><span class="line">    epoch_start_time = datetime.now()</span><br><span class="line">    total_loss = <span class="number">0</span>  <span class="comment"># 记录整个epoch的loss之和</span></span><br><span class="line">    total_correct_num = <span class="number">0</span>  <span class="comment"># 记录整个epoch的预测正确的word的数量</span></span><br><span class="line">    total_predict_num = <span class="number">0</span>  <span class="comment"># 记录整个epoch的预测的word的总数量</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开始评估，遍历数据集</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():  <span class="comment"># 禁止计算梯度，来节省显存</span></span><br><span class="line">        <span class="keyword">for</span> batch_idx, (input_ids, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(valid_dataloader)):</span><br><span class="line">            <span class="comment"># 1.将数据送入模型，得到预测结果和损失</span></span><br><span class="line">            input_ids = input_ids.to(pc.device)</span><br><span class="line">            labels = labels.to(pc.device)</span><br><span class="line">            outputs = model(input_ids, labels=labels)</span><br><span class="line">            logits = outputs.logits</span><br><span class="line">            loss = outputs.loss</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 2.统计指标并打印</span></span><br><span class="line">            total_loss += loss.item()</span><br><span class="line">            <span class="comment"># 统计该batch的预测token的正确数与总数</span></span><br><span class="line">            batch_correct_num, batch_total_num = calculate_acc(logits, labels, ignore_index=pc.ignore_index)</span><br><span class="line">            total_correct_num += batch_correct_num</span><br><span class="line">            total_predict_num += batch_total_num</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 整个轮次评估完成后，统计整个epoch的指标</span></span><br><span class="line">    epoch_mean_loss = total_loss / <span class="built_in">len</span>(valid_dataloader)</span><br><span class="line">    epoch_mean_acc = total_correct_num / total_predict_num</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;第<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>轮次评估结束，平均的损失为<span class="subst">&#123;epoch_mean_loss&#125;</span>，平均的准确率为<span class="subst">&#123;epoch_mean_acc&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;完成本轮次评估所花时间为: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(datetime.now() - epoch_start_time))</span><br><span class="line">    <span class="keyword">return</span> epoch_mean_loss, epoch_mean_acc</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">model2train</span>():</span><br><span class="line">    <span class="comment"># todo:1 加载数据(训练集和验证集)</span></span><br><span class="line">    train_dataloader, valid_dataloader = get_data_loader(pc.train_path, pc.valid_path)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;训练集的长度--&gt;<span class="subst">&#123;<span class="built_in">len</span>(train_dataloader)&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;验证集的长度--&gt;<span class="subst">&#123;<span class="built_in">len</span>(valid_dataloader)&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="comment"># todo:2 加载模型</span></span><br><span class="line">    <span class="comment"># 2.1 创建模型</span></span><br><span class="line">    <span class="keyword">if</span> pc.pretrained_model:</span><br><span class="line">        <span class="comment"># 加载预训练模型</span></span><br><span class="line">        model = GPT2LMHeadModel.from_pretrained(pc.pretrained_model)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 初始化模型</span></span><br><span class="line">        model_config = GPT2Config.from_json_file(pc.config_json)</span><br><span class="line">        model = GPT2LMHeadModel(config=model_config)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;model--&gt;<span class="subst">&#123;model&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.2 将模型放到指定设备上</span></span><br><span class="line">    model.to(pc.device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.3 需要对比tokenizer的词表大小和模型的词表大小是否一致</span></span><br><span class="line">    tokenizer = BertTokenizer.from_pretrained(pc.vocab_path)</span><br><span class="line">    <span class="comment"># print(f&#x27;tokenizer.vocab_size--&gt;&#123;tokenizer.vocab_size&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;model.config.vocab_size--&gt;&#123;model.config.vocab_size&#125;&#x27;)</span></span><br><span class="line">    <span class="keyword">assert</span> tokenizer.vocab_size == model.config.vocab_size, <span class="string">&#x27;模型和tokenizer的词表大小不一致&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># todo:3 设置训练的组件</span></span><br><span class="line">    <span class="comment"># 优化器对象</span></span><br><span class="line">    optimizer = AdamW(model.parameters(), lr=pc.lr, eps=pc.eps)</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    优化点：学习率预热</span></span><br><span class="line"><span class="string">    学习率预热的目的：让模型在初始阶段更快的使用数据，避免训练过程中学习率过大或过小带来训练不稳定或者收敛速度太慢的问题，从而提高模型训练效果和泛化性能</span></span><br><span class="line"><span class="string">    实现方式：在初始阶段，将学习率从较小的值逐步增加到预设的初始值，然后按照我们设定的训练策略逐渐变小。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    get_linear_schedule_with_warmup: 使用这个方法来实现学习率预热，它的方式是从0以线性的方式增大到预设的学习率，然后再以线性的方式逐渐降低到0</span></span><br><span class="line"><span class="string">    参数： optimizer：优化器对象</span></span><br><span class="line"><span class="string">    num_warmup_steps：预热步数，指的是从0增加到预设的学习率所需的步数</span></span><br><span class="line"><span class="string">    num_training_steps: 指的是整个训练过程的总的步数，确切来说在给定的数据集上，参数更新的次数。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># total_steps = len(train_dataloader) * pc.epochs  # 不进行梯度累积时，总的训练步数</span></span><br><span class="line">    total_steps = <span class="built_in">len</span>(train_dataloader) * pc.epochs / pc.gradient_accumulation_steps  <span class="comment"># 进行梯度累积时，总的训练步数</span></span><br><span class="line">    scheduler = get_linear_schedule_with_warmup(optimizer,</span><br><span class="line">                                                num_warmup_steps=pc.warmup_steps,</span><br><span class="line">                                                num_training_steps=total_steps)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># todo:4 设置训练的参数</span></span><br><span class="line">    train_losses = []  <span class="comment"># 存储训练过程中，每轮训练的loss</span></span><br><span class="line">    valid_losses = []  <span class="comment"># 存储验证过程中，每轮验证的loss</span></span><br><span class="line">    best_valid_loss = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)  <span class="comment"># 最佳验证集loss</span></span><br><span class="line">    train_correct_rate = []  <span class="comment"># 存储训练过程中，每轮训练的预测准确率</span></span><br><span class="line">    valid_correct_rate = []  <span class="comment"># 存储验证过程中，每轮验证的预测准确率</span></span><br><span class="line">    <span class="comment"># todo:5 进行轮次训练</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(pc.epochs):</span><br><span class="line">        <span class="comment"># todo: 5.1 模型训练</span></span><br><span class="line">        train_loss, train_correct =  train_epoch(model, train_dataloader, optimizer, scheduler, epoch)</span><br><span class="line">        train_losses.append(train_loss)</span><br><span class="line">        train_correct_rate.append(train_correct)</span><br><span class="line">        <span class="comment"># todo: 5.2 模型评估</span></span><br><span class="line">        valid_loss, valid_correct = valid_epoch(model, valid_dataloader, epoch)</span><br><span class="line">        valid_losses.append(valid_loss)</span><br><span class="line">        valid_correct_rate.append(valid_correct)</span><br><span class="line">        <span class="comment"># todo: 5.3 保存模型</span></span><br><span class="line">        <span class="keyword">if</span> valid_loss &lt; best_valid_loss:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;当前最好的模型是第<span class="subst">&#123;epoch&#125;</span>轮次的，损失为<span class="subst">&#123;valid_loss&#125;</span>。&#x27;</span>)</span><br><span class="line">            best_valid_loss = valid_loss  <span class="comment"># 更新最小的验证集损失</span></span><br><span class="line">            <span class="comment"># 当前这个模型是更好的，需要进行保存</span></span><br><span class="line">            save_path = os.path.join(pc.save_model_path, <span class="string">&#x27;best_model&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(save_path):</span><br><span class="line">                os.mkdir(save_path)</span><br><span class="line">            model.save_pretrained(save_path)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;train_losses--&gt;<span class="subst">&#123;train_losses&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;valid_losses--&gt;<span class="subst">&#123;valid_losses&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;train_correct_rates--&gt;<span class="subst">&#123;train_correct_rate&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;valid_correct_rates--&gt;<span class="subst">&#123;valid_correct_rate&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    model2train()</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="补充知识点"><a href="#补充知识点" class="headerlink" title="补充知识点"></a>补充知识点</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">labels = torch.tensor([<span class="number">12</span>, <span class="number">1</span>, <span class="number">45</span>, -<span class="number">100</span>])</span><br><span class="line">ignore_index = -<span class="number">100</span></span><br><span class="line">max_index = torch.tensor([<span class="number">12</span>, <span class="number">8</span>, <span class="number">45</span>, <span class="number">65</span>])</span><br><span class="line"></span><br><span class="line">not_pad = labels.ne(ignore_index)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;not_pad---&gt;<span class="subst">&#123;not_pad&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">correct_position = max_index.eq(labels)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;correct_position---&gt;<span class="subst">&#123;correct_position&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">correct_num = correct_position.masked_select(not_pad)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;correct_num---&gt;<span class="subst">&#123;correct_num&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;正确的个数---&gt;<span class="subst">&#123;correct_num.<span class="built_in">sum</span>()&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;总的个数---&gt;<span class="subst">&#123;not_pad.<span class="built_in">sum</span>()&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250824164122110.png" alt="image-20250824164122110"></p>
<h3 id="functions-tools-py代码"><a href="#functions-tools-py代码" class="headerlink" title="functions_tools.py代码"></a>functions_tools.py代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_acc</span>(<span class="params">logits, labels, ignore_index=-<span class="number">100</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    计算模型预测结果 准确的word个数和总的word个数，这些个数中都是不包含-100标签所在的位置的</span></span><br><span class="line"><span class="string">    :param logits: 模型的预测输出</span></span><br><span class="line"><span class="string">    :param labels: 真实标签</span></span><br><span class="line"><span class="string">    :param ignore_index: 在计算时，需要忽略的标签索引，默认为-100</span></span><br><span class="line"><span class="string">    :return: correct_num 预测正确的个数, total_num 总的个数</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># print(f&#x27;原始logits--&gt;&#123;logits.shape&#125;&#x27;)  # [8, 49, 13317]</span></span><br><span class="line">    <span class="comment"># print(f&#x27;原始labels--&gt;&#123;labels.shape&#125;&#x27;)  # [8, 49]</span></span><br><span class="line">    <span class="comment"># 1.处理输入数据，去掉预测结果的最后一个字符，去掉标签的第一个字符</span></span><br><span class="line">    logits = logits[:, :-<span class="number">1</span>, :]</span><br><span class="line">    labels = labels[:, <span class="number">1</span>:]</span><br><span class="line">    <span class="comment"># print(f&#x27;位移后的logits--&gt;&#123;logits.shape&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;位移后的labels--&gt;&#123;labels.shape&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># 为了方便后续的计算，需要将 logits 转换成2维，而 labels 转换成1维</span></span><br><span class="line">    logits = logits.contiguous().view(-<span class="number">1</span>, logits.shape[-<span class="number">1</span>])</span><br><span class="line">    labels = labels.contiguous().view(-<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># print(f&#x27;降维后的logits--&gt;&#123;logits.shape&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;降维后的labels--&gt;&#123;labels.shape&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.取出最大的概率值，并返回最大概率的索引</span></span><br><span class="line">    max_index = logits.argmax(dim=-<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># print(f&#x27;最大概率的索引--&gt;&#123;max_index.shape, max_index&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.计算预测正确的个数和总的个数</span></span><br><span class="line">    <span class="comment"># print(f&#x27;labels---&gt;&#123;labels&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># ne()的作用是判断两个张量的元素是否相等，返回一个布尔张量，如果两个元素相等，返回False，否则返回True</span></span><br><span class="line">    not_pad = labels.ne(ignore_index)</span><br><span class="line">    <span class="comment"># print(f&#x27;not_pad---&gt;&#123;not_pad&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># eq()的作用是判断两个张量的元素是否相等，返回一个布尔张量，如果两个元素相等，返回True，否则返回False</span></span><br><span class="line">    correct_position = max_index.eq(labels)</span><br><span class="line">    <span class="comment"># print(f&#x27;correct_position---&gt;&#123;correct_position&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 需要correct_position中取出-100位置的数据，也就是说只取 pad_mask 为True的数据</span></span><br><span class="line">    <span class="comment"># masked_select(boolen张量) 将boolen张量中为True的数据取出来</span></span><br><span class="line">    correct_num = correct_position.masked_select(not_pad).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="comment"># print(f&#x27;correct_position.masked_select(not_pad)---&gt;&#123;correct_position.masked_select(not_pad)&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;correct_num---&gt;&#123;correct_num&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 总的个数</span></span><br><span class="line">    total_num = not_pad.<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">return</span> correct_num, total_num</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="5-模型预测（人机交互）"><a href="#5-模型预测（人机交互）" class="headerlink" title="5. 模型预测（人机交互）"></a>5. 模型预测（人机交互）</h2><ul>
<li>使用训练好的模型，进行人机交互，输入Ctrl+Z结束对话之后，聊天记录将保存到sample目录下的sample.txt文件中。</li>
</ul>
<p>思路：</p>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250824201058908.png" alt="image-20250824201058908"></p>
<p>代码位置：llm_tuning&#x2F;Gpt2_Chatbot&#x2F;interact.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> GPT2LMHeadModel, BertTokenizer</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> Gpt2_Chatbot.parameter_config <span class="keyword">import</span> ParameterConfig</span><br><span class="line"></span><br><span class="line">pc = ParameterConfig()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">top_k_top_p_filtering</span>(<span class="params">logits, top_k=<span class="number">0</span>, top_p=<span class="number">0.0</span>, filter_value=-<span class="built_in">float</span>(<span class="params"><span class="string">&#x27;Inf&#x27;</span></span>)</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    使用top-k和/或nucleus（top-p）筛选来过滤logits的分布</span></span><br><span class="line"><span class="string">    :param logits: 最后一个token的logits的分布，形状为（词汇大小）</span></span><br><span class="line"><span class="string">    :param top_k: top_k &gt; 0: 保留概率最高的top k个token（top-k筛选）</span></span><br><span class="line"><span class="string">    :param top_p: top_p &gt; 0.0: 保留累积概率大于等于top_p的top token（nucleus筛选）</span></span><br><span class="line"><span class="string">    :param filter_value: 极小值</span></span><br><span class="line"><span class="string">    :return: logits: 过滤后的logits分布，其中低概率标记被设置为 filter_value。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 确保logits的维度为1，这里只处理批量大小为1的情况。</span></span><br><span class="line">    <span class="keyword">assert</span> logits.dim() == <span class="number">1</span></span><br><span class="line">    <span class="comment"># 对top_k值进行安全性检查，防止它超过logits最后一个维度的大小，避免运行时错误。</span></span><br><span class="line">    top_k = <span class="built_in">min</span>(top_k, logits.size(-<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> top_k &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 移除概率小于top_k标记</span></span><br><span class="line">        <span class="comment"># torch.topk()返回最后一维中最大的top_k个元素，返回值为二维(values, indices)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;torch.topk(logits, top_k)---&gt;&#123;torch.topk(logits, top_k)&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;torch.topk(logits, top_k)[0]--&gt;&#123;torch.topk(logits, top_k)[0]&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;torch.topk(logits, top_k)[0][-1]--&gt;&#123;torch.topk(logits, top_k)[0][-1]&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 判断logits的值，如果小于top_k标记，则设置为filter_value</span></span><br><span class="line">        indices_to_remove = logits &lt; torch.topk(logits, top_k)[<span class="number">0</span>][-<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># print(f&#x27;indices_to_remove---&gt;&#123;indices_to_remove&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;logits---&gt;&#123;logits&#125;&#x27;)</span></span><br><span class="line">        logits[indices_to_remove] = filter_value  <span class="comment"># 对于topk之外的其他元素的logits值设为负无穷</span></span><br><span class="line">        <span class="comment"># print(f&#x27;过滤后的logits---&gt;&#123;logits&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> top_p &gt; <span class="number">0.0</span>:</span><br><span class="line">        sorted_logits, sorted_indices = torch.sort(logits, descending=<span class="literal">True</span>)  <span class="comment"># 对logits进行递减排序</span></span><br><span class="line">        <span class="comment"># print(f&#x27;sorted_logits--&gt;&#123;sorted_logits&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;sorted_indices--&gt;&#123;sorted_indices&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># F.softmax(sorted_logits, dim=-1)：将排序后的 logits 转为概率分布</span></span><br><span class="line">        <span class="comment"># torch.cumsum(..., dim=-1)：计算累积概率</span></span><br><span class="line">        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-<span class="number">1</span>), dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对应位置为 True 的 token 是 累积概率超过 top_p 阈值的 token，通常需要被移除</span></span><br><span class="line">        sorted_indices_to_remove = cumulative_probs &gt; top_p</span><br><span class="line">        <span class="comment"># print(f&#x27;sorted_indices_to_remove1--&gt;&#123;sorted_indices_to_remove&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 将索引向右移动，以确保即使第一个token超过阈值也能保留</span></span><br><span class="line">        sorted_indices_to_remove[..., <span class="number">1</span>:] = sorted_indices_to_remove[..., :-<span class="number">1</span>].clone()  <span class="comment"># 将索引向右移动一位</span></span><br><span class="line">        sorted_indices_to_remove[..., <span class="number">0</span>] = <span class="number">0</span>  <span class="comment"># 将第一个token设为False，确保第一个 token 被保留</span></span><br><span class="line">        <span class="comment"># print(f&#x27;sorted_indices_to_remove2---&gt;&#123;sorted_indices_to_remove&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将需要移除的token设置为filter_value。</span></span><br><span class="line">        indices_to_remove = sorted_indices[sorted_indices_to_remove]</span><br><span class="line">        <span class="comment"># print(f&#x27;indices_to_remove---&gt;&#123;indices_to_remove&#125;&#x27;)</span></span><br><span class="line">        logits[indices_to_remove] = filter_value</span><br><span class="line">        <span class="comment"># print(f&#x27;logits---&gt;&#123;logits&#125;&#x27;)</span></span><br><span class="line">    <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">model2predict</span>():</span><br><span class="line">    <span class="comment"># 1、加载模型</span></span><br><span class="line">    model_path = os.path.join(pc.save_model_path, <span class="string">&#x27;best_model&#x27;</span>)</span><br><span class="line">    model = GPT2LMHeadModel.from_pretrained(model_path).to(pc.device)</span><br><span class="line">    <span class="comment"># 将模型设置为预测模式</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载分词器</span></span><br><span class="line">    tokenizer = BertTokenizer.from_pretrained(pc.vocab_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将用户和机器人的对话保存到文件中</span></span><br><span class="line">    f = <span class="built_in">open</span>(os.path.join(pc.save_samples_path, <span class="string">&#x27;samples.txt&#x27;</span>), <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2、处理数据，送入模型预测</span></span><br><span class="line">    <span class="comment"># 2.1 需要保存用户上下文，将上下文一起送入模型中</span></span><br><span class="line">    <span class="comment"># 使用history列表来存储用户的问题和模型的输出</span></span><br><span class="line">    history = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># 获取用户输入</span></span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&#x27;请输入问题：&#x27;</span>)</span><br><span class="line">        <span class="comment"># print(f&#x27;user_input--&gt;&#123;user_input&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 将用户的问题写入文件中</span></span><br><span class="line">        f.write(<span class="string">&#x27;用户问题：&#x27;</span> + user_input + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">        query_ids = tokenizer.encode(<span class="string">&#x27;用户问题：&#x27;</span> + user_input, add_special_tokens=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># print(f&#x27;query_ids--&gt;&#123;query_ids&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 将问题ids加入到history中</span></span><br><span class="line">        history.append(query_ids)</span><br><span class="line">        <span class="comment"># print(f&#x27;history--&gt;&#123;history&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2.2每次送入大模型时，需要将用户的问题和模型的输出拼接到一起送入大模型</span></span><br><span class="line">        input_ids = [tokenizer.cls_token_id]  <span class="comment"># 给大模型的输入需要以[CLS]开头</span></span><br><span class="line">        <span class="comment"># 遍历history列表，将列表中的 用户问题 和 模型输出 拼接成输入，送给大模型</span></span><br><span class="line">        <span class="keyword">for</span> ids <span class="keyword">in</span> history[-pc.max_history_len:]:  <span class="comment"># 为了防止输入过长，只取最后5个历史记录</span></span><br><span class="line">            input_ids.extend(ids)</span><br><span class="line">            <span class="comment"># 在每个句子结束之后，添加[SEP]作为分割</span></span><br><span class="line">            input_ids.append(tokenizer.sep_token_id)</span><br><span class="line">        <span class="comment"># print(f&#x27;遍历完history的input_ids--&gt;&#123;input_ids&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 把数据转为张量</span></span><br><span class="line">        input_ids = torch.tensor(input_ids).long().to(pc.device)</span><br><span class="line">        <span class="comment"># 2.3 送入模型进行预测</span></span><br><span class="line">        <span class="comment"># 初始化一个空列表，用来存储模型输出的ids</span></span><br><span class="line">        outputs_ids = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(pc.max_len):</span><br><span class="line">            outputs = model(input_ids).logits</span><br><span class="line">            <span class="comment"># print(f&#x27;outputs--&gt;&#123;outputs.shape&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># 直接取最后一行的结果，即为模型输出的概率分布</span></span><br><span class="line">            next_token_logits = outputs[-<span class="number">1</span>, :]</span><br><span class="line">            <span class="comment"># print(f&#x27;next_token_logits--&gt;&#123;next_token_logits.shape&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># print(f&#x27;next_token_logits--&gt;&#123;next_token_logits&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># 2.4 模型预测结果的选择</span></span><br><span class="line">            <span class="comment"># 1）对于已经生成的结果中的每个token添加一个重复惩罚项，降低其生成概率，从而缓解复读机问题。</span></span><br><span class="line">            <span class="keyword">for</span> <span class="built_in">id</span> <span class="keyword">in</span> <span class="built_in">set</span>(outputs_ids):</span><br><span class="line">                <span class="comment"># print(f&#x27;id--&gt;&#123;id&#125;&#x27;)</span></span><br><span class="line">                <span class="comment"># print(f&#x27;next_token_logits[id]--&gt;&#123;next_token_logits[id]&#125;&#x27;)</span></span><br><span class="line">                <span class="keyword">if</span> next_token_logits[<span class="built_in">id</span>] &gt; <span class="number">0</span>:</span><br><span class="line">                    next_token_logits[<span class="built_in">id</span>] /= pc.repetition_penalty</span><br><span class="line">                <span class="keyword">else</span>:  <span class="comment"># 如果这个logits为负数，则需要乘以重复惩罚项</span></span><br><span class="line">                    next_token_logits[<span class="built_in">id</span>] *= pc.repetition_penalty</span><br><span class="line">            <span class="comment"># 2）为了避免预测结果中出现[UNK]字符，需要将[UNK]这个token的logits设为无穷小。</span></span><br><span class="line">            next_token_logits[tokenizer.unk_token_id] = -<span class="built_in">float</span>(<span class="string">&#x27;Inf&#x27;</span>)</span><br><span class="line">            <span class="comment"># 3）使用了top_k_top_p_filtering策略，这个策略的作用是根据给定的top_k参数和top_p参数，选出前几个高概率的预测结果，并且累积概率不超过top_p。这样做的一个效果就是：可以保证文本生成质量的同时，具有一定的多样性。具体实现时，就是将不符合要求的token的概率设置成无穷小。</span></span><br><span class="line">            filtered_logits = top_k_top_p_filtering(next_token_logits, top_k=pc.topk, top_p=pc.topp)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 4）使用torch.multinomial方法，对预测结果中的token进行随机取样，这个函数的特性是，token的概率越大，被抽取的几率就越高。</span></span><br><span class="line">            next_token = torch.multinomial(F.softmax(filtered_logits, dim=-<span class="number">1</span>), num_samples=<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># print(f&#x27;next_token--&gt;&#123;next_token&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 如果预测结果是[SEP]，则说明已经生成了一个完整的句子，可以结束预测</span></span><br><span class="line">            <span class="keyword">if</span> next_token.item() == tokenizer.sep_token_id:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 将预测结果加入到outputs_ids中</span></span><br><span class="line">            outputs_ids.append(next_token.item())</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 将 next_token 和 原来的 input_ids 连接起来，作为下一次输入</span></span><br><span class="line">            input_ids = torch.cat([input_ids, next_token], dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print(f&#x27;outputs_ids--&gt;&#123;outputs_ids&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 将模型的回复加到history中</span></span><br><span class="line">        model_ids = tokenizer.encode(<span class="string">&quot;模型回答：&quot;</span>, add_special_tokens=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># print(f&#x27;model_ids+outputs_ids--&gt;&#123;model_ids+outputs_ids&#125;&#x27;)</span></span><br><span class="line">        history.append(model_ids+outputs_ids)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将预测结果ids转为文本</span></span><br><span class="line">        answer = tokenizer.convert_ids_to_tokens(outputs_ids)</span><br><span class="line">        <span class="comment"># print(f&#x27;answer--&gt;&#123;answer&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 打印机器人的回复</span></span><br><span class="line">        answer_sentence = <span class="string">&#x27;&#x27;</span>.join(answer)</span><br><span class="line">        f.write(<span class="string">&#x27;模型回答：&#x27;</span> + answer_sentence + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;模型回答：&#x27;</span>, answer_sentence)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    model2predict()</span><br></pre></td></tr></table></figure>



<h2 id="6-基于Flask框架web开发-了解"><a href="#6-基于Flask框架web开发-了解" class="headerlink" title="6. 基于Flask框架web开发(了解)"></a>6. 基于Flask框架web开发(了解)</h2><ul>
<li>对interact.py进行调整, 去除while无限循环，由前端保存history，只需要对传入的句子进行预测即可。</li>
</ul>
<p>代码位置：llm_tuning&#x2F;Gpt2_Chatbot&#x2F;flask_predict.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> GPT2LMHeadModel, BertTokenizer</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> Gpt2_Chatbot.parameter_config <span class="keyword">import</span> ParameterConfig</span><br><span class="line"></span><br><span class="line">pc = ParameterConfig()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">top_k_top_p_filtering</span>(<span class="params">logits, top_k=<span class="number">0</span>, top_p=<span class="number">0.0</span>, filter_value=-<span class="built_in">float</span>(<span class="params"><span class="string">&#x27;Inf&#x27;</span></span>)</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    使用top-k和/或nucleus（top-p）筛选来过滤logits的分布</span></span><br><span class="line"><span class="string">    :param logits: 最后一个token的logits的分布，形状为（词汇大小）</span></span><br><span class="line"><span class="string">    :param top_k: top_k &gt; 0: 保留概率最高的top k个token（top-k筛选）</span></span><br><span class="line"><span class="string">    :param top_p: top_p &gt; 0.0: 保留累积概率大于等于top_p的top token（nucleus筛选）</span></span><br><span class="line"><span class="string">    :param filter_value: 极小值</span></span><br><span class="line"><span class="string">    :return: logits: 过滤后的logits分布，其中低概率标记被设置为 filter_value。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 确保logits的维度为1，这里只处理批量大小为1的情况。</span></span><br><span class="line">    <span class="keyword">assert</span> logits.dim() == <span class="number">1</span></span><br><span class="line">    <span class="comment"># 对top_k值进行安全性检查，防止它超过logits最后一个维度的大小，避免运行时错误。</span></span><br><span class="line">    top_k = <span class="built_in">min</span>(top_k, logits.size(-<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> top_k &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 移除概率小于top_k标记</span></span><br><span class="line">        <span class="comment"># torch.topk()返回最后一维中最大的top_k个元素，返回值为二维(values, indices)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;torch.topk(logits, top_k)---&gt;&#123;torch.topk(logits, top_k)&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;torch.topk(logits, top_k)[0]--&gt;&#123;torch.topk(logits, top_k)[0]&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;torch.topk(logits, top_k)[0][-1]--&gt;&#123;torch.topk(logits, top_k)[0][-1]&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 判断logits的值，如果小于top_k标记，则设置为filter_value</span></span><br><span class="line">        indices_to_remove = logits &lt; torch.topk(logits, top_k)[<span class="number">0</span>][-<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># print(f&#x27;indices_to_remove---&gt;&#123;indices_to_remove&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;logits---&gt;&#123;logits&#125;&#x27;)</span></span><br><span class="line">        logits[indices_to_remove] = filter_value  <span class="comment"># 对于topk之外的其他元素的logits值设为负无穷</span></span><br><span class="line">        <span class="comment"># print(f&#x27;过滤后的logits---&gt;&#123;logits&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> top_p &gt; <span class="number">0.0</span>:</span><br><span class="line">        sorted_logits, sorted_indices = torch.sort(logits, descending=<span class="literal">True</span>)  <span class="comment"># 对logits进行递减排序</span></span><br><span class="line">        <span class="comment"># print(f&#x27;sorted_logits--&gt;&#123;sorted_logits&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;sorted_indices--&gt;&#123;sorted_indices&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># F.softmax(sorted_logits, dim=-1)：将排序后的 logits 转为概率分布</span></span><br><span class="line">        <span class="comment"># torch.cumsum(..., dim=-1)：计算累积概率</span></span><br><span class="line">        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-<span class="number">1</span>), dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对应位置为 True 的 token 是 累积概率超过 top_p 阈值的 token，通常需要被移除</span></span><br><span class="line">        sorted_indices_to_remove = cumulative_probs &gt; top_p</span><br><span class="line">        <span class="comment"># print(f&#x27;sorted_indices_to_remove1--&gt;&#123;sorted_indices_to_remove&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 将索引向右移动，以确保即使第一个token超过阈值也能保留</span></span><br><span class="line">        sorted_indices_to_remove[..., <span class="number">1</span>:] = sorted_indices_to_remove[..., :-<span class="number">1</span>].clone()  <span class="comment"># 将索引向右移动一位</span></span><br><span class="line">        sorted_indices_to_remove[..., <span class="number">0</span>] = <span class="number">0</span>  <span class="comment"># 将第一个token设为False，确保第一个 token 被保留</span></span><br><span class="line">        <span class="comment"># print(f&#x27;sorted_indices_to_remove2---&gt;&#123;sorted_indices_to_remove&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将需要移除的token设置为filter_value。</span></span><br><span class="line">        indices_to_remove = sorted_indices[sorted_indices_to_remove]</span><br><span class="line">        <span class="comment"># print(f&#x27;indices_to_remove---&gt;&#123;indices_to_remove&#125;&#x27;)</span></span><br><span class="line">        logits[indices_to_remove] = filter_value</span><br><span class="line">        <span class="comment"># print(f&#x27;logits---&gt;&#123;logits&#125;&#x27;)</span></span><br><span class="line">    <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、加载模型</span></span><br><span class="line">model_path = os.path.join(pc.save_model_path, <span class="string">&#x27;best_model&#x27;</span>)</span><br><span class="line">model = GPT2LMHeadModel.from_pretrained(model_path).to(pc.device)</span><br><span class="line"><span class="comment"># 将模型设置为预测模式</span></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载分词器</span></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(pc.vocab_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">model_predict</span>(<span class="params">text, history</span>):</span><br><span class="line">    <span class="comment"># 2.1 获取用户输入</span></span><br><span class="line">    query_ids = tokenizer.encode(<span class="string">&#x27;用户问题：&#x27;</span> + text, add_special_tokens=<span class="literal">False</span>)</span><br><span class="line">    <span class="comment"># print(f&#x27;query_ids--&gt;&#123;query_ids&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># 将问题ids加入到history中</span></span><br><span class="line">    history.append(query_ids)</span><br><span class="line">    <span class="comment"># print(f&#x27;history--&gt;&#123;history&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.2每次送入大模型时，需要将用户的问题和模型的输出拼接到一起送入大模型</span></span><br><span class="line">    input_ids = [tokenizer.cls_token_id]  <span class="comment"># 给大模型的输入需要以[CLS]开头</span></span><br><span class="line">    <span class="comment"># 遍历history列表，将列表中的 用户问题 和 模型输出 拼接成输入，送给大模型</span></span><br><span class="line">    <span class="keyword">for</span> ids <span class="keyword">in</span> history[-pc.max_history_len:]:  <span class="comment"># 为了防止输入过长，只取最后5个历史记录</span></span><br><span class="line">        input_ids.extend(ids)</span><br><span class="line">        <span class="comment"># 在每个句子结束之后，添加[SEP]作为分割</span></span><br><span class="line">        input_ids.append(tokenizer.sep_token_id)</span><br><span class="line">    <span class="comment"># print(f&#x27;遍历完history的input_ids--&gt;&#123;input_ids&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 把数据转为张量</span></span><br><span class="line">    input_ids = torch.tensor(input_ids).long().to(pc.device)</span><br><span class="line">    <span class="comment"># 2.3 送入模型进行预测</span></span><br><span class="line">    <span class="comment"># 初始化一个空列表，用来存储模型输出的ids</span></span><br><span class="line">    outputs_ids = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(pc.max_len):</span><br><span class="line">        outputs = model(input_ids).logits</span><br><span class="line">        <span class="comment"># print(f&#x27;outputs--&gt;&#123;outputs.shape&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 直接取最后一行的结果，即为模型输出的概率分布</span></span><br><span class="line">        next_token_logits = outputs[-<span class="number">1</span>, :]</span><br><span class="line">        <span class="comment"># print(f&#x27;next_token_logits--&gt;&#123;next_token_logits.shape&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;next_token_logits--&gt;&#123;next_token_logits&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 2.4 模型预测结果的选择</span></span><br><span class="line">        <span class="comment"># 1）对于已经生成的结果中的每个token添加一个重复惩罚项，降低其生成概率，从而缓解复读机问题。</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">id</span> <span class="keyword">in</span> <span class="built_in">set</span>(outputs_ids):</span><br><span class="line">            <span class="comment"># print(f&#x27;id--&gt;&#123;id&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># print(f&#x27;next_token_logits[id]--&gt;&#123;next_token_logits[id]&#125;&#x27;)</span></span><br><span class="line">            <span class="keyword">if</span> next_token_logits[<span class="built_in">id</span>] &gt; <span class="number">0</span>:</span><br><span class="line">                next_token_logits[<span class="built_in">id</span>] /= pc.repetition_penalty</span><br><span class="line">            <span class="keyword">else</span>:  <span class="comment"># 如果这个logits为负数，则需要乘以重复惩罚项</span></span><br><span class="line">                next_token_logits[<span class="built_in">id</span>] *= pc.repetition_penalty</span><br><span class="line">        <span class="comment"># 2）为了避免预测结果中出现[UNK]字符，需要将[UNK]这个token的logits设为无穷小。</span></span><br><span class="line">        next_token_logits[tokenizer.unk_token_id] = -<span class="built_in">float</span>(<span class="string">&#x27;Inf&#x27;</span>)</span><br><span class="line">        <span class="comment"># 3）使用了top_k_top_p_filtering策略，这个策略的作用是根据给定的top_k参数和top_p参数，选出前几个高概率的预测结果，并且累积概率不超过top_p。这样做的一个效果就是：可以保证文本生成质量的同时，具有一定的多样性。具体实现时，就是将不符合要求的token的概率设置成无穷小。</span></span><br><span class="line">        filtered_logits = top_k_top_p_filtering(next_token_logits, top_k=pc.topk, top_p=pc.topp)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4）使用torch.multinomial方法，对预测结果中的token进行随机取样，这个函数的特性是，token的概率越大，被抽取的几率就越高。</span></span><br><span class="line">        next_token = torch.multinomial(F.softmax(filtered_logits, dim=-<span class="number">1</span>), num_samples=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># print(f&#x27;next_token--&gt;&#123;next_token&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果预测结果是[SEP]，则说明已经生成了一个完整的句子，可以结束预测</span></span><br><span class="line">        <span class="keyword">if</span> next_token.item() == tokenizer.sep_token_id:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将预测结果加入到outputs_ids中</span></span><br><span class="line">        outputs_ids.append(next_token.item())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将 next_token 和 原来的 input_ids 连接起来，作为下一次输入</span></span><br><span class="line">        input_ids = torch.cat([input_ids, next_token], dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># print(f&#x27;outputs_ids--&gt;&#123;outputs_ids&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># 将模型的回复加到history中</span></span><br><span class="line">    model_ids = tokenizer.encode(<span class="string">&quot;模型回答：&quot;</span>, add_special_tokens=<span class="literal">False</span>)</span><br><span class="line">    <span class="comment"># print(f&#x27;model_ids+outputs_ids--&gt;&#123;model_ids+outputs_ids&#125;&#x27;)</span></span><br><span class="line">    history.append(model_ids+outputs_ids)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将预测结果ids转为文本</span></span><br><span class="line">    answer = tokenizer.convert_ids_to_tokens(outputs_ids)</span><br><span class="line">    <span class="comment"># print(f&#x27;answer--&gt;&#123;answer&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># 打印机器人的回复</span></span><br><span class="line">    answer_sentence = <span class="string">&#x27;&#x27;</span>.join(answer)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> answer_sentence, history</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    text = <span class="string">&#x27;你好&#x27;</span></span><br><span class="line">    history = []</span><br><span class="line">    answer_sentence, history = model_predict(text, history)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;answer_sentence--&gt;<span class="subst">&#123;answer_sentence&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;history--&gt;<span class="subst">&#123;history&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    text = <span class="string">&#x27;头疼怎么办&#x27;</span></span><br><span class="line">    answer_sentence, history = model_predict(text, history)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;answer_sentence--&gt;<span class="subst">&#123;answer_sentence&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;history--&gt;<span class="subst">&#123;history&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>基于Flask框架的web后端接口</li>
</ul>
<p>这部分可以用大模型生成，写好提示词即可。</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">使用大模型生成web前后端代码,</span> <span class="string">描述如下:</span></span><br><span class="line"><span class="attr">现在你是一个代码专家,</span> <span class="string">目前已经训练好了一个模型, 并且已经将该模型进行了封装, 函数名为model_predict(), 该函数传入参数为text, history，其中text为用户问题，history为一个列表，用来保存上下文信息；返回值为response, history，其中response为预测结果，history为列表。</span></span><br><span class="line"></span><br><span class="line"><span class="attr">现在需要你基于Flask框架,</span> <span class="string">对该函数进行API接口封装制作, 并且希望能够制作一个简单的web界面, 界面的主要功能呈现如下:</span></span><br><span class="line"><span class="attr">1.</span> <span class="string">用户输入问题和history列表, 然后返回预测结果和history。这个history不需要前端往里边添加内容，只需要保存这个变量即可。在前端页面刷新时，这个变量清空为[]。</span></span><br><span class="line"><span class="attr">2.</span> <span class="string">将用户和模型的聊天信息保留在页面上展示</span></span><br><span class="line"><span class="attr">3.</span> <span class="string">页面标题名称叫做:黑马医疗问诊机器人</span></span><br><span class="line"><span class="attr">4.</span> <span class="string">页面标题和输入对话框布局要对称, 并且用不同的颜色渲染</span></span><br><span class="line"><span class="attr">请给出详细的app.py和index.html的代码</span></span><br></pre></td></tr></table></figure>

<p>代码位置：llm_tuning&#x2F;Gpt2_Chatbot&#x2F;app.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask, request, jsonify, render_template</span><br><span class="line"><span class="keyword">from</span> Gpt2_Chatbot.flask_predict <span class="keyword">import</span> model_predict</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"><span class="comment"># API 接口</span></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/api/predict&#x27;</span>, methods=[<span class="string">&#x27;POST&#x27;</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>():</span><br><span class="line">    data = request.json <span class="keyword">or</span> &#123;&#125;</span><br><span class="line">    question = data.get(<span class="string">&#x27;question&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Question--&gt;<span class="subst">&#123;question&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="comment"># 前端传过来一个 history 列表（例如：[[872, 1962], [872, 1962, 8024, 6821...]]）</span></span><br><span class="line">    history = data.get(<span class="string">&#x27;history&#x27;</span>, [])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;History--&gt;<span class="subst">&#123;history&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 调用模型预测，假设 model_predict 返回 (answer, new_history)</span></span><br><span class="line">    answer, new_history = model_predict(question, history=history)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 把 answer 和更新后的 history 一并返回（前端保存并更新history，企业中也可以将history其保存到数据库或文件中）</span></span><br><span class="line">    <span class="keyword">return</span> jsonify(&#123;<span class="string">&#x27;question&#x27;</span>: question, <span class="string">&#x27;answer&#x27;</span>: answer, <span class="string">&#x27;history&#x27;</span>: new_history&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Web 界面</span></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">index</span>():</span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">&#x27;index.html&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app.run(debug=<span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>web前端代码</li>
</ul>
<p>代码位置：llm_tuning&#x2F;Gpt2_Chatbot&#x2F;templates&#x2F;index.html</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">&quot;zh-CN&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">name</span>=<span class="string">&quot;viewport&quot;</span> <span class="attr">content</span>=<span class="string">&quot;width=device-width, initial-scale=1.0&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>黑马医疗问诊机器人<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">style</span>&gt;</span><span class="language-css"></span></span><br><span class="line"><span class="language-css">        <span class="selector-tag">body</span> &#123;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">font-family</span>: <span class="string">&#x27;Arial&#x27;</span>, sans-serif;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">max-width</span>: <span class="number">800px</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">margin</span>: <span class="number">0</span> auto;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">padding</span>: <span class="number">20px</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">background-color</span>: <span class="number">#f5f5f5</span>;</span></span><br><span class="line"><span class="language-css">        &#125;</span></span><br><span class="line"><span class="language-css">        <span class="selector-class">.header</span> &#123;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">text-align</span>: center;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">margin-bottom</span>: <span class="number">30px</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">padding</span>: <span class="number">20px</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">background</span>: <span class="built_in">linear-gradient</span>(<span class="number">135deg</span>, <span class="number">#4b6cb7</span>, <span class="number">#182848</span>);</span></span><br><span class="line"><span class="language-css">            <span class="attribute">color</span>: white;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">border-radius</span>: <span class="number">10px</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">box-shadow</span>: <span class="number">0</span> <span class="number">4px</span> <span class="number">8px</span> <span class="built_in">rgba</span>(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0.1</span>);</span></span><br><span class="line"><span class="language-css">        &#125;</span></span><br><span class="line"><span class="language-css">        <span class="selector-class">.chat-container</span> &#123;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">background-color</span>: white;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">border-radius</span>: <span class="number">10px</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">box-shadow</span>: <span class="number">0</span> <span class="number">4px</span> <span class="number">8px</span> <span class="built_in">rgba</span>(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0.1</span>);</span></span><br><span class="line"><span class="language-css">            <span class="attribute">padding</span>: <span class="number">20px</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">margin-bottom</span>: <span class="number">20px</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">height</span>: <span class="number">400px</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">overflow-y</span>: auto;</span></span><br><span class="line"><span class="language-css">        &#125;</span></span><br><span class="line"><span class="language-css">        <span class="selector-class">.message</span> &#123;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">margin-bottom</span>: <span class="number">15px</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">padding</span>: <span class="number">10px</span> <span class="number">15px</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">border-radius</span>: <span class="number">18px</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">max-width</span>: <span class="number">70%</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">word-wrap</span>: break-word;</span></span><br><span class="line"><span class="language-css">        &#125;</span></span><br><span class="line"><span class="language-css">        <span class="selector-class">.user-message</span> &#123;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">background-color</span>: <span class="number">#e3f2fd</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">margin-left</span>: auto;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">border-bottom-right-radius</span>: <span class="number">5px</span>;</span></span><br><span class="line"><span class="language-css">        &#125;</span></span><br><span class="line"><span class="language-css">        <span class="selector-class">.bot-message</span> &#123;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">background-color</span>: <span class="number">#f1f1f1</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">margin-right</span>: auto;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">border-bottom-left-radius</span>: <span class="number">5px</span>;</span></span><br><span class="line"><span class="language-css">        &#125;</span></span><br><span class="line"><span class="language-css">        <span class="selector-class">.input-container</span> &#123;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">display</span>: flex;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">gap</span>: <span class="number">10px</span>;</span></span><br><span class="line"><span class="language-css">        &#125;</span></span><br><span class="line"><span class="language-css">        <span class="selector-id">#user-input</span> &#123;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">flex</span>: <span class="number">1</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">padding</span>: <span class="number">12px</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">border</span>: <span class="number">1px</span> solid <span class="number">#ddd</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">border-radius</span>: <span class="number">20px</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">font-size</span>: <span class="number">16px</span>;</span></span><br><span class="line"><span class="language-css">        &#125;</span></span><br><span class="line"><span class="language-css">        <span class="selector-id">#send-button</span> &#123;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">padding</span>: <span class="number">12px</span> <span class="number">20px</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">background-color</span>: <span class="number">#4b6cb7</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">color</span>: white;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">border</span>: none;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">border-radius</span>: <span class="number">20px</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">cursor</span>: pointer;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">font-size</span>: <span class="number">16px</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">transition</span>: background-color <span class="number">0.3s</span>;</span></span><br><span class="line"><span class="language-css">        &#125;</span></span><br><span class="line"><span class="language-css">        <span class="selector-id">#send-button</span><span class="selector-pseudo">:hover</span> &#123;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">background-color</span>: <span class="number">#3a56a1</span>;</span></span><br><span class="line"><span class="language-css">        &#125;</span></span><br><span class="line"><span class="language-css">        <span class="selector-class">.timestamp</span> &#123;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">font-size</span>: <span class="number">12px</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">color</span>: <span class="number">#777</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">margin-top</span>: <span class="number">5px</span>;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">text-align</span>: right;</span></span><br><span class="line"><span class="language-css">        &#125;</span></span><br><span class="line"><span class="language-css">    </span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;header&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">h1</span>&gt;</span>黑马医疗问诊机器人<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>您的智能健康顾问<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;chat-container&quot;</span> <span class="attr">id</span>=<span class="string">&quot;chat-box&quot;</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 初始系统消息 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;message bot-message&quot;</span>&gt;</span></span><br><span class="line">            您好！我是黑马小健康助手，请问有什么健康问题可以帮您解答？</span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;timestamp&quot;</span>&gt;</span>系统消息<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;input-container&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">id</span>=<span class="string">&quot;user-input&quot;</span> <span class="attr">placeholder</span>=<span class="string">&quot;请输入您的健康问题...&quot;</span> <span class="attr">autofocus</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">button</span> <span class="attr">id</span>=<span class="string">&quot;send-button&quot;</span>&gt;</span>发送<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="comment">// 每次刷新页面 history 都从空开始</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">let</span> history = [];</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="variable language_">document</span>.<span class="title function_">getElementById</span>(<span class="string">&#x27;send-button&#x27;</span>).<span class="title function_">addEventListener</span>(<span class="string">&#x27;click&#x27;</span>, sendMessage);</span></span><br><span class="line"><span class="language-javascript">    <span class="variable language_">document</span>.<span class="title function_">getElementById</span>(<span class="string">&#x27;user-input&#x27;</span>).<span class="title function_">addEventListener</span>(<span class="string">&#x27;keypress&#x27;</span>, <span class="keyword">function</span>(<span class="params">e</span>) &#123;</span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">if</span> (e.<span class="property">key</span> === <span class="string">&#x27;Enter&#x27;</span>) <span class="title function_">sendMessage</span>();</span></span><br><span class="line"><span class="language-javascript">    &#125;);</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">function</span> <span class="title function_">sendMessage</span>(<span class="params"></span>) &#123;</span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">const</span> userInput = <span class="variable language_">document</span>.<span class="title function_">getElementById</span>(<span class="string">&#x27;user-input&#x27;</span>);</span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">const</span> question = userInput.<span class="property">value</span>.<span class="title function_">trim</span>();</span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">if</span> (question === <span class="string">&#x27;&#x27;</span>) <span class="keyword">return</span>;</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">        <span class="comment">// 显示用户消息</span></span></span><br><span class="line"><span class="language-javascript">        <span class="title function_">addMessage</span>(question, <span class="string">&#x27;user&#x27;</span>);</span></span><br><span class="line"><span class="language-javascript">        userInput.<span class="property">value</span> = <span class="string">&#x27;&#x27;</span>;</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">        <span class="comment">// 把当前 history 发给后端</span></span></span><br><span class="line"><span class="language-javascript">        <span class="title function_">fetch</span>(<span class="string">&#x27;/api/predict&#x27;</span>, &#123;</span></span><br><span class="line"><span class="language-javascript">            <span class="attr">method</span>: <span class="string">&#x27;POST&#x27;</span>,</span></span><br><span class="line"><span class="language-javascript">            <span class="attr">headers</span>: &#123; <span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;application/json&#x27;</span> &#125;,</span></span><br><span class="line"><span class="language-javascript">            <span class="attr">body</span>: <span class="title class_">JSON</span>.<span class="title function_">stringify</span>(&#123; <span class="attr">question</span>: question, <span class="attr">history</span>: history &#125;)</span></span><br><span class="line"><span class="language-javascript">        &#125;)</span></span><br><span class="line"><span class="language-javascript">        .<span class="title function_">then</span>(<span class="function"><span class="params">response</span> =&gt;</span> response.<span class="title function_">json</span>())</span></span><br><span class="line"><span class="language-javascript">        .<span class="title function_">then</span>(<span class="function"><span class="params">data</span> =&gt;</span> &#123;</span></span><br><span class="line"><span class="language-javascript">            <span class="comment">// 显示机器人回答</span></span></span><br><span class="line"><span class="language-javascript">            <span class="title function_">addMessage</span>(data.<span class="property">answer</span>, <span class="string">&#x27;bot&#x27;</span>);</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">            <span class="comment">// 更新 history</span></span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">if</span> (<span class="title class_">Array</span>.<span class="title function_">isArray</span>(data.<span class="property">history</span>)) &#123;</span></span><br><span class="line"><span class="language-javascript">                history = data.<span class="property">history</span>;</span></span><br><span class="line"><span class="language-javascript">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="title class_">Array</span>.<span class="title function_">isArray</span>(data.<span class="property">new_history</span>)) &#123;</span></span><br><span class="line"><span class="language-javascript">                history = data.<span class="property">new_history</span>;</span></span><br><span class="line"><span class="language-javascript">            &#125; <span class="keyword">else</span> &#123;</span></span><br><span class="line"><span class="language-javascript">                history.<span class="title function_">push</span>([question, data.<span class="property">answer</span>]);</span></span><br><span class="line"><span class="language-javascript">            &#125;</span></span><br><span class="line"><span class="language-javascript">        &#125;)</span></span><br><span class="line"><span class="language-javascript">        .<span class="title function_">catch</span>(<span class="function"><span class="params">error</span> =&gt;</span> &#123;</span></span><br><span class="line"><span class="language-javascript">            <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&#x27;Error:&#x27;</span>, error);</span></span><br><span class="line"><span class="language-javascript">            <span class="title function_">addMessage</span>(<span class="string">&#x27;抱歉，服务暂时不可用，请稍后再试。&#x27;</span>, <span class="string">&#x27;bot&#x27;</span>);</span></span><br><span class="line"><span class="language-javascript">        &#125;);</span></span><br><span class="line"><span class="language-javascript">    &#125;</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">function</span> <span class="title function_">addMessage</span>(<span class="params">text, sender</span>) &#123;</span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">const</span> chatBox = <span class="variable language_">document</span>.<span class="title function_">getElementById</span>(<span class="string">&#x27;chat-box&#x27;</span>);</span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">const</span> messageDiv = <span class="variable language_">document</span>.<span class="title function_">createElement</span>(<span class="string">&#x27;div&#x27;</span>);</span></span><br><span class="line"><span class="language-javascript">        messageDiv.<span class="property">className</span> = <span class="string">`message <span class="subst">$&#123;sender&#125;</span>-message`</span>;</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">const</span> now = <span class="keyword">new</span> <span class="title class_">Date</span>();</span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">const</span> timeString = now.<span class="title function_">toLocaleTimeString</span>([], &#123;<span class="attr">hour</span>: <span class="string">&#x27;2-digit&#x27;</span>, <span class="attr">minute</span>:<span class="string">&#x27;2-digit&#x27;</span>&#125;);</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">        messageDiv.<span class="property">innerHTML</span> = <span class="string">`</span></span></span><br><span class="line"><span class="string"><span class="language-javascript">            <span class="subst">$&#123;text&#125;</span></span></span></span><br><span class="line"><span class="string"><span class="language-javascript">            &lt;div class=&quot;timestamp&quot;&gt;<span class="subst">$&#123;sender === <span class="string">&#x27;user&#x27;</span> ? <span class="string">&#x27;您&#x27;</span> : <span class="string">&#x27;小健康助手&#x27;</span>&#125;</span> · <span class="subst">$&#123;timeString&#125;</span>&lt;/div&gt;</span></span></span><br><span class="line"><span class="string"><span class="language-javascript">        `</span>;</span></span><br><span class="line"><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">        chatBox.<span class="title function_">appendChild</span>(messageDiv);</span></span><br><span class="line"><span class="language-javascript">        chatBox.<span class="property">scrollTop</span> = chatBox.<span class="property">scrollHeight</span>;</span></span><br><span class="line"><span class="language-javascript">    &#125;</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>运行app.py文件, 效果如下:</li>
</ul>
<h1 id="P03-新零售行业评价决策系统"><a href="#P03-新零售行业评价决策系统" class="headerlink" title="P03_新零售行业评价决策系统"></a>P03_新零售行业评价决策系统</h1><h2 id="一、项目介绍【理解】"><a href="#一、项目介绍【理解】" class="headerlink" title="一、项目介绍【理解】"></a>一、项目介绍【理解】</h2><h3 id="1、项目背景"><a href="#1、项目背景" class="headerlink" title="1、项目背景"></a>1、项目背景</h3><ul>
<li>随着科技的迅速发展和智能设备的普及，AI技术在新零售行业中得到了广泛应用。其中 <strong>智能推荐系统</strong> 是AI技在新零售中最为常见且有效的应用之一。通过分析用户的购买历史、浏览行为以及喜好偏好，推荐系统可以根据个人特征给用户进行个性化商品推荐。这种个性化推荐不仅可以提高用户购买意愿，减少信息过载，还可以带来更高的用户满意度和销量。</li>
<li><strong>在智能推荐系统中，文本分类的应用属于重要的应用环节</strong>。比如：某电商网站都允许用户为商品填写评论，这些文本评论能够体现出用户的偏好以及商品特征信息，是一种语义信息丰富的隐式特征。 相比于单纯的利用显式评分特征，文本信息一方面可以弥补评分稀疏性的问题，另一方面在推荐系统的可解释方面也能够做的更好。</li>
<li>因此，本次项目我们将 <strong>以”电商平台用户评论”为背景，基于深度学习方法实现评论文本的准确分类</strong> ，这样做的目的是通过用户对不同商品或服务的评价，平台能够快速回应用户需求，改进产品和服务。同时，自动分类也为个性化推荐奠定基础，帮助用户更轻松地找到符合其偏好的商品。</li>
</ul>
<h3 id="2、评论文本分类实现方法"><a href="#2、评论文本分类实现方法" class="headerlink" title="2、评论文本分类实现方法"></a>2、评论文本分类实现方法</h3><h4 id="2-1-传统的深度学习方法"><a href="#2-1-传统的深度学习方法" class="headerlink" title="2.1 传统的深度学习方法"></a>2.1 传统的深度学习方法</h4><ul>
<li>目前实现文本分类的方法很多，如经典的应用于文本的卷积神经网络（Text-CNN）、循环神经网络（Text-RNN)、基于BERT等预训练模型的fine-tuning等，但是这些方法多为建立在具有大量的标注数据下的有监督学习。在很多实际场景中，由于领域特殊性和标注成本高，导致标注训练数据缺乏，模型无法有效地学习参数，从而易出现过拟合现象。因此，如何 <strong>通过小样本数据训练得到一个性能较好的分类模型</strong> 是目前的研究热点。</li>
</ul>
<h4 id="2-2-模型微调方法"><a href="#2-2-模型微调方法" class="headerlink" title="2.2 模型微调方法"></a>2.2 模型微调方法</h4><ul>
<li>基于前面章节的介绍，我们可以借助Prompt-Tuning的技术，来实现模型部分参数的微调（当然如果模型参数较小比如BERT,也可以全量参数微调），相比传统技术方法，Prompt-Tuning方法可以实现在较少样本的训练上，就可以达到较好的结果。</li>
<li>在本次项目中，我们将分别基于 <strong>BERT+PET（硬模版）以及BERT+P-Tuning（软模版）</strong> 两种方式实现用户评论文本的分类。重点是理解prompt的构造方法，以及promt-tuning方法的实现原理。</li>
</ul>
<h2 id="二、BERT-PET方式介绍【理解】"><a href="#二、BERT-PET方式介绍【理解】" class="headerlink" title="二、BERT+PET方式介绍【理解】"></a>二、BERT+PET方式介绍【理解】</h2><h3 id="1、-PET回顾"><a href="#1、-PET回顾" class="headerlink" title="1、&#x3D;&#x3D;PET回顾&#x3D;&#x3D;"></a>1、&#x3D;&#x3D;PET回顾&#x3D;&#x3D;</h3><ul>
<li>PET（PatternExploiting Training）的核心思想是：&#x3D;&#x3D;根据先验知识人工定义模版，将目标分类任务转换为与MLM一致的完形填空，然后再去微调MLM任务参数。&#x3D;&#x3D;</li>
</ul>
<div align=center><img src="./img/5-4.png" style="zoom:85%" ><img/></div>

<blockquote>
<p>图中示例1: 情感分类任务（好评还是差评），原始文本:这家店真不错,值得推荐。PET模板: [MASK]满意。Label:不&#x2F;很。标签词映射（Label Word Verbalizer）：例如如果<code>[MASK]</code>预测的词是“不”，则认为是差评类，如果是“很”，则认为是好评类。</p>
<p>图中示例2:新闻分类任务（多分类），原始文本：中国女排再夺冠！PET模版：下面是[MASK] [MASK]新闻，Label：体育&#x2F;财经&#x2F;时政&#x2F;军事</p>
</blockquote>
<hr>
<ul>
<li><strong>PET 方法的核心步骤</strong></li>
</ul>
<p><strong>PET方法整体过程可以概括为</strong>：首先，将下游任务通过人工模板（pattern）转化为语言模型的填空任务，并通过verbalizer把预测的词映射到任务标签，从而用少量标注样本训练多个“子模型”；接着，这些子模型在大量未标注数据上生成伪标签，形成软标注数据；最后，通过知识蒸馏，训练一个单一的学生模型来学习多个子模型的预测分布，从而兼顾鲁棒性和泛化能力。在这里，我们只需要完成分类任务，所以只需要实现第一步即可。</p>
<p>具体步骤如下：</p>
<p>1）<strong>定义任务模式 (Task Patterns)：</strong></p>
<ul>
<li>首先，你需要将下游任务的输入和输出，转换为一种 <strong>包含空白（[MASK] 或其他特殊标记）的自然语言句子模板</strong> 。这些模板被称为“模式”。</li>
<li><strong>示例 (情感分类)：</strong><ul>
<li>原始输入：<code>这部电影太棒了！</code> 标签：<code>积极</code></li>
<li>POFT 模式：<code>这部电影太棒了！这是一部____的电影。</code> （其中 <code>____</code> 是待填充的空白）</li>
</ul>
</li>
<li><strong>示例 (问题回答 - 抽取式)：</strong><ul>
<li>原始输入：<code>上下文：北京是中国的首都。问题：中国的首都是哪里？</code> 答案：<code>北京</code></li>
<li>POFT 模式：<code>根据上下文：北京是中国的首都。中国的首都是哪里？答案是____。</code></li>
</ul>
</li>
</ul>
<p>2） <strong>定义标签映射 (Verbalizer)：</strong></p>
<ul>
<li>对于任务的每个标签（或答案），你需要将其映射到 PLM(预训练语言模型) 词汇表中的一个或多个 <strong>具体词汇</strong> 。</li>
<li><strong>示例 (情感分类)：</strong><ul>
<li><code>积极</code> → <code>好</code>, <code>棒</code>, <code>优秀</code></li>
<li><code>消极</code> → <code>差</code>, <code>烂</code>, <code>糟糕</code></li>
</ul>
</li>
<li><strong>示例 (问题回答)：</strong> 答案本身就是模型需要生成的词语。</li>
</ul>
<p>3） <strong>构造训练样本：</strong></p>
<ul>
<li>将你的 <strong>所有有标签的训练数据</strong> ，根据定义的模式和标签映射进行转换。</li>
<li>对于每个样本，输入变成模式化的句子，而模型的训练目标是在空白处生成正确的 Verbalizer 词汇（或答案词汇）。</li>
</ul>
<p>4） <strong>全量微调 PLM：</strong></p>
<ul>
<li>在这些 <strong>模式化</strong> 、 <strong>转换后的训练数据</strong> 上，对 <strong>整个预训练语言模型进行全量微调</strong> 。</li>
<li>微调的目标函数通常是 <strong>交叉熵损失</strong> ，旨在最大化模型在空白处预测正确 Verbalizer 词汇的概率。这实际上是回归到 PLM 预训练时的 <strong>语言模型目标</strong> （如掩码语言模型或文本生成）。<ul>
<li><strong>区别于 Prompt Engineering：</strong> PFT 在这里 <strong>更新模型的所有参数</strong> ，而不仅仅是 Prompt 向量。</li>
<li><strong>区别于传统 Fine-tuning：</strong> 传统 Fine-tuning 可能是在 PLM 上添加一个专门的分类头或抽取层进行微调。而 POFT 则是让 PLM 通过 <strong>预测词汇</strong> 来完成任务，更接近其预训练的方式。</li>
</ul>
</li>
</ul>
<p>5） <strong>推理阶段：</strong></p>
<ul>
<li>对于新的输入，同样通过模式进行转换。</li>
<li>将转换后的输入送入微调后的 PLM。</li>
<li>模型会在空白处生成最可能的词汇。通过 Verbalizer，将这些预测的词汇反向映射回任务的原始标签或答案。<ul>
<li>例如，如果模型预测 <code>好</code> 的概率最高，就将其映射为 <code>积极</code>。</li>
</ul>
</li>
</ul>
<h3 id="2、-环境准备"><a href="#2、-环境准备" class="headerlink" title="2、 环境准备"></a>2、 环境准备</h3><p>本项目基于 torch+ transformers 实现，运行前请安装相关依赖包：</p>
<ul>
<li>python&#x3D;&#x3D;3.10</li>
<li>transformers&#x3D;&#x3D;4.40.2</li>
<li>torch&#x3D;&#x3D;2.5.1+cu121</li>
<li>datasets&#x3D;&#x3D;3.6.0</li>
<li>scikit-learn&#x3D;&#x3D;1.7.0</li>
</ul>
<hr>
<h3 id="3、项目架构"><a href="#3、项目架构" class="headerlink" title="3、项目架构"></a>3、项目架构</h3><p>项目架构流程图：</p>
<div align=center><img src="./img/5-2.png" style="zoom:35%" ><img/></div>

<p>项目整体代码介绍：</p>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250818044920669.png" alt="image-20250818044920669"></p>
<h2 id="三、BERT-PET方式数据预处理【理解】"><a href="#三、BERT-PET方式数据预处理【理解】" class="headerlink" title="三、BERT+PET方式数据预处理【理解】"></a>三、BERT+PET方式数据预处理【理解】</h2><ul>
<li>本项目中对数据部分的预处理步骤如下:<ol>
<li>查看项目数据集</li>
<li>编写Config类项目文件配置代码</li>
<li>编写数据处理相关代码</li>
</ol>
</li>
</ul>
<h3 id="1、查看项目数据集"><a href="#1、查看项目数据集" class="headerlink" title="1、查看项目数据集"></a>1、查看项目数据集</h3><ul>
<li><p>数据存放位置：llm_tuning&#x2F;prompt_tasks&#x2F;PET&#x2F;data</p>
</li>
<li><p>data文件夹里面包含4个txt文档，分别为：train.txt、dev.txt、prompt.txt、verbalizer.txt</p>
</li>
</ul>
<hr>
<h4 id="1-1-train-txt"><a href="#1-1-train-txt" class="headerlink" title="1.1 train.txt"></a>1.1 train.txt</h4><ul>
<li>train.txt为训练数据集，其部分数据展示如下：</li>
</ul>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">水果	脆脆的，甜味可以，可能时间有点长了，水分不是很足。</span><br><span class="line">平板	华为机器肯定不错，但第一次碰上京东最糟糕的服务，以后不想到京东购物了。</span><br><span class="line">书籍	为什么不认真的检查一下， 发这么一本脏脏的书给顾客呢！</span><br><span class="line">衣服	手感不错，用料也很好，不知道水洗后怎样，相信大品牌，质量过关，五星好评！！！</span><br><span class="line">水果	苹果有点小，不过好吃，还有几个烂的。估计是故意的放的。差评。</span><br><span class="line">衣服	掉色掉的厉害，洗一次就花了</span><br></pre></td></tr></table></figure>

<blockquote>
<p>train.txt一共包含63条样本数据，每一行用<code>\t</code>分开，前半部分为标签(label)，后半部分为原始输入 (用户评论)。</p>
<p>如果想使用自定义数据训练，只需要仿照上述示例数据构建数据集即可。</p>
</blockquote>
<hr>
<h4 id="1-2-dev-txt"><a href="#1-2-dev-txt" class="headerlink" title="1.2 dev.txt"></a>1.2 dev.txt</h4><ul>
<li>dev.txt为验证数据集，其部分数据展示如下：</li>
</ul>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">书籍	&quot;一点都不好笑,很失望,内容也不是很实用&quot;</span><br><span class="line">衣服	完全是一条旧裤子。</span><br><span class="line">手机	相机质量不错，如果阳光充足，可以和数码相机媲美．界面比较人性化，容易使用．软件安装简便</span><br><span class="line">书籍	明明说有货，结果送货又没有了。并且也不告诉我，怎么评啊</span><br><span class="line">洗浴	非常不满意，晚上洗的头发，第二天头痒痒的不行了，还都是头皮屑。</span><br><span class="line">水果	这个苹果感觉是长熟的苹果，没有打蜡，不错，又甜又脆</span><br></pre></td></tr></table></figure>

<blockquote>
<p>dev.txt一共包含590条样本数据，每一行用<code>\t</code>分开，前半部分为标签(label)，后半部分为原始输入 (用户评论)。</p>
<p>如果想使用自定义数据训练，只需要仿照上述示例数据构建数据集即可。</p>
</blockquote>
<h4 id="1-3-prompt-txt"><a href="#1-3-prompt-txt" class="headerlink" title="1.3 prompt.txt"></a>1.3 prompt.txt</h4><ul>
<li>prompt.txt为人工设定提示模版，其数据展示如下：</li>
</ul>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">这是一条&#123;MASK&#125;评论：&#123;textA&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>其中，用大括号括起来的部分为「自定义参数」，可以自定义设置大括号内的值。</p>
</blockquote>
<blockquote>
<p>示例中 {MASK} 代表 [MASK] token 的位置，{textA} 代表评论数据的位置。</p>
<p>你可以改为自己想要的模板，例如想新增一个 {textB} 参数：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;textA&#125;和&#123;textB&#125;是&#123;MASK&#125;同的意思。</span><br></pre></td></tr></table></figure></blockquote>
<h4 id="1-4-verbalizer-txt"><a href="#1-4-verbalizer-txt" class="headerlink" title="1.4 verbalizer.txt"></a>1.4 verbalizer.txt</h4><ul>
<li><p>verbalizer.txt 主要用于定义「真实标签」到「标签预测词」之间的映射。在有些情况下，将「真实标签」作为 [MASK] 去预测可能不具备很好的语义通顺性，因此，我们会对「真实标签」做一定的映射。</p>
</li>
<li><p>例如：</p>
</li>
</ul>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;中国爆冷2-1战胜韩国&quot;是一则[MASK][MASK]新闻。	体育</span><br></pre></td></tr></table></figure>

<ul>
<li><p>这句话中的标签为「体育」，但如果我们将标签设置为「足球」会更容易预测。</p>
</li>
<li><p>因此，我们可以对「体育」这个 label 构建许多个子标签，在推理时，只要预测到子标签最终推理出真实标签即可，如下：</p>
</li>
</ul>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">体育 -&gt; 足球,篮球,网球,棒球,乒乓,体育</span><br></pre></td></tr></table></figure>

<ul>
<li>项目中标签词映射数据展示如下：</li>
</ul>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">电脑	电脑</span><br><span class="line">水果	水果</span><br><span class="line">平板	平板</span><br><span class="line">衣服	衣服</span><br><span class="line">酒店	酒店</span><br><span class="line">洗浴	洗浴</span><br><span class="line">书籍	书籍</span><br><span class="line">蒙牛	蒙牛</span><br><span class="line">手机	手机</span><br><span class="line">电器	电器</span><br></pre></td></tr></table></figure>

<blockquote>
<p>verbalizer.txt 一共包含10个类别，上述数据中，我们使用了1对1的verbalizer, 如果想定义一对多的映射，只需要在后面用”,”分割即可， eg: </p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">水果	苹果,香蕉,橘子</span><br></pre></td></tr></table></figure>

<p>若想使用自定义数据训练，只需要仿照示例数据构建数据集</p>
</blockquote>
<h3 id="2、编写Config类项目文件配置代码"><a href="#2、编写Config类项目文件配置代码" class="headerlink" title="2、编写Config类项目文件配置代码"></a>2、编写Config类项目文件配置代码</h3><ul>
<li><p>代码路径：llm_tuning&#x2F;prompt_tasks&#x2F;PET&#x2F;pet_config.py</p>
</li>
<li><p>config文件目的：配置项目常用变量，一般这些变量属于不经常改变的，比如：训练文件路径、模型训练次数、模型超参数等等</p>
</li>
</ul>
<p>具体代码实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">base_dir = os.path.dirname(os.path.abspath(__file__))</span><br><span class="line"><span class="comment"># print(f&#x27;base_dir--&gt;&#123;base_dir&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ProjectConfig</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 初始化设备配置，根据系统环境选择使用GPU或CPU</span></span><br><span class="line">        self.device = <span class="string">&#x27;cuda:0&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line">        <span class="comment"># self.device = &quot;mps:0&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 预训练模型路径配置</span></span><br><span class="line">        self.pre_model = os.path.join(base_dir, <span class="string">&#x27;../../bert-base-chinese&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 训练、验证数据集路径配置</span></span><br><span class="line">        self.train_path = os.path.join(base_dir, <span class="string">&#x27;data/train.txt&#x27;</span>)</span><br><span class="line">        self.dev_path = os.path.join(base_dir, <span class="string">&#x27;data/dev.txt&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提示词和标签映射文件路径配置</span></span><br><span class="line">        self.prompt_file = os.path.join(base_dir, <span class="string">&#x27;data/prompt.txt&#x27;</span>)</span><br><span class="line">        self.verbalizer = os.path.join(base_dir, <span class="string">&#x27;data/verbalizer.txt&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 模型输入序列最大长度配置</span></span><br><span class="line">        self.max_seq_len = <span class="number">256</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 设置训练的超参数</span></span><br><span class="line">        self.batch_size = <span class="number">8</span>  <span class="comment"># 每个批次的大小，根据显存和模型大小调整</span></span><br><span class="line">        self.learning_rate = <span class="number">5e-5</span>  <span class="comment"># 学习率，影响模型收敛速度和效果</span></span><br><span class="line">        self.weight_decay = <span class="number">0</span>  <span class="comment"># 权重衰减，用于防止过拟合，这里不使用权重衰减</span></span><br><span class="line">        self.warmup_ratio = <span class="number">0.06</span>  <span class="comment"># 学习率预热比例，帮助模型初期更快地学习</span></span><br><span class="line">        self.max_label_len = <span class="number">2</span>  <span class="comment"># 最大标签长度，限制输出序列的最大长度</span></span><br><span class="line">        self.epochs = <span class="number">20</span>  <span class="comment"># 训练的轮数，即整个数据集通过模型的次数</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 日志和验证配置</span></span><br><span class="line">        self.logging_steps = <span class="number">2</span></span><br><span class="line">        self.valid_steps = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 模型保存路径配置</span></span><br><span class="line">        self.save_dir = os.path.join(base_dir, <span class="string">&#x27;save_model&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    pc = ProjectConfig()</span><br><span class="line">    <span class="built_in">print</span>(pc.prompt_file)</span><br><span class="line">    <span class="built_in">print</span>(pc.pre_model)</span><br></pre></td></tr></table></figure>

<h3 id="3、编写数据处理相关代码"><a href="#3、编写数据处理相关代码" class="headerlink" title="3、编写数据处理相关代码"></a>3、编写数据处理相关代码</h3><ul>
<li><p>代码路径：llm_tuning&#x2F;prompt_tasks&#x2F;PET&#x2F;data_handle&#x2F;</p>
</li>
<li><p>data_handle文件夹中一共包含三个py脚本：template.py、data_preprocess.py、data_loader.py</p>
</li>
</ul>
<h4 id="3-1-template-py"><a href="#3-1-template-py" class="headerlink" title="3.1 &#x3D;&#x3D;template.py&#x3D;&#x3D;"></a>3.1 &#x3D;&#x3D;template.py&#x3D;&#x3D;</h4><ul>
<li>目的：构建固定模版类，text2id的转换</li>
<li>思路：</li>
</ul>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250823121459553.png" alt="image-20250823121459553"></p>
<ul>
<li>定义HardTemplate类代码如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.pet_config <span class="keyword">import</span> ProjectConfig</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用硬模板，人工定义句子和[MASK]之间的位置关系。</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HardTemplate</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, prompt: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        初始化Prompt对象的构造函数</span></span><br><span class="line"><span class="string">        :param prompt: prompt格式定义字符串, 表示待处理的提示模板 e.g. -&gt; &quot;这是一条&#123;MASK&#125;评论：&#123;textA&#125;&quot;</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.prompt = prompt  <span class="comment"># 保存原始的提示模板字符串</span></span><br><span class="line">        self.inputs_list = []  <span class="comment"># 根据文字prompt拆分为各part的列表</span></span><br><span class="line">        self.custom_tokens = &#123;<span class="string">&#x27;MASK&#x27;</span>&#125;   <span class="comment"># 初始化自定义token集合，至少包含&#x27;MASK&#x27; token</span></span><br><span class="line"></span><br><span class="line">        self.prompt_analysis()  <span class="comment"># 解析prompt模板，初始化时即对prompt进行分析处理</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">prompt_analysis</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    	将prompt文字模板拆解为可映射的数据结构。</span></span><br><span class="line"><span class="string">		Examples:</span></span><br><span class="line"><span class="string">			prompt -&gt; &quot;这是一条&#123;MASK&#125;评论：&#123;textA&#125;&quot;</span></span><br><span class="line"><span class="string">			inputs_list -&gt; [&#x27;这&#x27;, &#x27;是&#x27;, &#x27;一&#x27;, &#x27;条&#x27;, &#x27;MASK&#x27;, &#x27;评&#x27;, &#x27;论&#x27;, &#x27;：&#x27;, &#x27;textA&#x27;]</span></span><br><span class="line"><span class="string">			custom_tokens -&gt; &#123;&#x27;textA&#x27;, &#x27;MASK&#x27;&#125;</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># print(f&#x27;prompt--&gt;&#123;self.prompt&#125;&#x27;)</span></span><br><span class="line">        idx = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 遍历提示模板字符串中的每个字符</span></span><br><span class="line">        <span class="keyword">while</span> idx &lt; <span class="built_in">len</span>(self.prompt):</span><br><span class="line">            str_part = <span class="string">&#x27;&#x27;</span></span><br><span class="line">            <span class="comment"># 如果当前字符不是&#x27;&#123;&#x27;, &#x27;&#125;&#x27;，则直接添加到输入列表中</span></span><br><span class="line">            <span class="keyword">if</span> self.prompt[idx] <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&#x27;&#123;&#x27;</span>, <span class="string">&#x27;&#125;&#x27;</span>]:</span><br><span class="line">                self.inputs_list.append(self.prompt[idx])</span><br><span class="line">            <span class="comment"># 如果遇到&#x27;&#123;&#x27;，表示进入自定义字段部分</span></span><br><span class="line">            <span class="keyword">if</span> self.prompt[idx] == <span class="string">&#x27;&#123;&#x27;</span>:  <span class="comment"># 进入自定义字段</span></span><br><span class="line">                idx += <span class="number">1</span></span><br><span class="line">                <span class="comment"># 继续遍历直到遇到&#x27;&#125;&#x27;，并将自定义字段的值拼接到str_part中</span></span><br><span class="line">                <span class="keyword">while</span> self.prompt[idx] != <span class="string">&#x27;&#125;&#x27;</span>:</span><br><span class="line">                    str_part += self.prompt[idx]  <span class="comment"># 拼接该自定义字段的值</span></span><br><span class="line">                    idx += <span class="number">1</span></span><br><span class="line">                <span class="comment"># print(f&#x27;idx--&gt;&#123;idx&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># 如果遇到&#x27;&#125;&#x27;，但没有对应的&#x27;&#123;&#x27;，抛出异常提示括号不匹配</span></span><br><span class="line">            <span class="keyword">elif</span> self.prompt[idx] == <span class="string">&#x27;&#125;&#x27;</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">&quot;遇到了单独的 &#x27;&#125;&#x27;, 请检查输入的prompt。&quot;</span>)</span><br><span class="line">            <span class="comment"># 如果str_part不为空，表示已经完整地获取了一个自定义字段</span></span><br><span class="line">            <span class="keyword">if</span> str_part:</span><br><span class="line">                self.inputs_list.append(str_part)  <span class="comment"># 将所有自定义字段添加到输入列表中</span></span><br><span class="line">                self.custom_tokens.add(str_part)  <span class="comment"># 将所有自定义字段存储，后续会检测输入信息是否完整</span></span><br><span class="line">            <span class="comment"># 移动到下一个字符</span></span><br><span class="line">            idx += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># print(f&#x27;self.inputs_list--&gt;&#123;self.inputs_list&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;self.custom_tokens--&gt;&#123;self.custom_tokens&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 inputs_dict: <span class="built_in">dict</span>,</span></span><br><span class="line"><span class="params">                 tokenizer,</span></span><br><span class="line"><span class="params">                 mask_length,</span></span><br><span class="line"><span class="params">                 max_seq_len=<span class="number">512</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        输入一个样本，转换为符合模板的格式。</span></span><br><span class="line"><span class="string">        :param inputs_dict: prompt中的参数字典, e.g. -&gt; &#123; &#x27;textA&#x27;: &#x27;包装不错，苹果挺甜的，个头也大。&#x27;, &#x27;MASK&#x27;: &#x27;[MASK]&#x27;&#125;</span></span><br><span class="line"><span class="string">        :param tokenizer: 用于encoding文本的分词器</span></span><br><span class="line"><span class="string">        :param mask_length: MASK token 的长度</span></span><br><span class="line"><span class="string">        :param max_seq_len: 最大的句子长度</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        dict -&gt; &#123;</span></span><br><span class="line"><span class="string">				&#x27;text&#x27;: &#x27;[CLS]这是一条[MASK][MASK]评论：包装不错，苹果挺甜的，个头也大。[SEP][PAD][PAD][PAD]&#x27;,</span></span><br><span class="line"><span class="string">				&#x27;input_ids&#x27;: [101, 6821, 3221, 671, 3340, 103, 103, 6397, ..., 102, 0, 0, 0],</span></span><br><span class="line"><span class="string">				&#x27;token_type_ids&#x27;: [0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0],</span></span><br><span class="line"><span class="string">				&#x27;attention_mask&#x27;: [1, 1, 1, 1, 1, 1, 1, 1, ..., 1, 1, 1, 1,],</span></span><br><span class="line"><span class="string">				&#x27;mask_position&#x27;: [5, 6]</span></span><br><span class="line"><span class="string">			&#125;</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 定义输出格式</span></span><br><span class="line">        <span class="comment"># 初始化一个字典对象以存储处理后的输出数据</span></span><br><span class="line">        <span class="comment"># 该字典包含了文本数据及其对应的编码信息、注意力掩码和掩码位置等关键信息</span></span><br><span class="line">        outputs = &#123;</span><br><span class="line">            <span class="comment"># 存储原始文本数据</span></span><br><span class="line">            <span class="string">&#x27;text&#x27;</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">            <span class="comment"># 存储文本经过分词和数值化后的输入ID序列</span></span><br><span class="line">            <span class="string">&#x27;input_ids&#x27;</span>: [],</span><br><span class="line">            <span class="comment"># 存储段嵌入（token type embeddings）的ID序列，用于区分不同句子</span></span><br><span class="line">            <span class="string">&#x27;token_type_ids&#x27;</span>: [],</span><br><span class="line">            <span class="comment"># 存储注意力掩码，用于指示每个token是否应该被关注</span></span><br><span class="line">            <span class="string">&#x27;attention_mask&#x27;</span>: [],</span><br><span class="line">            <span class="comment"># 存储掩码位置，即在输入序列中被掩码的token的位置</span></span><br><span class="line">            <span class="string">&#x27;mask_position&#x27;</span>: []</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print(f&#x27;inputs_dict--&gt;&#123;inputs_dict&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 初始化一个空字符串，用于构建最终的格式化字符串</span></span><br><span class="line">        str_formated = <span class="string">&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 遍历输入列表中的每个值</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> self.inputs_list:</span><br><span class="line">            <span class="comment"># 检查当前值是否在custom_tokens中</span></span><br><span class="line">            <span class="keyword">if</span> value <span class="keyword">in</span> self.custom_tokens:</span><br><span class="line">                <span class="comment"># 如果当前值是&#x27;MASK&#x27;，使用mask_length副本的inputs_dict中的对应值</span></span><br><span class="line">                <span class="keyword">if</span> value == <span class="string">&#x27;MASK&#x27;</span>:</span><br><span class="line">                    str_formated += inputs_dict[value] * mask_length</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># 对于其他自定义值，直接添加inputs_dict中的对应值</span></span><br><span class="line">                    str_formated += inputs_dict[value]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 如果当前值不是custom_tokens中的值，直接添加到格式化字符串中</span></span><br><span class="line">                str_formated += value</span><br><span class="line">        <span class="comment"># 打印格式化后的字符串，用于调试和验证</span></span><br><span class="line">        <span class="comment"># print(f&#x27;str_formated--&gt;&#123;str_formated&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 使用tokenizer对格式化后的字符串进行编码</span></span><br><span class="line">        <span class="comment"># 编码配置包括截断、最大长度设置和填充，以满足模型输入的要求</span></span><br><span class="line">        encoded = tokenizer(text=str_formated,</span><br><span class="line">                            truncation=<span class="literal">True</span>,</span><br><span class="line">                            max_length=max_seq_len,</span><br><span class="line">                            padding=<span class="string">&#x27;max_length&#x27;</span>)</span><br><span class="line">        <span class="comment"># print(&#x27;*&#x27; * 80)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;encoded---&gt;&#123;encoded&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 将编码后的输入ID赋值给输出字典中的&#x27;input_ids&#x27;键</span></span><br><span class="line">        outputs[<span class="string">&#x27;input_ids&#x27;</span>] = encoded[<span class="string">&#x27;input_ids&#x27;</span>]</span><br><span class="line">        <span class="comment"># 将编码后的token类型ID赋值给输出字典中的&#x27;token_type_ids&#x27;键</span></span><br><span class="line">        outputs[<span class="string">&#x27;token_type_ids&#x27;</span>] = encoded[<span class="string">&#x27;token_type_ids&#x27;</span>]</span><br><span class="line">        <span class="comment"># 将编码后的注意力掩码赋值给输出字典中的&#x27;attention_mask&#x27;键</span></span><br><span class="line">        outputs[<span class="string">&#x27;attention_mask&#x27;</span>] = encoded[<span class="string">&#x27;attention_mask&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print(tokenizer.convert_ids_to_tokens(encoded[&#x27;input_ids&#x27;]))</span></span><br><span class="line">        <span class="comment"># 将编码后的输入ID转换为文本，并存储到输出字典中</span></span><br><span class="line">        outputs[<span class="string">&#x27;text&#x27;</span>] = <span class="string">&#x27;&#x27;</span>.join(tokenizer.convert_ids_to_tokens(encoded[<span class="string">&#x27;input_ids&#x27;</span>]))</span><br><span class="line">        <span class="comment"># print(f&#x27;outputs--&gt;&#123;outputs&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将掩码标记 &#x27;[MASK]&#x27; 转换为其对应的ID</span></span><br><span class="line">        mask_token_id = tokenizer.convert_tokens_to_ids(<span class="string">&#x27;[MASK]&#x27;</span>)</span><br><span class="line">        <span class="comment"># print(f&#x27;mask_token_id--&gt;&#123;mask_token_id&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(np.array(outputs[&#x27;input_ids&#x27;]) == mask_token_id)</span></span><br><span class="line">        <span class="comment"># print(np.where(np.array(outputs[&#x27;input_ids&#x27;]) == mask_token_id))</span></span><br><span class="line">        <span class="comment"># 计算并获取输入ID中&#x27;mask&#x27;标记的位置，并将其转换为列表</span></span><br><span class="line">        mask_position = np.where(np.array(outputs[<span class="string">&#x27;input_ids&#x27;</span>]) == mask_token_id)[<span class="number">0</span>].tolist()</span><br><span class="line">        <span class="comment"># print(f&#x27;mask_position--&gt;&#123;mask_position&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 将计算出的mask_position添加到outputs字典中</span></span><br><span class="line">        outputs[<span class="string">&#x27;mask_position&#x27;</span>] = mask_position</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 创建ProjectConfig对象以获取项目配置</span></span><br><span class="line">    pc = ProjectConfig()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据预训练模型配置，加载分词器</span></span><br><span class="line">    tokenizer = AutoTokenizer.from_pretrained(pc.pre_model)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义一个硬模板对象，用于构建特定格式的输入文本</span></span><br><span class="line">    hard_template = HardTemplate(prompt=<span class="string">&#x27;这是一条&#123;MASK&#125;评论：&#123;textA&#125;&#x27;</span>)</span><br><span class="line">    <span class="comment"># 打印硬模板的输入列表和自定义token信息，以便调试</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;inputs_list--&gt;<span class="subst">&#123;hard_template.inputs_list&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;custom_tokens--&gt;<span class="subst">&#123;hard_template.custom_tokens&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用硬模板、分词器和指定的输入字典构建一个模板实例</span></span><br><span class="line">    <span class="comment"># 调用模板对象, 自动调用__call__方法</span></span><br><span class="line">    tep = hard_template(</span><br><span class="line">        inputs_dict=&#123;<span class="string">&#x27;textA&#x27;</span>: <span class="string">&#x27;包装不错，苹果挺甜的，个头也大。&#x27;</span>, <span class="string">&#x27;MASK&#x27;</span>: <span class="string">&#x27;[MASK]&#x27;</span>&#125;,</span><br><span class="line">        tokenizer=tokenizer,</span><br><span class="line">        mask_length=<span class="number">2</span>,</span><br><span class="line">        max_seq_len=<span class="number">30</span></span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;tep---&gt;<span class="subst">&#123;tep&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<hr>
<h4 id="3-2-data-preprocess-py"><a href="#3-2-data-preprocess-py" class="headerlink" title="3.2 &#x3D;&#x3D;data_preprocess.py&#x3D;&#x3D;"></a>3.2 &#x3D;&#x3D;data_preprocess.py&#x3D;&#x3D;</h4><ul>
<li>目的: 将样本数据转换为模型接受的输入数据。具体来说，就是将每行数据进行处理，获取数据的标签和评论信息，然后进行处理获取输入和标签。</li>
<li>定义数据转换方法convert_example()，代码如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="comment"># partial：把一个函数的某些参数给固定住（也就是设置默认值），返回一个新的函数，调用这个新函数会更简单</span></span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.data_handle.template <span class="keyword">import</span> HardTemplate</span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.pet_config <span class="keyword">import</span> ProjectConfig</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_example</span>(<span class="params"></span></span><br><span class="line"><span class="params">        examples: <span class="built_in">dict</span>,</span></span><br><span class="line"><span class="params">        tokenizer,</span></span><br><span class="line"><span class="params">        max_seq_len: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        max_label_len: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        hard_template: HardTemplate,</span></span><br><span class="line"><span class="params">        train_mode=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">        return_tensor=<span class="literal">False</span></span>) -&gt; <span class="built_in">dict</span>:</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    将样本数据转换为模型接收的输入数据。</span></span><br><span class="line"><span class="string">    :param examples: dict类型。训练数据样本,</span></span><br><span class="line"><span class="string">    e.g. -&gt; &#123;</span></span><br><span class="line"><span class="string">            &quot;text&quot;: [&#x27;手机	这个手机也太卡了。&#x27;,</span></span><br><span class="line"><span class="string">                     &#x27;体育	世界杯为何迟迟不见宣传&#x27;,</span></span><br><span class="line"><span class="string">                     ...</span></span><br><span class="line"><span class="string">            ]&#125;</span></span><br><span class="line"><span class="string">    :param tokenizer: 分词器对象</span></span><br><span class="line"><span class="string">    :param max_seq_len: int类型。句子的最大长度，若没有达到最大长度，则padding为最大长度</span></span><br><span class="line"><span class="string">    :param max_label_len: int类型。最大label长度，若没有达到最大长度，则padding为最大长度</span></span><br><span class="line"><span class="string">    :param hard_template: HardTemplate类型。模板类</span></span><br><span class="line"><span class="string">    :param train_mode: bool类型。训练阶段 or 推理阶段</span></span><br><span class="line"><span class="string">    :param return_tensor: bool类型。是否返回tensor类型，如不是，则返回numpy类型。</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">        dict (str: np.array) -&gt; tokenized_output = &#123;</span></span><br><span class="line"><span class="string">                        &#x27;input_ids&#x27;: [[1, 47, 10, 7, 304, 3, 3, 3, 3, 47, 27, 247, 98, 105, 512, 777, 15, 12043, 2], ...],</span></span><br><span class="line"><span class="string">                        &#x27;token_type_ids&#x27;: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...],</span></span><br><span class="line"><span class="string">                        &#x27;attention_mask&#x27;: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], ...],</span></span><br><span class="line"><span class="string">                        &#x27;mask_positions&#x27;: [[5, 6, 7, 8], ...],</span></span><br><span class="line"><span class="string">                        &#x27;mask_labels&#x27;: [[2372, 3442, 0, 0], [2643, 4434, 2334, 0], ...]</span></span><br><span class="line"><span class="string">                    &#125;</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 初始化一个字典，用于存储token化的输出信息</span></span><br><span class="line">    tokenized_output = &#123;</span><br><span class="line">        <span class="string">&#x27;input_ids&#x27;</span>: [],  <span class="comment"># 输入文本的token ID序列</span></span><br><span class="line">        <span class="string">&#x27;token_type_ids&#x27;</span>: [],  <span class="comment"># token类型ID序列，用于区分不同句子的token</span></span><br><span class="line">        <span class="string">&#x27;attention_mask&#x27;</span>: [],  <span class="comment"># 注意力掩码序列，用于标识真实token与padding token</span></span><br><span class="line">        <span class="string">&#x27;mask_positions&#x27;</span>: [],  <span class="comment"># mask标签在输入序列中的位置</span></span><br><span class="line">        <span class="string">&#x27;mask_labels&#x27;</span>: []  <span class="comment"># 需要预测的mask标签的真实值</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># print(f&#x27;examples--》&#123;examples&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># 遍历examples中的&#x27;text&#x27;列表，获取索引和文本内容</span></span><br><span class="line">    <span class="keyword">for</span> i, example <span class="keyword">in</span> <span class="built_in">enumerate</span>(examples[<span class="string">&#x27;text&#x27;</span>]):</span><br><span class="line">        <span class="comment"># 判断是否处于训练模式</span></span><br><span class="line">        <span class="keyword">if</span> train_mode:</span><br><span class="line">            <span class="comment"># print(f&#x27;example--&gt;&#123;example&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># 将文本内容按制表符分割，获取标签和内容</span></span><br><span class="line">            label, content = example.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">            <span class="comment"># print(f&#x27;label--&gt;&#123;label&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># print(f&#x27;content--&gt;&#123;content&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 使用tokenizer对标签进行编</span></span><br><span class="line">            label_encoded = tokenizer(label, add_special_tokens=<span class="literal">False</span>)[<span class="string">&#x27;input_ids&#x27;</span>]</span><br><span class="line">            <span class="comment"># print(f&#x27;label_encoded--&gt;&#123;label_encoded&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 如果标签长度超过最大标签长度, 将标签编码序列的长度限制在最大标签长度内</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(label_encoded) &gt;= max_label_len:</span><br><span class="line">                label_encoded = label_encoded[:max_label_len]</span><br><span class="line">            <span class="comment"># 如果标签长度小于最大标签长度, 将标签编码序列进行填充，以确保其长度与max_label_len相等</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 这里使用了tokenizer的pad_token_id属性作为填充元素</span></span><br><span class="line">                <span class="comment"># print(f&#x27;tokenizer.pad_token_id--&gt;&#123;tokenizer.pad_token_id&#125;&#x27;)</span></span><br><span class="line">                label_encoded = label_encoded + [tokenizer.pad_token_id] * (max_label_len - <span class="built_in">len</span>(label_encoded))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 将编码后的标签添加到tokenized_output字典中的&#x27;mask_labels&#x27;列表中</span></span><br><span class="line">            tokenized_output[<span class="string">&#x27;mask_labels&#x27;</span>].append(label_encoded)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 如果不是训练模式，直接将文本内容进行修剪并使用</span></span><br><span class="line">            content = example.strip()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 初始化输入字典，用于准备文本数据和特殊标记</span></span><br><span class="line">        inputs_dict = &#123;</span><br><span class="line">            <span class="string">&#x27;textA&#x27;</span>: content,  <span class="comment"># &#x27;textA&#x27; 键对应的是后续处理的主要文本内容</span></span><br><span class="line">            <span class="string">&#x27;MASK&#x27;</span>: <span class="string">&#x27;[MASK]&#x27;</span>  <span class="comment"># &#x27;MASK&#x27; 键用于标识特殊的掩码标记，常用于语言模型中</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment"># print(f&#x27;inputs_dict--&gt;&#123;inputs_dict&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 使用硬模板编码方法处理输入数据</span></span><br><span class="line">        <span class="comment"># 该方法将输入数据字典、tokenizer、最大序列长度和最大标签长度作为参数</span></span><br><span class="line">        <span class="comment"># 目的是将输入数据编码成模型所需的格式</span></span><br><span class="line">        encoded_inputs = hard_template(</span><br><span class="line">            inputs_dict=inputs_dict,</span><br><span class="line">            tokenizer=tokenizer,</span><br><span class="line">            max_seq_len=max_seq_len,</span><br><span class="line">            mask_length=max_label_len)</span><br><span class="line">        <span class="comment"># print(f&#x27;encoded_inputs--&gt;&#123;encoded_inputs&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将编码后的输入ID添加到输出字典中的input_ids列表</span></span><br><span class="line">        tokenized_output[<span class="string">&#x27;input_ids&#x27;</span>].append(encoded_inputs[<span class="string">&quot;input_ids&quot;</span>])</span><br><span class="line">        <span class="comment"># 将编码后的token类型ID添加到输出字典中的token_type_ids列表</span></span><br><span class="line">        tokenized_output[<span class="string">&#x27;token_type_ids&#x27;</span>].append(encoded_inputs[<span class="string">&quot;token_type_ids&quot;</span>])</span><br><span class="line">        <span class="comment"># 将编码后的注意力掩码添加到输出字典中的attention_mask列表</span></span><br><span class="line">        tokenized_output[<span class="string">&#x27;attention_mask&#x27;</span>].append(encoded_inputs[<span class="string">&quot;attention_mask&quot;</span>])</span><br><span class="line">        <span class="comment"># 将遮罩位置信息添加到输出字典中的mask_positions列表</span></span><br><span class="line">        tokenized_output[<span class="string">&#x27;mask_positions&#x27;</span>].append(encoded_inputs[<span class="string">&quot;mask_position&quot;</span>])</span><br><span class="line">    <span class="comment"># print(f&#x27;tokenized_output--&gt;&#123;tokenized_output&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历tokenized_output字典，其中k是键，v是值</span></span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> tokenized_output.items():</span><br><span class="line">        <span class="comment"># 如果return_tensor为True，将值转换为torch.LongTensor类型</span></span><br><span class="line">        <span class="keyword">if</span> return_tensor:</span><br><span class="line">            tokenized_output[k] = torch.LongTensor(v)</span><br><span class="line">        <span class="comment"># 否则，将值转换为numpy数组</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            tokenized_output[k] = np.array(v)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tokenized_output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 创建ProjectConfig对象以获取项目配置</span></span><br><span class="line">    pc = ProjectConfig()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用预训练模型的分词器进行初始化</span></span><br><span class="line">    tokenizer = AutoTokenizer.from_pretrained(pc.pre_model)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义一个硬模板，用于将特定的文本结构化到模型输入中</span></span><br><span class="line">    <span class="comment"># &#123;MASK&#125;用于指示模型需要预测的位置，&#123;textA&#125;是输入文本的占位符</span></span><br><span class="line">    hard_template = HardTemplate(prompt=<span class="string">&#x27;这是一条&#123;MASK&#125;评论：&#123;textA&#125;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义示例输入，包含需要处理的文本数据</span></span><br><span class="line">    <span class="comment"># 每个元素是一个包含类别和评论文本的字符串，用制表符分隔</span></span><br><span class="line">    examples = &#123;<span class="string">&quot;text&quot;</span>: [<span class="string">&#x27;手机	这个手机也太卡了。&#x27;</span>, <span class="string">&#x27;体育	世界杯为何迟迟不见宣传&#x27;</span>]&#125;</span><br><span class="line">    tokenized_output = convert_example(examples, tokenizer, max_seq_len=<span class="number">30</span>, max_label_len=<span class="number">2</span>, hard_template=hard_template)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;tokenized_output--&gt;<span class="subst">&#123;tokenized_output&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;*&#x27;</span> * <span class="number">80</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用functools.partial函数创建一个部分应用函数convert_func</span></span><br><span class="line">    <span class="comment"># 此函数基于convert_example函数，预先设置了一些参数，以便于后续的调用中简化操作</span></span><br><span class="line">    <span class="comment"># 这样做是为了优化样本处理流程，将频繁使用的参数固定下来，提高代码复用性和灵活性</span></span><br><span class="line">    convert_func = partial(convert_example,</span><br><span class="line">                           tokenizer=tokenizer,</span><br><span class="line">                           hard_template=hard_template,</span><br><span class="line">                           max_seq_len=<span class="number">30</span>,</span><br><span class="line">                           max_label_len=<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 加载训练数据集</span></span><br><span class="line">    <span class="comment"># 使用ProjectConfig中定义的训练数据路径</span></span><br><span class="line">    train_dataset = load_dataset(<span class="string">&#x27;text&#x27;</span>, data_files=pc.train_path)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">type</span>(train_dataset))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;train_dataset--&gt;<span class="subst">&#123;train_dataset&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="comment"># print(train_dataset[&#x27;train&#x27;])</span></span><br><span class="line">    <span class="comment"># print(train_dataset[&#x27;train&#x27;][&#x27;text&#x27;])</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用map方法对训练数据集进行批量转换</span></span><br><span class="line">    <span class="comment"># batched=True相当于将train_dataset看成一个批次的样本直接对数据进行处理，节省时间</span></span><br><span class="line">    dataset = train_dataset.<span class="built_in">map</span>(convert_func, batched=<span class="literal">True</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;dataset--&gt;<span class="subst">&#123;dataset&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历数据集中的训练数据部分</span></span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> dataset[<span class="string">&#x27;train&#x27;</span>]:</span><br><span class="line">        <span class="comment"># 打印当前训练数据示例</span></span><br><span class="line">        <span class="built_in">print</span>(value)</span><br><span class="line">        <span class="comment"># 打印输入ID序列的长度</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">len</span>(value[<span class="string">&#x27;input_ids&#x27;</span>]))</span><br><span class="line">        <span class="comment"># 打印输入ID序列的数据类型</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">type</span>(value[<span class="string">&#x27;input_ids&#x27;</span>]))</span><br><span class="line">        <span class="comment"># 仅打印第一个训练数据示例后跳出循环</span></span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<hr>
<h4 id="3-3-data-loader-py"><a href="#3-3-data-loader-py" class="headerlink" title="3.3 data_loader.py"></a>3.3 data_loader.py</h4><ul>
<li>目的：定义数据加载器</li>
<li>定义获取数据加载器的方法get_data()，代码如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, default_data_collator</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.data_handle.data_preprocess <span class="keyword">import</span> convert_example</span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.data_handle.template <span class="keyword">import</span> HardTemplate</span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.pet_config <span class="keyword">import</span> ProjectConfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化项目配置文件</span></span><br><span class="line">pc = ProjectConfig()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用项目配置文件中指定的预训练模型，初始化一个自动分词器</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(pc.pre_model)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_data</span>():</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    加载训练和验证数据集，并进行预处理以适应模型训练。</span></span><br><span class="line"><span class="string">    该函数首先读取提示模板文件，然后使用该模板创建一个硬模板对象。</span></span><br><span class="line"><span class="string">    接着，它加载原始数据集，并将其转换为适合模型训练的格式。</span></span><br><span class="line"><span class="string">    最后，它将处理后的数据集包装在DataLoader对象中，以便在训练过程中方便地访问数据。</span></span><br><span class="line"><span class="string">    :return: train_dataloader: 训练数据集的DataLoader对象。</span></span><br><span class="line"><span class="string">    dev_dataloader: 验证数据集的DataLoader对象。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 读取提示模板文件的第一行作为prompt</span></span><br><span class="line">    prompt = <span class="built_in">open</span>(pc.prompt_file, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>).readlines()[<span class="number">0</span>].strip()  <span class="comment"># prompt定义</span></span><br><span class="line">    <span class="comment"># print(f&#x27;prompt--&gt;&#123;prompt&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用读取的prompt创建一个硬模板对象</span></span><br><span class="line">    hard_template = HardTemplate(prompt=prompt)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建一个新函数，用于将示例转换为模型训练所需的格式</span></span><br><span class="line">    new_func = partial(convert_example,</span><br><span class="line">                       tokenizer=tokenizer,</span><br><span class="line">                       hard_template=hard_template,</span><br><span class="line">                       max_seq_len=pc.max_seq_len,</span><br><span class="line">                       max_label_len=pc.max_label_len)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载原始文本数据集</span></span><br><span class="line">    dataset = load_dataset(<span class="string">&#x27;text&#x27;</span>,</span><br><span class="line">                           data_files=&#123;<span class="string">&#x27;train&#x27;</span>: pc.train_path, <span class="string">&#x27;dev&#x27;</span>: pc.dev_path&#125;)</span><br><span class="line">    <span class="comment"># print(f&#x27;dataset--&gt;&#123;dataset&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用新函数对数据集进行映射，进行批量处理</span></span><br><span class="line">    dataset = dataset.<span class="built_in">map</span>(new_func, batched=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># print(f&#x27;dataset改变之后的--&gt;&#123;dataset&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 提取训练数据集和验证数据集</span></span><br><span class="line">    train_dataset = dataset[<span class="string">&quot;train&quot;</span>]</span><br><span class="line">    <span class="comment"># print(f&#x27;train_dataset--&gt;&#123;train_dataset&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;train_dataset[0]--&gt;&#123;train_dataset[0]&#125;&#x27;)</span></span><br><span class="line">    dev_dataset = dataset[<span class="string">&quot;dev&quot;</span>]</span><br><span class="line">    <span class="comment"># print(f&#x27;dev_dataset--&gt;&#123;dev_dataset&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># print(&#x27;dev_dataset&#x27;, dev_dataset[0])</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用default_data_collator将数据转换为tensor数据类型</span></span><br><span class="line">    train_dataloader = DataLoader(train_dataset,</span><br><span class="line">                                  shuffle=<span class="literal">True</span>,</span><br><span class="line">                                  collate_fn=default_data_collator,</span><br><span class="line">                                  batch_size=pc.batch_size)</span><br><span class="line">    <span class="comment"># print(f&#x27;train_dataloader--&gt;&#123;train_dataloader&#125;&#x27;)</span></span><br><span class="line">    dev_dataloader = DataLoader(dev_dataset,</span><br><span class="line">                                collate_fn=default_data_collator,</span><br><span class="line">                                batch_size=pc.batch_size)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回处理后的训练和验证数据集的DataLoader对象</span></span><br><span class="line">    <span class="keyword">return</span> train_dataloader, dev_dataloader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 获取训练和验证数据集的加载器</span></span><br><span class="line">    train_dataloader, dev_dataloader = get_data()</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">len</span>(train_dataloader))</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">len</span>(dev_dataloader))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历训练数据集加载器</span></span><br><span class="line">    <span class="keyword">for</span> i, value <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataloader):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;i---&gt;<span class="subst">&#123;i&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;value---&gt;<span class="subst">&#123;value&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="comment"># 打印当前数据项中&#x27;input_ids&#x27;的数据类型</span></span><br><span class="line">        <span class="built_in">print</span>(value[<span class="string">&#x27;input_ids&#x27;</span>].dtype)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="四、PET方式模型搭建与训练【实现】"><a href="#四、PET方式模型搭建与训练【实现】" class="headerlink" title="四、PET方式模型搭建与训练【实现】"></a>四、PET方式模型搭建与训练【实现】</h2><ul>
<li>本项目中完成BERT+PET模型搭建、训练及应用的步骤如下（注意：因为本项目中使用的是BERT预训练模型，所以直接加载即可，无需重复搭建模型架构）:<ul>
<li>1.实现模型工具类函数</li>
<li>2.实现模型训练函数,验证函数</li>
<li>3.实现模型预测函数</li>
</ul>
</li>
</ul>
<hr>
<h3 id="1、实现模型工具类函数"><a href="#1、实现模型工具类函数" class="headerlink" title="1、实现模型工具类函数"></a>1、实现模型工具类函数</h3><ul>
<li>目的：模型在训练、验证、预测时需要的函数</li>
<li>代码路径：llm_tuning&#x2F;prompt_tasks&#x2F;PET&#x2F;utils<ul>
<li>utils文件夹共包含3个py脚本：verbalizer.py、metirc_utils.py以及common_utils.py</li>
</ul>
</li>
</ul>
<hr>
<h4 id="1-1-verbalizer-py"><a href="#1-1-verbalizer-py" class="headerlink" title="1.1 verbalizer.py"></a>1.1 verbalizer.py</h4><ul>
<li>目的：定义一个Verbalizer类，用于将一个主标签映射到子标签或者将子标签映射到主标签。</li>
<li>思路：</li>
</ul>
<img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250823153111306.png" alt="image-20250823153111306" style="zoom: 80%;" />

<ul>
<li>具体实现代码：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Union 是 typing 模块中定义的一个类,用于表示多个类型中的任意一种类型</span></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Union</span>, <span class="type">List</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.pet_config <span class="keyword">import</span> ProjectConfig</span><br><span class="line"></span><br><span class="line">pc = ProjectConfig()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Verbalizer类，用于将一个Label对应到其子Label的映射。</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Verbalizer</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 verbalizer_file: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">                 tokenizer, max_label_len: <span class="built_in">int</span></span></span><br><span class="line"><span class="params">                 </span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param verbalizer_file: verbalizer文件存放地址。</span></span><br><span class="line"><span class="string">        :param tokenizer: 用于文本和id之间的转换。</span></span><br><span class="line"><span class="string">        :param max_label_len: 标签长度，若大于则截断，若小于则补齐</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.tokenizer = tokenizer</span><br><span class="line">        self.label_dict = self.load_label_dict(verbalizer_file)</span><br><span class="line">        self.max_label_len = max_label_len</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_label_dict</span>(<span class="params">self, verbalizer_file: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        读取本地文件，构建verbalizer字典。</span></span><br><span class="line"><span class="string">        :param verbalizer_file: verbalizer文件存放地址。</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        dict -&gt; &#123;</span></span><br><span class="line"><span class="string">            &#x27;体育&#x27;: [&#x27;篮球&#x27;, &#x27;足球&#x27;,&#x27;网球&#x27;, &#x27;排球&#x27;,  ...],</span></span><br><span class="line"><span class="string">            &#x27;酒店&#x27;: [&#x27;宾馆&#x27;, &#x27;旅馆&#x27;, &#x27;旅店&#x27;, &#x27;酒店&#x27;, ...],</span></span><br><span class="line"><span class="string">            ...</span></span><br><span class="line"><span class="string">            &#125;</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化一个空字典，用于存储标签和子标签的关系</span></span><br><span class="line">        label_dict = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打开verbalizer文件，以只读模式，使用utf8编码</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(verbalizer_file, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="comment"># 读取文件的每一行</span></span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                <span class="comment"># 移除行尾的换行符，并按制表符(&#x27;\t&#x27;)分割标签和子标签</span></span><br><span class="line">                label, sub_labels = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">                <span class="comment"># 将子标签按逗号(,)分割成列表，使用set去重后再转回列表，存储到label_dict中</span></span><br><span class="line">                label_dict[label] = <span class="built_in">list</span>(<span class="built_in">set</span>(sub_labels.split(<span class="string">&#x27;,&#x27;</span>)))</span><br><span class="line">        <span class="comment"># 返回处理后的标签和子标签的字典</span></span><br><span class="line">        <span class="keyword">return</span> label_dict</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">find_sub_labels</span>(<span class="params">self, label: <span class="type">Union</span>[<span class="built_in">list</span>, <span class="built_in">str</span>]</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        通过主标签找到所有的子标签。</span></span><br><span class="line"><span class="string">        :param label: 标签, 文本型 或 id_list, e.g. -&gt; &#x27;体育&#x27; or [860, 5509]</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        dict -&gt; &#123;</span></span><br><span class="line"><span class="string">            &#x27;sub_labels&#x27;: [&#x27;足球&#x27;, &#x27;网球&#x27;],</span></span><br><span class="line"><span class="string">            &#x27;token_ids&#x27;: [[6639, 4413], [5381, 4413]]</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 如果传入的label为id列表，则通过tokenizer转换回字符串</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(label) == <span class="built_in">list</span>:</span><br><span class="line">            <span class="comment"># 移除label中的pad_token_id，直到label中不再包含它</span></span><br><span class="line">            <span class="keyword">while</span> self.tokenizer.pad_token_id <span class="keyword">in</span> label:</span><br><span class="line">                label.remove(self.tokenizer.pad_token_id)</span><br><span class="line">            <span class="comment"># 将处理后的id列表转换为tokens，并拼接成字符串</span></span><br><span class="line">            label = <span class="string">&#x27;&#x27;</span>.join(self.tokenizer.convert_ids_to_tokens(label))</span><br><span class="line">        <span class="comment"># print(f&#x27;label--&gt;&#123;label&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 检查转换后的label是否在标签字典中，如果不在则抛出异常</span></span><br><span class="line">        <span class="keyword">if</span> label <span class="keyword">not</span> <span class="keyword">in</span> self.label_dict:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">f&#x27;Lable Error: &quot;<span class="subst">&#123;label&#125;</span>&quot; 不在 label_dict <span class="subst">&#123;<span class="built_in">list</span>(self.label_dict)&#125;</span>.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 从标签字典中获取与label对应的子标签</span></span><br><span class="line">        sub_labels = self.label_dict[label]</span><br><span class="line">        <span class="comment"># print(f&#x27;sub_labels--&gt;&#123;sub_labels&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 将子标签作为结果的一个部分存储在字典中</span></span><br><span class="line">        ret = &#123;<span class="string">&#x27;sub_labels&#x27;</span>: sub_labels&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对每个子标签进行token化，不含特殊符号</span></span><br><span class="line">        token_ids = [token_id <span class="keyword">for</span> token_id <span class="keyword">in</span> self.tokenizer(sub_labels, add_special_tokens=<span class="literal">False</span>)[<span class="string">&#x27;input_ids&#x27;</span>]]</span><br><span class="line">        <span class="comment"># print(f&#x27;token_ids--&gt;&#123;token_ids&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 遍历所有的token_ids，进行截断与补齐操作</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(token_ids)):</span><br><span class="line">            <span class="comment"># 对标签进行截断</span></span><br><span class="line">            token_ids[i] = token_ids[i][:self.max_label_len]</span><br><span class="line">            <span class="comment"># 如果长度不足max_label_len，则使用pad_token_id进行补齐</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(token_ids[i]) &lt; self.max_label_len:</span><br><span class="line">                token_ids[i] = token_ids[i] + [self.tokenizer.pad_token_id] * (self.max_label_len - <span class="built_in">len</span>(token_ids[i]))</span><br><span class="line">        <span class="comment"># 将处理后的token_ids存入ret字典中</span></span><br><span class="line">        ret[<span class="string">&#x27;token_ids&#x27;</span>] = token_ids</span><br><span class="line">        <span class="keyword">return</span> ret</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">batch_find_sub_labels</span>(<span class="params">self, label: <span class="type">List</span>[<span class="type">Union</span>[<span class="built_in">list</span>, <span class="built_in">str</span>]]</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        批量找到子标签。</span></span><br><span class="line"><span class="string">        :param label: 标签列表, [[4510, 5554], [860, 5509]] or [&#x27;体育&#x27;, &#x27;电脑&#x27;]</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        list -&gt; [</span></span><br><span class="line"><span class="string">                &#123;</span></span><br><span class="line"><span class="string">                    &#x27;sub_labels&#x27;: [&#x27;笔记本&#x27;, &#x27;电脑&#x27;],</span></span><br><span class="line"><span class="string">                    &#x27;token_ids&#x27;: [[5011, 6381, 3315], [4510, 5554]]</span></span><br><span class="line"><span class="string">                &#125;,</span></span><br><span class="line"><span class="string">                ...</span></span><br><span class="line"><span class="string">            ]</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> [self.find_sub_labels(l) <span class="keyword">for</span> l <span class="keyword">in</span> label]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_common_sub_str</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                           str1: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">                           str2: <span class="built_in">str</span></span></span><br><span class="line"><span class="params">                           </span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        寻找最大公共子串(连续子序列)。</span></span><br><span class="line"><span class="string">        :param str1: abcd</span></span><br><span class="line"><span class="string">        :param str2: abadbcdba</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化两个字符串的长度</span></span><br><span class="line">        lstr1, lstr2 = <span class="built_in">len</span>(str1), <span class="built_in">len</span>(str2)</span><br><span class="line">        <span class="comment"># 生成0矩阵，为方便后续计算，比字符串长度多了一列，生成一个 lstr1+1 * lstr2+1 的二维矩阵</span></span><br><span class="line">        record = [[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(lstr2 + <span class="number">1</span>)] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(lstr1 + <span class="number">1</span>)]</span><br><span class="line">        <span class="comment"># 初始化最长匹配对应在str1中的最后一位</span></span><br><span class="line">        p = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 初始化最长匹配长度</span></span><br><span class="line">        maxNum = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 遍历两个字符串，寻找最长公共子串</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, lstr1 + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, lstr2 + <span class="number">1</span>):</span><br><span class="line">                <span class="comment"># 当发现相同字符时</span></span><br><span class="line">                <span class="keyword">if</span> str1[i - <span class="number">1</span>] == str2[j - <span class="number">1</span>]:</span><br><span class="line">                    <span class="comment"># 在record矩阵中记录匹配长度</span></span><br><span class="line">                    record[i][j] = record[i - <span class="number">1</span>][j - <span class="number">1</span>] + <span class="number">1</span></span><br><span class="line">                    <span class="comment"># 更新最长匹配长度和对应在str1中的最后一位</span></span><br><span class="line">                    <span class="keyword">if</span> record[i][j] &gt; maxNum:</span><br><span class="line">                        maxNum = record[i][j]</span><br><span class="line">                        p = i</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 返回最长公共子串和其长度</span></span><br><span class="line">        <span class="keyword">return</span> str1[p - maxNum:p], maxNum</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">hard_mapping</span>(<span class="params">self, sub_label: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        强匹配函数，当模型生成的子label不存在时，通过最大公共子串找到重合度最高的主label。</span></span><br><span class="line"><span class="string">        :param sub_label: 子label</span></span><br><span class="line"><span class="string">        :return: 主label</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化变量label和max_overlap_str，用于记录最大重叠度的标签和对应的重叠度值</span></span><br><span class="line">        label, max_overlap_str = <span class="string">&#x27;&#x27;</span>, <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 遍历标签字典，其中main_label是主标签，sub_labels是与主标签相关的子标签列表</span></span><br><span class="line">        <span class="keyword">for</span> main_label, sub_labels <span class="keyword">in</span> self.label_dict.items():</span><br><span class="line">            overlap_num = <span class="number">0</span></span><br><span class="line">            <span class="comment"># 对于每个子标签，计算它与当前推理标签之间的最长公共子串长度总和</span></span><br><span class="line">            <span class="keyword">for</span> s_label <span class="keyword">in</span> sub_labels:</span><br><span class="line">                <span class="comment"># 累加每个子标签与当前推理标签之间的最长公共子串长度</span></span><br><span class="line">                overlap_num += self.get_common_sub_str(sub_label, s_label)[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 如果当前的重叠度大于或等于之前的最大重叠度，则更新最大重叠度和对应的标签</span></span><br><span class="line">            <span class="keyword">if</span> overlap_num &gt;= max_overlap_str:</span><br><span class="line">                max_overlap_str = overlap_num</span><br><span class="line">                label = main_label</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> label</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">find_main_label</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                        sub_label: <span class="type">Union</span>[<span class="built_in">list</span>, <span class="built_in">str</span>],</span></span><br><span class="line"><span class="params">                        hard_mapping=<span class="literal">True</span></span></span><br><span class="line"><span class="params">                        </span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        通过子标签找到父标签。</span></span><br><span class="line"><span class="string">        :param sub_label: 子标签, 文本型 或 id_list, e.g. -&gt; &#x27;苹果&#x27; or [5741, 3362]</span></span><br><span class="line"><span class="string">        :param hard_mapping: 当生成的词语不存在时，是否一定要匹配到一个最相似的label。</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        dict -&gt; &#123;</span></span><br><span class="line"><span class="string">            &#x27;label&#x27;: &#x27;水果&#x27;,</span></span><br><span class="line"><span class="string">            &#x27;token_ids&#x27;: [3717, 3362]</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 如果传入的sub_label为id列表，则通过tokenizer转换回字符串</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(sub_label) == <span class="built_in">list</span>:</span><br><span class="line">            pad_token_id = self.tokenizer.pad_token_id</span><br><span class="line">            <span class="comment"># 移除列表中的[PAD]token，避免影响后续处理</span></span><br><span class="line">            <span class="keyword">while</span> pad_token_id <span class="keyword">in</span> sub_label:</span><br><span class="line">                sub_label.remove(pad_token_id)</span><br><span class="line">            <span class="comment"># 将id列表转换为对应的字符串</span></span><br><span class="line">            sub_label = <span class="string">&#x27;&#x27;</span>.join(self.tokenizer.convert_ids_to_tokens(sub_label))</span><br><span class="line">        <span class="comment"># print(f&#x27;sub_label--&gt;&#123;sub_label&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 初始化主标签为&#x27;无&#x27;，作为未找到特定子标签时的默认值</span></span><br><span class="line">        main_label = <span class="string">&#x27;无&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 遍历标签字典，寻找与子标签匹配的主标签</span></span><br><span class="line">        <span class="keyword">for</span> label, sub_labels <span class="keyword">in</span> self.label_dict.items():</span><br><span class="line">            <span class="comment"># 检查当前子标签是否在字典中对应的子标签列表中</span></span><br><span class="line">            <span class="keyword">if</span> sub_label <span class="keyword">in</span> sub_labels:</span><br><span class="line">                <span class="comment"># 当找到匹配时，更新主标签并终止循环</span></span><br><span class="line">                main_label = label</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="comment"># print(f&#x27;main_label--&gt;&#123;main_label&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 如果主标签为&#x27;无&#x27;且启用了强匹配功能，则使用强匹配方法更新主标签</span></span><br><span class="line">        <span class="keyword">if</span> main_label == <span class="string">&#x27;无&#x27;</span> <span class="keyword">and</span> hard_mapping:</span><br><span class="line">            main_label = self.hard_mapping(sub_label)</span><br><span class="line">        <span class="comment"># print(&#x27;强匹配&#x27;, main_label)</span></span><br><span class="line">        ret = &#123;</span><br><span class="line">            <span class="string">&#x27;label&#x27;</span>: main_label,</span><br><span class="line">            <span class="string">&#x27;token_ids&#x27;</span>: self.tokenizer(main_label, add_special_tokens=<span class="literal">False</span>)[<span class="string">&#x27;input_ids&#x27;</span>]</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ret</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">batch_find_main_label</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                              sub_label: <span class="type">List</span>[<span class="type">Union</span>[<span class="built_in">list</span>, <span class="built_in">str</span>]],</span></span><br><span class="line"><span class="params">                              hard_mapping=<span class="literal">True</span></span></span><br><span class="line"><span class="params">                              </span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        批量通过子标签找父标签。</span></span><br><span class="line"><span class="string">        :param sub_label: 子标签列表, [&#x27;苹果&#x27;, ...] or [[5741, 3362], ...]</span></span><br><span class="line"><span class="string">        :param hard_mapping:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        list: [</span></span><br><span class="line"><span class="string">                &#123;</span></span><br><span class="line"><span class="string">                &#x27;label&#x27;: &#x27;水果&#x27;,</span></span><br><span class="line"><span class="string">                &#x27;token_ids&#x27;: [3717, 3362]</span></span><br><span class="line"><span class="string">                &#125;,</span></span><br><span class="line"><span class="string">                ...</span></span><br><span class="line"><span class="string">        ]</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> [self.find_main_label(l, hard_mapping) <span class="keyword">for</span> l <span class="keyword">in</span> sub_label]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    tokenizer = AutoTokenizer.from_pretrained(pc.pre_model)</span><br><span class="line">    verbalizer = Verbalizer(</span><br><span class="line">        verbalizer_file=pc.verbalizer,</span><br><span class="line">        tokenizer=tokenizer,</span><br><span class="line">        max_label_len=<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;label_dict--&gt;<span class="subst">&#123;verbalizer.label_dict&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查找单个子标签</span></span><br><span class="line">    label = <span class="string">&#x27;电脑&#x27;</span></span><br><span class="line">    ret = verbalizer.find_sub_labels(label)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;ret--&gt;<span class="subst">&#123;ret&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;*&#x27;</span> * <span class="number">80</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查找多个子标签</span></span><br><span class="line">    labels = [<span class="string">&#x27;电脑&#x27;</span>, <span class="string">&#x27;衣服&#x27;</span>]</span><br><span class="line">    <span class="comment"># labels = [[4510, 5554], [6132, 3302]]</span></span><br><span class="line">    result = verbalizer.batch_find_sub_labels(labels)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;result--&gt;<span class="subst">&#123;result&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;*&#x27;</span> * <span class="number">80</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查找单个子标签对应的父标签</span></span><br><span class="line">    <span class="comment"># sub_label = [4510, 5554]</span></span><br><span class="line">    sub_label = <span class="string">&#x27;衣电&#x27;</span></span><br><span class="line">    ret = verbalizer.find_main_label(sub_label)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;ret--&gt;<span class="subst">&#123;ret&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;*&#x27;</span> * <span class="number">80</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查找多个子标签对应的父标签</span></span><br><span class="line">    <span class="comment"># sub_label = [&#x27;衣服&#x27;, &#x27;牛奶&#x27;]</span></span><br><span class="line">    sub_label = [[<span class="number">6132</span>, <span class="number">3302</span>], [<span class="number">5885</span>, <span class="number">4281</span>]]</span><br><span class="line">    ret = verbalizer.batch_find_main_label(sub_label, hard_mapping=<span class="literal">True</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;ret--&gt;<span class="subst">&#123;ret&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="1-2-common-utils-py"><a href="#1-2-common-utils-py" class="headerlink" title="1.2 common_utils.py"></a>1.2 common_utils.py</h4><ul>
<li>目的：定义损失函数、将mask_position位置的token logits转换为token的id。</li>
</ul>
<h5 id="损失计算思路-："><a href="#损失计算思路-：" class="headerlink" title="&#x3D;&#x3D;损失计算思路&#x3D;&#x3D;："></a>&#x3D;&#x3D;损失计算思路&#x3D;&#x3D;：</h5><p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250823173343428.png" alt="image-20250823173343428"></p>
<p>将logits获取id的思路：</p>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250823181627322.png" alt="image-20250823181627322"></p>
<ul>
<li>脚本里面包含两个函数：mlm_loss()以及convert_logits_to_ids()</li>
<li>代码如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mlm_loss</span>(<span class="params">logits,</span></span><br><span class="line"><span class="params">             mask_positions,</span></span><br><span class="line"><span class="params">             sub_mask_labels,</span></span><br><span class="line"><span class="params">             cross_entropy_criterion,</span></span><br><span class="line"><span class="params">             device</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    计算指定位置的mask token的output与label之间的cross entropy loss。</span></span><br><span class="line"><span class="string">    :param logits: (torch.tensor): 模型原始输出 -&gt; (batch_size, seq_len, vocab_size)</span></span><br><span class="line"><span class="string">    :param mask_positions: (torch.tensor): mask token的位置  -&gt; (batch_size, mask_label_num)</span></span><br><span class="line"><span class="string">    :param sub_mask_labels: (list): mask token的sub label, 由于每个label的sub_label数目不同，所以这里是个变长的list,</span></span><br><span class="line"><span class="string">                                    e.g. -&gt; [</span></span><br><span class="line"><span class="string">                                        [[2398, 3352]],</span></span><br><span class="line"><span class="string">                                        [[2398, 3352], [3819, 3861]]</span></span><br><span class="line"><span class="string">                                    ]</span></span><br><span class="line"><span class="string">    :param cross_entropy_criterion: (CrossEntropyLoss): CE Loss计算器</span></span><br><span class="line"><span class="string">    :param device: (str): cpu还是gpu</span></span><br><span class="line"><span class="string">    :return: CE Loss</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    获取logits的尺寸信息，为后续计算做准备</span></span><br><span class="line"><span class="string">    logits.size()返回一个包含三个维度的元组</span></span><br><span class="line"><span class="string">    第一个维度(batch_size)代表批次大小，即一次处理的数据批次包含的样本数量</span></span><br><span class="line"><span class="string">    第二个维度(seq_len)代表序列长度，即每个样本中包含的序列元素数量</span></span><br><span class="line"><span class="string">    第三个维度(vocab_size)代表词汇表大小，即每个序列元素可能的类别数量</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    batch_size, seq_len, vocab_size = logits.size()</span><br><span class="line">    <span class="comment"># print(f&#x27;模型预测结果logits--&gt;&#123;logits.size()&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;mask_positions--&gt;&#123;mask_positions.shape&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;sub_mask_labels--&gt;&#123;sub_mask_labels&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化loss变量为None，用于后续可能的损失计算</span></span><br><span class="line">    loss = <span class="literal">None</span></span><br><span class="line">    <span class="comment"># 遍历 logits、sub_mask_labels 和 mask_positions 的元素</span></span><br><span class="line">    <span class="keyword">for</span> single_value <span class="keyword">in</span> <span class="built_in">zip</span>(logits, sub_mask_labels, mask_positions):</span><br><span class="line">        <span class="comment"># 获取当前token的 logits</span></span><br><span class="line">        single_logits = single_value[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># print(f&#x27;single_logits--&gt;&#123;single_logits.shape&#125;&#x27;)  # 形状[512, 21128]</span></span><br><span class="line">        <span class="comment"># 获取当前token的 sub_mask_labels</span></span><br><span class="line">        single_sub_mask_labels = single_value[<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># print(f&#x27;single_sub_mask_labels--&gt;&#123;single_sub_mask_labels&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 获取当前token的 mask_positions</span></span><br><span class="line">        single_mask_positions = single_value[<span class="number">2</span>]</span><br><span class="line">        <span class="comment"># print(f&#x27;single_mask_positions--&gt;&#123;single_mask_positions&#125;&#x27;)  # 形状size[2]--&gt;具体值([5, 6])</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 从单个序列的logits中，提取出被掩码位置的logits</span></span><br><span class="line">        single_mask_logits = single_logits[single_mask_positions]  <span class="comment"># (mask_label_num, vocab_size)</span></span><br><span class="line">        <span class="comment"># 打印被掩码位置logits的形状，以验证其是否符合预期</span></span><br><span class="line">        <span class="comment"># print(f&#x27;single_mask_logits--&gt;&#123;single_mask_logits.shape&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 模型训练时主标签对应的所有子标签都有相似的特征值, 在计算CE Loss时，需要将每个子标签的对应的损失求平均，因此需要将预测的概率值进行扩展</span></span><br><span class="line">        <span class="comment"># 对单个 single_mask_logits 进行扩展，使其在第一个维度上重复，以匹配 single_sub_mask_labels 的数量</span></span><br><span class="line">        <span class="comment"># 使用repeat设置重复的倍数 (sub_label_num, mask_label_num, vocab_size)</span></span><br><span class="line">        single_mask_logits = single_mask_logits.repeat(<span class="built_in">len</span>(single_sub_mask_labels), <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 打印重复后的single_mask_logits的形状，以便调试和验证重复操作的效果</span></span><br><span class="line">        <span class="comment"># print(f&#x27;重复后的single_mask_logits--&gt;&#123;single_mask_logits.shape&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将三维张量调整为二维，以便计算损失</span></span><br><span class="line">        single_mask_logits = single_mask_logits.reshape(-<span class="number">1</span>, vocab_size)  <span class="comment"># (sub_label_num * mask_label_num, vocab_size)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;调整成二维后的single_mask_logits--&gt;&#123;single_mask_logits.shape&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将子标签转换为张量，并调整形状以匹配模型预测的结果</span></span><br><span class="line">        single_sub_mask_labels = torch.LongTensor(single_sub_mask_labels).to(device)  <span class="comment"># (sub_label_num, mask_label_num)</span></span><br><span class="line">        <span class="comment"># 计算损失值时真实子标签维度为1维，因此需要将其展平以匹配模型预测的结果</span></span><br><span class="line">        single_sub_mask_labels = single_sub_mask_labels.reshape(-<span class="number">1</span>, <span class="number">1</span>).squeeze()  <span class="comment"># (sub_label_num * mask_label_num)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;真实子标签mask值：single_sub_mask_labels--&gt;&#123;single_sub_mask_labels.shape&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;真实子标签mask值：single_sub_mask_labels--&gt;&#123;single_sub_mask_labels&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算当前批次所有子标签的损失</span></span><br><span class="line">        cur_loss = cross_entropy_criterion(single_mask_logits, single_sub_mask_labels)</span><br><span class="line">        <span class="comment"># 计算当前批次所有子标签的平均损失</span></span><br><span class="line">        cur_loss = cur_loss / <span class="built_in">len</span>(single_sub_mask_labels)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果当前损失loss未被初始化（即为None），则将其设置为当前批次的损失cur_loss</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> loss:</span><br><span class="line">            loss = cur_loss</span><br><span class="line">        <span class="comment"># 如果当前损失loss已经存在，则将当前批次的损失cur_loss累加到loss中</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            loss += cur_loss</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算平均损失：将累计的损失loss除以批次大小batch_size</span></span><br><span class="line">    loss = loss / batch_size  <span class="comment"># (1,)</span></span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_logits_to_ids</span>(<span class="params"></span></span><br><span class="line"><span class="params">        logits: torch.tensor,</span></span><br><span class="line"><span class="params">        mask_positions: torch.tensor</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    输入Language Model的词表概率分布（LMModel的logits），将mask_position位置的token logits转换为token的id。</span></span><br><span class="line"><span class="string">    :param logits: (torch.tensor): model output -&gt; (batch, seq_len, vocab_size) [8, 512, 21128]</span></span><br><span class="line"><span class="string">    :param mask_positions: (torch.tensor): mask token的位置 -&gt; (batch, mask_label_num) [8, 2]</span></span><br><span class="line"><span class="string">    :return: 对应mask position上最大概率的推理token -&gt; (batch, mask_label_num) [8, 2]</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 获取标签的长度，mask_positions.size()返回的是一个包含维度的元组，[1]表示获取第二个维度的大小</span></span><br><span class="line">    label_length = mask_positions.size()[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># print(f&#x27;label_length--&gt;&#123;label_length&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取批次大小、序列长度和词汇表大小，logits.size()返回的是一个包含维度的元组</span></span><br><span class="line">    batch_size, seq_len, vocab_size = logits.size()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化一个空列表，用于存储重塑后的 mask_positions</span></span><br><span class="line">    mask_positions_after_reshaped = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># print(f&#x27;mask_positions.detach().cpu().numpy().tolist()--&gt;&#123;mask_positions.detach().cpu().numpy().tolist()&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># 遍历每个批次的mask_positions</span></span><br><span class="line">    <span class="keyword">for</span> batch, mask_pos <span class="keyword">in</span> <span class="built_in">enumerate</span>(mask_positions.detach().cpu().numpy().tolist()):</span><br><span class="line">        <span class="comment"># 遍历每个mask位置</span></span><br><span class="line">        <span class="keyword">for</span> pos <span class="keyword">in</span> mask_pos:</span><br><span class="line">            <span class="comment"># 将批次号和序列中的mask位置结合起来，得到重塑后的mask_positions</span></span><br><span class="line">            mask_positions_after_reshaped.append(batch * seq_len + pos)</span><br><span class="line">    <span class="comment"># print(f&#x27;mask_positions_after_reshaped--&gt;&#123;mask_positions_after_reshaped&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;原始的logits--&gt;&#123;logits.shape&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将原始的logits重塑为(batch_size * seq_len, vocab_size)的形状</span></span><br><span class="line">    logits = logits.reshape(batch_size * seq_len, -<span class="number">1</span>)  <span class="comment"># (batch_size * seq_len, vocab_size)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;改变原始模型输出的结果形状--&gt;&#123;logits.shape&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从重塑后的logits中，选择出被掩码位置的logits</span></span><br><span class="line">    mask_logits = logits[mask_positions_after_reshaped]</span><br><span class="line">    <span class="comment"># print(f&#x27;被掩码位置的logits--&gt;&#123;mask_logits.shape&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取每个样本mask位置所预测的tokens</span></span><br><span class="line">    predict_tokens = mask_logits.argmax(dim=-<span class="number">1</span>)  <span class="comment"># (batch * label_num)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;获取每个样本mask位置预测的tokens&#x27;, predict_tokens)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将每个样本mask位置预测的tokens重塑为(batch, label_num)的形状</span></span><br><span class="line">    predict_tokens = predict_tokens.reshape(-<span class="number">1</span>, label_length)  <span class="comment"># (batch, label_num)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;predict_tokens--&gt;&#123;predict_tokens&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> predict_tokens</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="1-3-metirc-utils-py"><a href="#1-3-metirc-utils-py" class="headerlink" title="1.3 metirc_utils.py"></a>1.3 metirc_utils.py</h4><ul>
<li>目的：定义（多）分类问题下的指标评估（acc, precision, recall, f1）。</li>
<li>定义ClassEvaluator类，代码如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, precision_score, f1_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> recall_score, confusion_matrix</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ClassEvaluator</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 初始化真实结果和预测结果的列表</span></span><br><span class="line">        self.goldens = []  <span class="comment"># 存储真实结果数据</span></span><br><span class="line">        self.predictions = []  <span class="comment"># 存储预测结果数据</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_batch</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                  pred_batch: <span class="type">List</span>[<span class="type">List</span>],</span></span><br><span class="line"><span class="params">                  gold_batch: <span class="type">List</span>[<span class="type">List</span>]</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        添加一个batch中的prediction和gold列表，用于后续统一计算。</span></span><br><span class="line"><span class="string">        :param pred_batch: (list): 模型预测标签列表, e.g. -&gt;  [[&#x27;体&#x27;, &#x27;育&#x27;], [&#x27;财&#x27;, &#x27;经&#x27;], ...]</span></span><br><span class="line"><span class="string">        :param gold_batch: (list): 真实标签标签列表, e.g. -&gt;  [[&#x27;体&#x27;, &#x27;育&#x27;], [&#x27;财&#x27;, &#x27;经&#x27;], ...]</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 确保预测批次和真实批次长度一致，这是后续处理的前提条件</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(pred_batch) == <span class="built_in">len</span>(gold_batch)</span><br><span class="line">        <span class="comment"># print(f&#x27;pred_batch0--&gt;&#123;pred_batch&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;gold_batch0--&gt;&#123;gold_batch&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 若遇到多个子标签构成一个标签的情况</span></span><br><span class="line">        <span class="comment"># 判断gold_batch的第一个元素是否为列表或元组类型</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(gold_batch[<span class="number">0</span>]) <span class="keyword">in</span> [<span class="built_in">list</span>, <span class="built_in">tuple</span>]:</span><br><span class="line">            <span class="comment"># 如果是，则将pred_batch中的每个元素转换为字符串后拼接起来</span></span><br><span class="line">            pred_batch = [<span class="string">&#x27;&#x27;</span>.join([<span class="built_in">str</span>(e) <span class="keyword">for</span> e <span class="keyword">in</span> ele]) <span class="keyword">for</span> ele <span class="keyword">in</span> pred_batch]</span><br><span class="line">            <span class="comment"># 同样地，也将gold_batch中的每个元素转换为字符串后拼接起来</span></span><br><span class="line">            gold_batch = [<span class="string">&#x27;&#x27;</span>.join([<span class="built_in">str</span>(e) <span class="keyword">for</span> e <span class="keyword">in</span> ele]) <span class="keyword">for</span> ele <span class="keyword">in</span> gold_batch]</span><br><span class="line">        <span class="comment"># print(f&#x27;pred_batch--&gt;&#123;pred_batch&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;gold_batch--&gt;&#123;gold_batch&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将真实结果的批次数据添加到self.goldens列表中</span></span><br><span class="line">        self.goldens.extend(gold_batch)</span><br><span class="line">        <span class="comment"># print(f&#x27;self.goldens--&gt;&#123;self.goldens&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 将预测结果的批次数据添加到self.predictions列表中</span></span><br><span class="line">        self.predictions.extend(pred_batch)</span><br><span class="line">        <span class="comment"># print(f&#x27;self.predictions--&gt;&#123;self.predictions&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compute</span>(<span class="params">self, round_num=<span class="number">2</span></span>) -&gt; <span class="built_in">dict</span>:</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        根据当前类中累积的变量值，计算当前的P, R, F1。</span></span><br><span class="line"><span class="string">        :param round_num: (int): 计算结果保留小数点后几位, 默认小数点后2位。</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        dict -&gt; &#123;</span></span><br><span class="line"><span class="string">            &#x27;accuracy&#x27;: 准确率,</span></span><br><span class="line"><span class="string">            &#x27;precision&#x27;: 精准率,</span></span><br><span class="line"><span class="string">            &#x27;recall&#x27;: 召回率,</span></span><br><span class="line"><span class="string">            &#x27;f1&#x27;: f1值,</span></span><br><span class="line"><span class="string">            &#x27;class_metrics&#x27;: &#123;</span></span><br><span class="line"><span class="string">                &#x27;0&#x27;: &#123;</span></span><br><span class="line"><span class="string">                        &#x27;precision&#x27;: 该类别下的precision,</span></span><br><span class="line"><span class="string">                        &#x27;recall&#x27;: 该类别下的recall,</span></span><br><span class="line"><span class="string">                        &#x27;f1&#x27;: 该类别下的f1</span></span><br><span class="line"><span class="string">                    &#125;,</span></span><br><span class="line"><span class="string">                ...</span></span><br><span class="line"><span class="string">            &#125;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># print(f&#x27;self.goldens--&gt;&#123;self.goldens&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;self.predictions--&gt;&#123;self.predictions&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 初始化类别集合、类别指标字典和结果字典，用于存储全局指标</span></span><br><span class="line">        <span class="comment"># 将 self.goldens 和 self.predictions 的集合合并，并进行排序，结果存储在变量 classes 中。</span></span><br><span class="line">        classes = <span class="built_in">sorted</span>(<span class="built_in">list</span>(<span class="built_in">set</span>(self.goldens) | <span class="built_in">set</span>(self.predictions)))</span><br><span class="line">        class_metrics = &#123;&#125;</span><br><span class="line">        res = &#123;&#125;</span><br><span class="line">        <span class="comment"># print(f&#x27;classes--&gt;&#123;classes&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 构建全局指标</span></span><br><span class="line">        <span class="comment"># 计算并存储全局准确率</span></span><br><span class="line">        res[<span class="string">&#x27;accuracy&#x27;</span>] = <span class="built_in">round</span>(accuracy_score(self.goldens, self.predictions), round_num)</span><br><span class="line">        <span class="comment"># 计算并存储全局精确率</span></span><br><span class="line">        res[<span class="string">&#x27;precision&#x27;</span>] = <span class="built_in">round</span>(precision_score(self.goldens, self.predictions, average=<span class="string">&#x27;weighted&#x27;</span>), round_num)</span><br><span class="line">        <span class="comment"># 计算并存储全局召回率</span></span><br><span class="line">        res[<span class="string">&#x27;recall&#x27;</span>] = <span class="built_in">round</span>(recall_score(self.goldens, self.predictions, average=<span class="string">&#x27;weighted&#x27;</span>), round_num)</span><br><span class="line">        <span class="comment"># 计算并存储全局F1分数</span></span><br><span class="line">        res[<span class="string">&#x27;f1&#x27;</span>] = <span class="built_in">round</span>(f1_score(self.goldens, self.predictions, average=<span class="string">&#x27;weighted&#x27;</span>), round_num)</span><br><span class="line">        <span class="comment"># print(f&#x27;res--&gt;&#123;res&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># 计算混淆矩阵，并将其转换为numpy数组，形状为(n_class, n_class)</span></span><br><span class="line">            conf_matrix = np.array(confusion_matrix(self.goldens, self.predictions))</span><br><span class="line">            <span class="comment"># print(f&#x27;conf_matrix--&gt;&#123;conf_matrix&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># 确保混淆矩阵的维度与类别数量匹配</span></span><br><span class="line">            <span class="keyword">assert</span> conf_matrix.shape[<span class="number">0</span>] == <span class="built_in">len</span>(classes)</span><br><span class="line">            <span class="comment"># 遍历每个类别，计算精确度(precision)、召回率(recall)和F1分数(f1)</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(conf_matrix.shape[<span class="number">0</span>]):</span><br><span class="line">                <span class="comment"># 计算当前类别的精确度</span></span><br><span class="line">                precision = <span class="number">0</span> <span class="keyword">if</span> <span class="built_in">sum</span>(conf_matrix[:, i]) == <span class="number">0</span> <span class="keyword">else</span> (conf_matrix[i, i] / <span class="built_in">sum</span>(conf_matrix[:, i]))</span><br><span class="line">                <span class="comment"># 计算当前类别的召回率</span></span><br><span class="line">                recall = <span class="number">0</span> <span class="keyword">if</span> <span class="built_in">sum</span>(conf_matrix[i, :]) == <span class="number">0</span> <span class="keyword">else</span> (conf_matrix[i, i] / <span class="built_in">sum</span>(conf_matrix[i, :]))</span><br><span class="line">                <span class="comment"># 计算当前类别的F1分数</span></span><br><span class="line">                f1 = <span class="number">0</span> <span class="keyword">if</span> (precision + recall) == <span class="number">0</span> <span class="keyword">else</span> (<span class="number">2</span> * precision * recall / (precision + recall))</span><br><span class="line">                <span class="comment"># 将当前类别的精确度、召回率和F1分数保存到字典中</span></span><br><span class="line">                class_metrics[classes[i]] = &#123;</span><br><span class="line">                    <span class="string">&#x27;precision&#x27;</span>: <span class="built_in">round</span>(precision, round_num),</span><br><span class="line">                    <span class="string">&#x27;recall&#x27;</span>: <span class="built_in">round</span>(recall, round_num),</span><br><span class="line">                    <span class="string">&#x27;f1&#x27;</span>: <span class="built_in">round</span>(f1, round_num)</span><br><span class="line">                &#125;</span><br><span class="line">            <span class="comment"># 将所有类别的指标保存到结果字典中</span></span><br><span class="line">            res[<span class="string">&#x27;class_metrics&#x27;</span>] = class_metrics</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="comment"># 异常处理：当计算类别指标时发生异常，打印警告信息和相关数据</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;[Warning] Something wrong when calculate class_metrics: <span class="subst">&#123;e&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;--&gt; goldens: <span class="subst">&#123;<span class="built_in">set</span>(self.goldens)&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;--&gt; predictions: <span class="subst">&#123;<span class="built_in">set</span>(self.predictions)&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;--&gt; diff elements: <span class="subst">&#123;<span class="built_in">set</span>(self.predictions) - <span class="built_in">set</span>(self.goldens)&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="comment"># 将结果字典中的类别指标设置为空字典</span></span><br><span class="line">            res[<span class="string">&#x27;class_metrics&#x27;</span>] = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">		重置积累的数值。</span></span><br><span class="line"><span class="string">		&quot;&quot;&quot;</span></span><br><span class="line">        self.goldens = []</span><br><span class="line">        self.predictions = []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    metric = ClassEvaluator()</span><br><span class="line">    metric.add_batch(</span><br><span class="line">        [[<span class="string">&#x27;财&#x27;</span>, <span class="string">&#x27;经&#x27;</span>], [<span class="string">&#x27;财&#x27;</span>, <span class="string">&#x27;经&#x27;</span>], [<span class="string">&#x27;体&#x27;</span>, <span class="string">&#x27;育&#x27;</span>], [<span class="string">&#x27;体&#x27;</span>, <span class="string">&#x27;育&#x27;</span>], [<span class="string">&#x27;计&#x27;</span>, <span class="string">&#x27;算&#x27;</span>, <span class="string">&#x27;机&#x27;</span>]],</span><br><span class="line">        [[<span class="string">&#x27;体&#x27;</span>, <span class="string">&#x27;育&#x27;</span>], [<span class="string">&#x27;财&#x27;</span>, <span class="string">&#x27;经&#x27;</span>], [<span class="string">&#x27;体&#x27;</span>, <span class="string">&#x27;育&#x27;</span>], [<span class="string">&#x27;计&#x27;</span>, <span class="string">&#x27;算&#x27;</span>, <span class="string">&#x27;机&#x27;</span>], [<span class="string">&#x27;计&#x27;</span>, <span class="string">&#x27;算&#x27;</span>, <span class="string">&#x27;机&#x27;</span>]],</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># metric.add_batch(</span></span><br><span class="line">    <span class="comment">#     [0, 0, 1, 1, 0],</span></span><br><span class="line">    <span class="comment">#     [1, 1, 1, 0, 0]</span></span><br><span class="line">    <span class="comment"># )</span></span><br><span class="line">    res = metric.compute()</span><br><span class="line">    <span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="2、实现模型训练函数-验证函数"><a href="#2、实现模型训练函数-验证函数" class="headerlink" title="2、实现模型训练函数,验证函数"></a>2、实现模型训练函数,验证函数</h3><ul>
<li><p>目的：实现模型的训练和验证</p>
</li>
<li><p>脚本里面包含两个函数：model2train()和evaluate_model()</p>
</li>
<li><p>代码路径：llm_tuning&#x2F;prompt_tasks&#x2F;PET&#x2F;train.py</p>
<p>代码如下：</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForMaskedLM, AutoTokenizer, get_scheduler</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.data_handle.data_loader <span class="keyword">import</span> get_data</span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.pet_config <span class="keyword">import</span> ProjectConfig</span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.utils.common_utils <span class="keyword">import</span> mlm_loss, convert_logits_to_ids</span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.utils.metirc_utils <span class="keyword">import</span> ClassEvaluator</span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.utils.verbalizer <span class="keyword">import</span> Verbalizer</span><br><span class="line"></span><br><span class="line">pc = ProjectConfig()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">model2train</span>():</span><br><span class="line">    <span class="comment"># 加载训练数据和验证数据</span></span><br><span class="line">    train_dataloader, dev_dataloader = get_data()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载预训练模型</span></span><br><span class="line">    model = AutoModelForMaskedLM.from_pretrained(pc.pre_model).to(pc.device)</span><br><span class="line">    <span class="comment"># print(f&#x27;预训练模型带MLM头的--&gt;&#123;model&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># 加载分词器</span></span><br><span class="line">    tokenizer = AutoTokenizer.from_pretrained(pc.pre_model)</span><br><span class="line">    <span class="comment"># 加载映射词表</span></span><br><span class="line">    verbalizer = Verbalizer(verbalizer_file=pc.verbalizer,</span><br><span class="line">                            tokenizer=tokenizer,</span><br><span class="line">                            max_label_len=pc.max_label_len)</span><br><span class="line">    <span class="comment"># print(f&#x27;verbalizer--&gt;&#123;verbalizer.label_dict&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 不需要权重衰减的参数</span></span><br><span class="line">    no_decay = [<span class="string">&quot;bias&quot;</span>, <span class="string">&quot;LayerNorm.weight&quot;</span>]</span><br><span class="line">    <span class="comment"># print(type(model.parameters()))</span></span><br><span class="line">    <span class="comment"># 定义优化器的参数组，以便对模型的不同部分应用不同的权重衰减</span></span><br><span class="line">    optimizer_grouped_parameters = [</span><br><span class="line">        <span class="comment"># 第一组参数：包含所有适用权重衰减的模型参数</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;params&quot;</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> model.named_parameters() <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">any</span>(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)],</span><br><span class="line">            <span class="string">&quot;weight_decay&quot;</span>: pc.weight_decay,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="comment"># 第二组参数：包含所有不适用权重衰减的模型参数</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;params&quot;</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> model.named_parameters() <span class="keyword">if</span> <span class="built_in">any</span>(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)],</span><br><span class="line">            <span class="string">&quot;weight_decay&quot;</span>: <span class="number">0.0</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">    ]</span><br><span class="line">    <span class="comment"># 初始化AdamW优化器，用于模型参数的优化</span></span><br><span class="line">    <span class="comment"># AdamW是Adam算法的变体，加入了权重衰减（L2正则化），有助于防止过拟合</span></span><br><span class="line">    <span class="comment"># 参数optimizer_grouped_parameters是分组的模型参数，允许对不同的参数应用不同的学习率或正则化强度</span></span><br><span class="line">    optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=pc.learning_rate)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据训练轮数计算最大训练步数，以便于scheduler动态调整lr</span></span><br><span class="line">    num_update_steps_per_epoch = <span class="built_in">len</span>(train_dataloader)</span><br><span class="line">    <span class="comment"># 指定总的训练步数，它会被学习率调度器用来确定学习率的变化规律，确保学习率在整个训练过程中得以合理地调节</span></span><br><span class="line">    max_train_steps = pc.epochs * num_update_steps_per_epoch</span><br><span class="line">    <span class="comment"># 计算预热阶段的训练步数，用于初始化学习率调度</span></span><br><span class="line">    warm_steps = <span class="built_in">int</span>(pc.warmup_ratio * max_train_steps)  <span class="comment"># 预热阶段的训练步数</span></span><br><span class="line">    <span class="comment"># 创建学习率调度器，使用线性调度策略，根据训练的进行逐步调整学习率</span></span><br><span class="line">    lr_scheduler = get_scheduler(</span><br><span class="line">        name=<span class="string">&#x27;linear&#x27;</span>,</span><br><span class="line">        optimizer=optimizer,</span><br><span class="line">        num_warmup_steps=warm_steps,</span><br><span class="line">        num_training_steps=max_train_steps)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化损失列表，用于记录训练过程中的损失值</span></span><br><span class="line">    loss_list = []</span><br><span class="line">    <span class="comment"># 记录训练开始的时间，用于计算训练时长</span></span><br><span class="line">    tic_train = time.time()</span><br><span class="line">    <span class="comment"># 创建分类评估器，用于评估模型性能</span></span><br><span class="line">    metric = ClassEvaluator()</span><br><span class="line">    <span class="comment"># 定义损失函数，用于计算模型预测值与真实标签之间的差异</span></span><br><span class="line">    criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">    <span class="comment"># 初始化训练次数和最佳F1分数，用于跟踪训练进度和模型性能</span></span><br><span class="line">    global_step, best_f1 = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;开始训练：&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(pc.epochs):</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> tqdm(train_dataloader, desc=<span class="string">&#x27;模型训练&#x27;</span>):</span><br><span class="line">            <span class="comment"># print(f&#x27;batch--&gt;&#123;batch&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># 将批次数据输入模型，获取logits</span></span><br><span class="line">            logits = model(input_ids=batch[<span class="string">&#x27;input_ids&#x27;</span>].to(pc.device),</span><br><span class="line">                           token_type_ids=batch[<span class="string">&#x27;token_type_ids&#x27;</span>].to(pc.device),</span><br><span class="line">                           attention_mask=batch[<span class="string">&#x27;attention_mask&#x27;</span>].to(pc.device)).logits</span><br><span class="line">            <span class="comment"># print(f&#x27;logits-&gt;&#123;logits.shape&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 真实标签</span></span><br><span class="line">            mask_labels = batch[<span class="string">&#x27;mask_labels&#x27;</span>].numpy().tolist()</span><br><span class="line">            <span class="comment"># print(f&#x27;mask_labels---&gt;&#123;mask_labels&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># 提取子标签</span></span><br><span class="line">            sub_labels = verbalizer.batch_find_sub_labels(mask_labels)</span><br><span class="line">            <span class="comment"># print(f&#x27;sub_labels---&gt;&#123;sub_labels&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># 获取子标签的token_ids</span></span><br><span class="line">            sub_labels = [ele[<span class="string">&#x27;token_ids&#x27;</span>] <span class="keyword">for</span> ele <span class="keyword">in</span> sub_labels]</span><br><span class="line">            <span class="comment"># print(f&#x27;sub_labels_token_ids---&gt;&#123;sub_labels&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 计算掩码语言模型的损失值</span></span><br><span class="line">            loss = mlm_loss(logits,</span><br><span class="line">                            batch[<span class="string">&#x27;mask_positions&#x27;</span>].to(pc.device),</span><br><span class="line">                            sub_labels,</span><br><span class="line">                            criterion,</span><br><span class="line">                            pc.device)</span><br><span class="line">            <span class="comment"># print(f&#x27;计算损失值--&gt;&#123;loss&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># 清零优化器的梯度</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            <span class="comment"># 反向传播计算梯度</span></span><br><span class="line">            loss.backward()</span><br><span class="line">            <span class="comment"># 更新模型参数</span></span><br><span class="line">            optimizer.step()</span><br><span class="line">            <span class="comment"># 更新学习率调度器</span></span><br><span class="line">            lr_scheduler.step()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 将损失值添加到损失列表中</span></span><br><span class="line">            loss_list.append(loss)</span><br><span class="line">            <span class="comment"># 训练次数增加1</span></span><br><span class="line">            global_step += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 打印训练日志</span></span><br><span class="line">            <span class="keyword">if</span> global_step % pc.logging_steps == <span class="number">0</span>:</span><br><span class="line">                time_diff = time.time() - tic_train</span><br><span class="line">                loss_avg = <span class="built_in">sum</span>(loss_list) / <span class="built_in">len</span>(loss_list)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;global step %d, epoch: %d, loss: %.5f, speed: %.2f step/s&quot;</span></span><br><span class="line">                      % (global_step, epoch, loss_avg, pc.logging_steps / time_diff))</span><br><span class="line">                tic_train = time.time()</span><br><span class="line">        <span class="comment"># 模型验证</span></span><br><span class="line">        <span class="comment"># 使用给定的模型、评估指标、数据加载器、分词器和标记化器进行模型评估</span></span><br><span class="line">        acc, precision, recall, f1, class_metrics = evaluate_model(model,</span><br><span class="line">                                                                   metric,</span><br><span class="line">                                                                   dev_dataloader,</span><br><span class="line">                                                                   tokenizer,</span><br><span class="line">                                                                   verbalizer)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打印评估结果中的精确度、召回率和F1分数</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;验证集的 precision: %.5f, recall: %.5f, F1: %.5f&quot;</span> % (precision, recall, f1))</span><br><span class="line">        <span class="comment"># 如果当前F1分数高于最佳F1分数，则更新最佳F1分数和相关模型及分词器</span></span><br><span class="line">        <span class="keyword">if</span> f1 &gt; best_f1:</span><br><span class="line">            <span class="built_in">print</span>(</span><br><span class="line">                <span class="string">f&quot;最好的f1分数被更新: <span class="subst">&#123;best_f1:<span class="number">.5</span>f&#125;</span> --&gt; <span class="subst">&#123;f1:<span class="number">.5</span>f&#125;</span>&quot;</span></span><br><span class="line">            )</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;每种类型的Metrics为: <span class="subst">&#123;class_metrics&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="comment"># 更新当前最佳的F1分数</span></span><br><span class="line">            best_f1 = f1</span><br><span class="line">            <span class="comment"># 定义当前保存模型和分词器的目录</span></span><br><span class="line">            cur_save_dir = os.path.join(pc.save_dir, <span class="string">&quot;model_best&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(cur_save_dir)</span><br><span class="line">            <span class="comment"># 检查并创建保存目录（如果不存在）</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(cur_save_dir):</span><br><span class="line">                os.makedirs(cur_save_dir)</span><br><span class="line">            <span class="comment"># 保存模型到指定目录</span></span><br><span class="line">            model.save_pretrained(cur_save_dir)</span><br><span class="line">            <span class="comment"># 保存分词器到指定目录</span></span><br><span class="line">            tokenizer.save_pretrained(cur_save_dir)</span><br><span class="line">        tic_train = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;训练结束&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate_model</span>(<span class="params">model,</span></span><br><span class="line"><span class="params">                   metric,</span></span><br><span class="line"><span class="params">                   data_loader,</span></span><br><span class="line"><span class="params">                   tokenizer,</span></span><br><span class="line"><span class="params">                   verbalizer</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    在测试集上评估当前模型的训练效果。</span></span><br><span class="line"><span class="string">    :param model: 当前模型</span></span><br><span class="line"><span class="string">    :param metric: 评估指标类(metric)</span></span><br><span class="line"><span class="string">    :param data_loader: 测试集的dataloader</span></span><br><span class="line"><span class="string">    :param tokenizer: 分词器</span></span><br><span class="line"><span class="string">    :param verbalizer: 映射表</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    metric.reset()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> step, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(data_loader, desc=<span class="string">&#x27;模型验证&#x27;</span>)):</span><br><span class="line">            <span class="comment"># print(f&#x27;batch--&gt;&#123;batch&#125;&#x27;)</span></span><br><span class="line">            logits = model(input_ids=batch[<span class="string">&#x27;input_ids&#x27;</span>].to(pc.device),</span><br><span class="line">                           token_type_ids=batch[<span class="string">&#x27;token_type_ids&#x27;</span>].to(pc.device),</span><br><span class="line">                           attention_mask=batch[<span class="string">&#x27;attention_mask&#x27;</span>].to(pc.device)).logits</span><br><span class="line">            <span class="comment"># print(f&#x27;验证集模型预测的结果————&gt;&#123;logits.shape&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">            mask_labels = batch[<span class="string">&#x27;mask_labels&#x27;</span>].numpy().tolist()  <span class="comment"># (batch, label_num)</span></span><br><span class="line">            <span class="comment"># print(f&quot;mask_labels-0--&gt;&#123;mask_labels&#125;&quot;)</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(mask_labels)):  <span class="comment"># 去掉label中的[PAD] token</span></span><br><span class="line">                <span class="keyword">while</span> tokenizer.pad_token_id <span class="keyword">in</span> mask_labels[i]:</span><br><span class="line">                    mask_labels[i].remove(tokenizer.pad_token_id)</span><br><span class="line">            <span class="comment"># print(f&#x27;mask_labels-1--&gt;&#123;mask_labels&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># 将mask_labels id转换为文字</span></span><br><span class="line">            mask_labels = [<span class="string">&#x27;&#x27;</span>.join(tokenizer.convert_ids_to_tokens(t)) <span class="keyword">for</span> t <span class="keyword">in</span> mask_labels]</span><br><span class="line">            <span class="comment"># print(f&#x27;真实的结果主标签：mask_labels_str--&gt;&#123;mask_labels&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 获取模型预测的子标签</span></span><br><span class="line">            predictions = convert_logits_to_ids(logits,</span><br><span class="line">                                                batch[<span class="string">&#x27;mask_positions&#x27;</span>]).cpu().numpy().tolist()  <span class="comment"># (batch, label_num)</span></span><br><span class="line">            <span class="comment"># print(f&#x27;模型预测的子标签的结果--&gt;&#123;predictions&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 根据模型预测的子标签，找到子label属于的主label</span></span><br><span class="line">            predictions = verbalizer.batch_find_main_label(predictions)  <span class="comment"># 找到子label属于的主label</span></span><br><span class="line">            <span class="comment"># print(f&quot;找到模型预测的子标签对应的主标签的结果--&gt;&#123;predictions&#125;&#x27;)&quot;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 获得预测的主标签名</span></span><br><span class="line">            predictions = [ele[<span class="string">&#x27;label&#x27;</span>] <span class="keyword">for</span> ele <span class="keyword">in</span> predictions]</span><br><span class="line">            <span class="comment"># print(f&quot;只获得预测的主标签的结果string--&gt;&#123;predictions&#125;&#x27;)&quot;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 调用add_batch方法, 将模型预测的主标签与真实主标签保存到metric属性中</span></span><br><span class="line">            metric.add_batch(pred_batch=predictions, gold_batch=mask_labels)</span><br><span class="line">    eval_metric = metric.compute()</span><br><span class="line">    model.train()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> eval_metric[<span class="string">&#x27;accuracy&#x27;</span>], eval_metric[<span class="string">&#x27;precision&#x27;</span>], \</span><br><span class="line">        eval_metric[<span class="string">&#x27;recall&#x27;</span>], eval_metric[<span class="string">&#x27;f1&#x27;</span>], \</span><br><span class="line">        eval_metric[<span class="string">&#x27;class_metrics&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    model2train()</span><br></pre></td></tr></table></figure>

<hr>
<ul>
<li>输出结果:</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">.....</span><br><span class="line"><span class="keyword">global</span> step <span class="number">40</span>, epoch: <span class="number">4</span>, loss: <span class="number">0.62105</span>, speed: <span class="number">1.27</span> step/s</span><br><span class="line">Evaluation precision: <span class="number">0.78000</span>, recall: <span class="number">0.77000</span>, F1: <span class="number">0.76000</span></span><br><span class="line">Each Class Metrics are: &#123;<span class="string">&#x27;书籍&#x27;</span>: &#123;<span class="string">&#x27;precision&#x27;</span>: <span class="number">0.97</span>, <span class="string">&#x27;recall&#x27;</span>: <span class="number">0.82</span>, <span class="string">&#x27;f1&#x27;</span>:</span><br><span class="line"><span class="number">0.89</span>&#125;, <span class="string">&#x27;平板&#x27;</span>: &#123;<span class="string">&#x27;precision&#x27;</span>: <span class="number">0.57</span>, <span class="string">&#x27;recall&#x27;</span>: <span class="number">0.84</span>, <span class="string">&#x27;f1&#x27;</span>: <span class="number">0.68</span>&#125;, <span class="string">&#x27;手机&#x27;</span>:</span><br><span class="line">&#123;<span class="string">&#x27;precision&#x27;</span>: <span class="number">0.0</span>, <span class="string">&#x27;recall&#x27;</span>: <span class="number">0.0</span>, <span class="string">&#x27;f1&#x27;</span>: <span class="number">0</span>&#125;, <span class="string">&#x27;水果&#x27;</span>: &#123;<span class="string">&#x27;precision&#x27;</span>: <span class="number">0.95</span>,</span><br><span class="line"><span class="string">&#x27;recall&#x27;</span>: <span class="number">0.81</span>, <span class="string">&#x27;f1&#x27;</span>: <span class="number">0.87</span>&#125;, <span class="string">&#x27;洗浴&#x27;</span>: &#123;<span class="string">&#x27;precision&#x27;</span>: <span class="number">0.7</span>, <span class="string">&#x27;recall&#x27;</span>: <span class="number">0.71</span>, <span class="string">&#x27;f1&#x27;</span>:</span><br><span class="line"><span class="number">0.7</span>&#125;, <span class="string">&#x27;电器&#x27;</span>: &#123;<span class="string">&#x27;precision&#x27;</span>: <span class="number">0.0</span>, <span class="string">&#x27;recall&#x27;</span>: <span class="number">0.0</span>, <span class="string">&#x27;f1&#x27;</span>: <span class="number">0</span>&#125;, <span class="string">&#x27;电脑&#x27;</span>: &#123;<span class="string">&#x27;precision&#x27;</span>:</span><br><span class="line"><span class="number">0.86</span>, <span class="string">&#x27;recall&#x27;</span>: <span class="number">0.38</span>, <span class="string">&#x27;f1&#x27;</span>: <span class="number">0.52</span>&#125;, <span class="string">&#x27;蒙牛&#x27;</span>: &#123;<span class="string">&#x27;precision&#x27;</span>: <span class="number">1.0</span>, <span class="string">&#x27;recall&#x27;</span>: <span class="number">0.68</span>,</span><br><span class="line"><span class="string">&#x27;f1&#x27;</span>: <span class="number">0.81</span>&#125;, <span class="string">&#x27;衣服&#x27;</span>: &#123;<span class="string">&#x27;precision&#x27;</span>: <span class="number">0.71</span>, <span class="string">&#x27;recall&#x27;</span>: <span class="number">0.91</span>, <span class="string">&#x27;f1&#x27;</span>: <span class="number">0.79</span>&#125;, <span class="string">&#x27;酒店&#x27;</span>:</span><br><span class="line">&#123;<span class="string">&#x27;precision&#x27;</span>: <span class="number">1.0</span>, <span class="string">&#x27;recall&#x27;</span>: <span class="number">0.88</span>, <span class="string">&#x27;f1&#x27;</span>: <span class="number">0.93</span>&#125;&#125;</span><br><span class="line"><span class="keyword">global</span> step <span class="number">50</span>, epoch: <span class="number">6</span>, loss: <span class="number">0.50076</span>, speed: <span class="number">1.23</span> step/s</span><br><span class="line"><span class="keyword">global</span> step <span class="number">60</span>, epoch: <span class="number">7</span>, loss: <span class="number">0.41744</span>, speed: <span class="number">1.23</span> step/s</span><br><span class="line">...</span><br><span class="line"><span class="keyword">global</span> step <span class="number">390</span>, epoch: <span class="number">48</span>, loss: <span class="number">0.06674</span>, speed: <span class="number">1.20</span> step/s</span><br><span class="line"><span class="keyword">global</span> step <span class="number">400</span>, epoch: <span class="number">49</span>, loss: <span class="number">0.06507</span>, speed: <span class="number">1.21</span> step/s</span><br><span class="line">Evaluation precision: <span class="number">0.78000</span>, recall: <span class="number">0.76000</span>, F1: <span class="number">0.75000</span></span><br></pre></td></tr></table></figure>

<hr>
<blockquote>
<ul>
<li>结论: BERT+PET模型在训练集上的表现是精确率&#x3D;78%</li>
<li>注意：本项目中只用了60条样本，在接近600条样本上精确率就已经达到了78%，如果想让指标更高，可以扩增样本。</li>
</ul>
</blockquote>
<hr>
<h3 id="3、实现模型预测函数"><a href="#3、实现模型预测函数" class="headerlink" title="3、实现模型预测函数"></a>3、实现模型预测函数</h3><ul>
<li><p>目的：加载训练好的模型并测试效果</p>
</li>
<li><p>代码路径：llm_tuning&#x2F;prompt_tasks&#x2F;PET&#x2F;inference.py</p>
<p>代码如下：</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForMaskedLM</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.data_handle.data_preprocess <span class="keyword">import</span> convert_example</span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.data_handle.template <span class="keyword">import</span> HardTemplate</span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.pet_config <span class="keyword">import</span> ProjectConfig</span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.utils.common_utils <span class="keyword">import</span> convert_logits_to_ids</span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.utils.verbalizer <span class="keyword">import</span> Verbalizer</span><br><span class="line"></span><br><span class="line">pc = ProjectConfig()</span><br><span class="line"></span><br><span class="line">model_path = os.path.join(pc.save_dir, <span class="string">&#x27;model_best&#x27;</span>)</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_path)</span><br><span class="line">model = AutoModelForMaskedLM.from_pretrained(model_path).to(pc.device)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">max_label_len = <span class="number">2</span>  <span class="comment"># 标签最大长度</span></span><br><span class="line">verbalizer = Verbalizer(</span><br><span class="line">    verbalizer_file=pc.verbalizer,</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    max_label_len=max_label_len)</span><br><span class="line">prompt = <span class="built_in">open</span>(pc.prompt_file, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf8&#x27;</span>).readlines()[<span class="number">0</span>].strip()  <span class="comment"># prompt定义</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;提示词--&gt; <span class="subst">&#123;prompt&#125;</span>&#x27;</span>)</span><br><span class="line">hard_template = HardTemplate(prompt=prompt)  <span class="comment"># 模板转换器定义</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">inference</span>(<span class="params">contents: <span class="type">List</span>[<span class="built_in">str</span>]</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    推理函数，输入原始句子，输出mask label的预测值。</span></span><br><span class="line"><span class="string">    :param contents:</span></span><br><span class="line"><span class="string">    :return: 描原始句子列表。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> (torch.no_grad()):</span><br><span class="line">        start_time = time.time()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将内容封装为示例字典，准备进行标记化处理</span></span><br><span class="line">        examples = &#123;<span class="string">&#x27;text&#x27;</span>: contents&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对示例进行标记化处理，返回标记化输出</span></span><br><span class="line">        tokenized_output = convert_example(</span><br><span class="line">            examples,</span><br><span class="line">            tokenizer,</span><br><span class="line">            hard_template=hard_template,</span><br><span class="line">            max_seq_len=<span class="number">128</span>,</span><br><span class="line">            max_label_len=max_label_len,</span><br><span class="line">            train_mode=<span class="literal">False</span>,</span><br><span class="line">            return_tensor=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 使用模型进行预测，获取logits</span></span><br><span class="line">        logits = model(input_ids=tokenized_output[<span class="string">&#x27;input_ids&#x27;</span>].to(pc.device),</span><br><span class="line">                       token_type_ids=tokenized_output[<span class="string">&#x27;token_type_ids&#x27;</span>].to(pc.device),</span><br><span class="line">                       attention_mask=tokenized_output[<span class="string">&#x27;attention_mask&#x27;</span>].to(pc.device)).logits</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将logits转换为预测标签</span></span><br><span class="line">        predictions = convert_logits_to_ids(logits, tokenized_output[<span class="string">&#x27;mask_positions&#x27;</span>]</span><br><span class="line">                                            ).cpu().numpy().tolist()  <span class="comment"># (batch, label_num)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 找到子label属于的主label</span></span><br><span class="line">        predictions = verbalizer.batch_find_main_label(predictions)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取预测的标签</span></span><br><span class="line">        predictions = [ele[<span class="string">&#x27;label&#x27;</span>] <span class="keyword">for</span> ele <span class="keyword">in</span> predictions]</span><br><span class="line"></span><br><span class="line">        used = time.time() - start_time</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;耗时 <span class="subst">&#123;used&#125;</span> 秒。&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> predictions</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    contents = [</span><br><span class="line">        <span class="string">&#x27;天台很好看，躺在躺椅上很悠闲，因为活动所以我觉得性价比还不错，适合一家出行，特别是去迪士尼也蛮近的，下次有机会肯定还会再来的，值得推荐&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;环境，设施，很棒，周边配套设施齐全，前台小姐姐超级漂亮！酒店很赞，早餐不错，服务态度很好，前台美眉很漂亮。性价比超高的一家酒店。强烈推荐&#x27;</span>,</span><br><span class="line">        <span class="string">&quot;物流超快，隔天就到了，还没用，屯着出游的时候用的，听方便的，占地小&quot;</span>,</span><br><span class="line">        <span class="string">&quot;福行市来到无早集市，因为是喜欢的面包店，所以跑来集市看看。第一眼就看到了，之前在微店买了小刘，这次买了老刘，还有一直喜欢的巧克力磅蛋糕。好奇老板为啥不做柠檬磅蛋糕了，微店一直都是买不到的状态。因为不爱碱水硬欧之类的，所以期待老板多来点其他小点，饼干一直也是大爱，那天好像也没看到&quot;</span>,</span><br><span class="line">        <span class="string">&quot;服务很用心，房型也很舒服，小朋友很喜欢，下次去嘉定还会再选择。床铺柔软舒适，晚上休息很安逸，隔音效果不错赞，下次还会来&quot;</span></span><br><span class="line">    ]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;针对下面的文本评论，请分别给出对应所属类别：&quot;</span>)</span><br><span class="line">    res = inference(contents)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;推断的类别为：&#x27;</span>, res)</span><br><span class="line">    new_dict = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(contents)):</span><br><span class="line">        new_dict[contents[i]] = res[i]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;new_dict--&gt;<span class="subst">&#123;new_dict&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>结果展示</li>
</ul>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&#123;</span></span><br><span class="line">    <span class="attr">&#x27;天台很好看，躺在躺椅上很悠闲，因为活动所以我觉得性价比还不错，适合一家出</span></span><br><span class="line"><span class="attr">行，特别是去迪士尼也蛮近的，下次有机会肯定还会再来的，值得推荐&#x27;</span>: <span class="string">&#x27;酒店&#x27;,</span></span><br><span class="line">    <span class="attr">&#x27;环境，设施，很棒，周边配套设施齐全，前台小姐姐超级漂亮！酒店很赞，早餐不</span></span><br><span class="line"><span class="attr">错，服务态度很好，前台美眉很漂亮。性价比超高的一家酒店。强烈推荐&#x27;</span>: <span class="string">&#x27;酒店&#x27;,</span></span><br><span class="line">    <span class="attr">&#x27;物流超快，隔天就到了，还没用，屯着出游的时候用的，听方便的，占地小&#x27;</span>: <span class="string">&#x27;平板&#x27;,</span></span><br><span class="line">    <span class="attr">&#x27;福行市来到无早集市，因为是喜欢的面包店，所以跑来集市看看。第一眼就看到了</span></span><br><span class="line"><span class="attr">，之前在微店买了小刘，这次买了老刘，还有一直喜欢的巧克力磅蛋糕。好奇老板为啥不做</span></span><br><span class="line"><span class="attr">柠檬磅蛋糕了，微店一直都是买不到的状态。因为不爱碱水硬欧之类的，所以期待老板多来</span></span><br><span class="line"><span class="attr">点其他小点，饼干一直也是大爱，那天好像也没看到&#x27;</span>: <span class="string">&#x27;水果&#x27;,</span></span><br><span class="line">    <span class="attr">&#x27;服务很用心，房型也很舒服，小朋友很喜欢，下次去嘉定还会再选择。床铺柔软舒</span></span><br><span class="line"><span class="attr">适，晚上休息很安逸，隔音效果不错赞，下次还会来&#x27;</span>: <span class="string">&#x27;酒店&#x27;</span></span><br><span class="line"><span class="attr">&#125;</span></span><br></pre></td></tr></table></figure>



<h2 id="五、BERT-P-Tuning方式介绍【理解】"><a href="#五、BERT-P-Tuning方式介绍【理解】" class="headerlink" title="五、BERT+P-Tuning方式介绍【理解】"></a>五、BERT+P-Tuning方式介绍【理解】</h2><h3 id="1、P-Tuning回顾"><a href="#1、P-Tuning回顾" class="headerlink" title="1、P-Tuning回顾"></a>1、P-Tuning回顾</h3><ul>
<li>P-Tuning（Pattern-Tuning）是一种连续空间可学习模板，PET的目的解决PET的缺点，使用可学习的向量作为伪模板，不再手动构建模板。</li>
</ul>
<div align=center><img src="./img/5-4-1.png" style="zoom:70%" ><img/></div>

<blockquote>
<p>以新闻分类任务为例：原始文本：中国女排再夺冠！P-Tuning可学习模板：[u1] [u2] …[MASK]…[un], Label：体育&#x2F;财经&#x2F;时政&#x2F;军事</p>
</blockquote>
<ul>
<li>P-tuning 的核心思想是：用一个小的可训练模块把一组“连续提示向量”生成并插入到原始输入 embedding 中，令<strong>冻结的预训练模型</strong>在下游任务上产生正确输出，训练时仅更新 prompt encoder（或提示向量），从而实现低成本高效的调优。</li>
</ul>
<hr>
<h3 id="2、环境准备"><a href="#2、环境准备" class="headerlink" title="2、环境准备"></a>2、环境准备</h3><p>本项目基于 pytorch + transformers 实现，运行前请安装相关依赖包：</p>
<hr>
<ul>
<li>python&#x3D;&#x3D;3.10</li>
<li>transformers&#x3D;&#x3D;4.40.2</li>
<li>torch&#x3D;&#x3D;2.5.1+cu121</li>
<li>datasets&#x3D;&#x3D;3.6.0</li>
<li>scikit-learn&#x3D;&#x3D;1.7.0</li>
</ul>
<hr>
<h3 id="3、项目架构-1"><a href="#3、项目架构-1" class="headerlink" title="3、项目架构"></a>3、项目架构</h3><ul>
<li>项目架构流程图：</li>
</ul>
<div align=center><img src="./img/5-4-2.png" style="zoom:35%" ><img/></div>

<ul>
<li>项目整体代码介绍：</li>
</ul>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250821011025805.png" alt="image-20250821011025805"></p>
<h2 id="六、BERT-P-Tuning方式数据预处理【理解】"><a href="#六、BERT-P-Tuning方式数据预处理【理解】" class="headerlink" title="六、BERT+P-Tuning方式数据预处理【理解】"></a>六、BERT+P-Tuning方式数据预处理【理解】</h2><p>本项目中对数据部分的预处理步骤如下:</p>
<ul>
<li>1.查看项目数据集</li>
<li>2.编写Config类项目文件配置代码</li>
<li>3.编写数据处理相关代码</li>
</ul>
<h3 id="1、查看项目数据集-1"><a href="#1、查看项目数据集-1" class="headerlink" title="1、查看项目数据集"></a>1、查看项目数据集</h3><ul>
<li><p>数据存放位置：llm_tuning&#x2F;prompt_tasks&#x2F;P-Tuning&#x2F;data</p>
</li>
<li><p>data文件夹里面包含3个txt文档，分别为：train.txt、dev.txt、verbalizer.txt</p>
</li>
</ul>
<hr>
<h4 id="1-1-train-txt-1"><a href="#1-1-train-txt-1" class="headerlink" title="1.1 train.txt"></a>1.1 train.txt</h4><ul>
<li>train.txt为训练数据集，其部分数据展示如下：</li>
</ul>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">水果	脆脆的，甜味可以，可能时间有点长了，水分不是很足。</span><br><span class="line">平板	华为机器肯定不错，但第一次碰上京东最糟糕的服务，以后不想到京东购物了。</span><br><span class="line">书籍	为什么不认真的检查一下， 发这么一本脏脏的书给顾客呢！</span><br><span class="line">衣服	手感不错，用料也很好，不知道水洗后怎样，相信大品牌，质量过关，五星好评！！！</span><br><span class="line">水果	苹果有点小，不过好吃，还有几个烂的。估计是故意的放的。差评。</span><br><span class="line">衣服	掉色掉的厉害，洗一次就花了</span><br></pre></td></tr></table></figure>

<blockquote>
<p>train.txt一共包含63条样本数据，每一行用<code>\t</code>分开，前半部分为标签(label)，后半部分为原始输入 (用户评论)。</p>
<p>如果想使用自定义数据训练，只需要仿照上述示例数据构建数据集即可。</p>
</blockquote>
<hr>
<h4 id="1-2-dev-txt-1"><a href="#1-2-dev-txt-1" class="headerlink" title="1.2 dev.txt"></a>1.2 dev.txt</h4><ul>
<li>dev.txt为验证数据集，其部分数据展示如下：</li>
</ul>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">书籍	&quot;一点都不好笑,很失望,内容也不是很实用&quot;</span><br><span class="line">衣服	完全是一条旧裤子。</span><br><span class="line">手机	相机质量不错，如果阳光充足，可以和数码相机媲美．界面比较人性化，容易使用．软件安装简便</span><br><span class="line">书籍	明明说有货，结果送货又没有了。并且也不告诉我，怎么评啊</span><br><span class="line">洗浴	非常不满意，晚上洗的头发，第二天头痒痒的不行了，还都是头皮屑。</span><br><span class="line">水果	这个苹果感觉是长熟的苹果，没有打蜡，不错，又甜又脆</span><br></pre></td></tr></table></figure>

<blockquote>
<p>dev.txt一共包含417条样本数据，每一行用<code>\t</code>分开，前半部分为标签(label)，后半部分为原始输入 (用户评论)。</p>
<p>如果想使用自定义数据训练，只需要仿照上述示例数据构建数据集即可。</p>
</blockquote>
<h4 id="1-3-verbalizer-txt"><a href="#1-3-verbalizer-txt" class="headerlink" title="1.3 verbalizer.txt"></a>1.3 verbalizer.txt</h4><ul>
<li><p>verbalizer.txt 主要用于定义「真实标签」到「标签预测词」之间的映射。在有些情况下，将「真实标签」作为 [MASK] 去预测可能不具备很好的语义通顺性，因此，我们会对「真实标签」做一定的映射。</p>
</li>
<li><p>例如：</p>
</li>
</ul>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;中国爆冷2-1战胜韩国&quot;是一则[MASK][MASK]新闻。	体育</span><br></pre></td></tr></table></figure>

<ul>
<li><p>这句话中的标签为「体育」，但如果我们将标签设置为「足球」会更容易预测。</p>
</li>
<li><p>因此，我们可以对「体育」这个 label 构建许多个子标签，在推理时，只要预测到子标签最终推理出真实标签即可，如下：</p>
</li>
</ul>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">体育 -&gt; 足球,篮球,网球,棒球,乒乓,体育</span><br></pre></td></tr></table></figure>

<ul>
<li>项目中标签词映射数据展示如下：</li>
</ul>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">电脑	电脑</span><br><span class="line">水果	水果</span><br><span class="line">平板	平板</span><br><span class="line">衣服	衣服</span><br><span class="line">酒店	酒店</span><br><span class="line">洗浴	洗浴</span><br><span class="line">书籍	书籍</span><br><span class="line">蒙牛	蒙牛</span><br><span class="line">手机	手机</span><br><span class="line">电器	电器</span><br></pre></td></tr></table></figure>

<blockquote>
<p>verbalizer.txt 一共包含10个类别，上述数据中，我们使用了1对1的verbalizer, 如果想定义一对多的映射，只需要在后面用”,”分割即可， eg: </p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">水果	苹果,香蕉,橘子</span><br></pre></td></tr></table></figure>

<p>若想使用自定义数据训练，只需要仿照示例数据构建数据集</p>
</blockquote>
<h3 id="2、编写Config类项目文件配置代码-1"><a href="#2、编写Config类项目文件配置代码-1" class="headerlink" title="2、编写Config类项目文件配置代码"></a>2、编写Config类项目文件配置代码</h3><ul>
<li><p>代码路径：llm_tuning&#x2F;prompt_tasks&#x2F;P-Tuning&#x2F;ptune_config.py</p>
</li>
<li><p>config文件目的：配置项目常用变量，一般这些变量属于不经常改变的，比如：训练文件路径、模型训练次数、模型超参数等等</p>
</li>
</ul>
<p>具体代码实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">base_dir = os.path.dirname(os.path.abspath(__file__))</span><br><span class="line"><span class="comment"># print(f&#x27;base_dir--&gt;&#123;base_dir&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ProjectConfig</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 设置设备为CUDA:0（如果可用），否则设置为CPU</span></span><br><span class="line">        self.device = <span class="string">&#x27;cuda:0&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line">        <span class="comment"># self.device = &quot;mps:0&quot;</span></span><br><span class="line">        <span class="comment"># 设置预训练模型的路径</span></span><br><span class="line">        self.pre_model = os.path.join(base_dir, <span class="string">&#x27;../../bert-base-chinese&#x27;</span>)</span><br><span class="line">        <span class="comment"># 设置训练数据集的路径</span></span><br><span class="line">        self.train_path = os.path.join(base_dir, <span class="string">&#x27;data/train.txt&#x27;</span>)</span><br><span class="line">        <span class="comment"># 设置验证数据集的路径</span></span><br><span class="line">        self.dev_path = os.path.join(base_dir, <span class="string">&#x27;data/dev.txt&#x27;</span>)</span><br><span class="line">        <span class="comment"># 设置verbalizer文件的路径，用于将标签映射到文本</span></span><br><span class="line">        self.verbalizer = os.path.join(base_dir, <span class="string">&#x27;data/verbalizer.txt&#x27;</span>)</span><br><span class="line">        <span class="comment"># 设置最大序列长度</span></span><br><span class="line">        self.max_seq_len = <span class="number">512</span></span><br><span class="line">        <span class="comment"># 设置批量大小</span></span><br><span class="line">        self.batch_size = <span class="number">8</span></span><br><span class="line">        <span class="comment"># 设置学习率</span></span><br><span class="line">        self.learning_rate = <span class="number">5e-5</span></span><br><span class="line">        <span class="comment"># 权重衰减系数</span></span><br><span class="line">        self.weight_decay = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 学习率预热的系数</span></span><br><span class="line">        self.warmup_ratio = <span class="number">0.06</span></span><br><span class="line">        <span class="comment"># 伪token的个数</span></span><br><span class="line">        self.p_embedding_num = <span class="number">6</span></span><br><span class="line">        <span class="comment"># 最大标签长度</span></span><br><span class="line">        self.max_label_len = <span class="number">2</span></span><br><span class="line">        <span class="comment"># 设置训练的轮数</span></span><br><span class="line">        self.epochs = <span class="number">50</span></span><br><span class="line">        <span class="comment"># 设置日志记录的步数</span></span><br><span class="line">        self.logging_steps = <span class="number">10</span></span><br><span class="line">        <span class="comment"># 设置验证的步数</span></span><br><span class="line">        self.valid_steps = <span class="number">20</span></span><br><span class="line">        <span class="comment"># 设置保存模型的目录</span></span><br><span class="line">        self.save_dir = os.path.join(base_dir, <span class="string">&#x27;save_model&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    pc = ProjectConfig()</span><br><span class="line">    <span class="built_in">print</span>(pc.verbalizer)</span><br></pre></td></tr></table></figure>

<h3 id="3、编写数据处理相关代码-1"><a href="#3、编写数据处理相关代码-1" class="headerlink" title="3、编写数据处理相关代码"></a>3、编写数据处理相关代码</h3><ul>
<li><p>代码路径：llm_tuning&#x2F;prompt_tasks&#x2F;P-Tuning&#x2F;data_handle&#x2F;</p>
</li>
<li><p>data_handle文件夹中一共包含两个py脚本：data_preprocess.py、data_loader.py</p>
</li>
</ul>
<hr>
<h4 id="3-1-data-preprocess-py"><a href="#3-1-data-preprocess-py" class="headerlink" title="3.1 data_preprocess.py"></a>3.1 data_preprocess.py</h4><ul>
<li>目的: 将模板与原始输入文本进行拼接，构造模型接受的输入数据</li>
<li>代码如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> prompt_tasks.P_Tuning.ptune_config <span class="keyword">import</span> ProjectConfig</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_example</span>(<span class="params"></span></span><br><span class="line"><span class="params">        examples: <span class="built_in">dict</span>,</span></span><br><span class="line"><span class="params">        tokenizer,</span></span><br><span class="line"><span class="params">        max_seq_len: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        max_label_len: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        p_embedding_num=<span class="number">6</span>,</span></span><br><span class="line"><span class="params">        train_mode=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">        return_tensor=<span class="literal">False</span></span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="built_in">dict</span>:</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    将样本数据转换为模型接收的输入数据。</span></span><br><span class="line"><span class="string">    :param examples: (dict): 训练数据样本</span></span><br><span class="line"><span class="string">    e.g. -&gt; &#123;</span></span><br><span class="line"><span class="string">                &quot;text&quot;: [</span></span><br><span class="line"><span class="string">                            &#x27;娱乐	嗨放派怎么停播了&#x27;,</span></span><br><span class="line"><span class="string">                            &#x27;体育	世界杯为何迟迟不见宣传&#x27;,</span></span><br><span class="line"><span class="string">                            ...</span></span><br><span class="line"><span class="string">                ]</span></span><br><span class="line"><span class="string">            &#125;</span></span><br><span class="line"><span class="string">    :param tokenizer: 分词器</span></span><br><span class="line"><span class="string">    :param max_seq_len: 最大句子长度</span></span><br><span class="line"><span class="string">    :param max_label_len: (int): 最大label长度，若没有达到最大长度，则padding为最大长度</span></span><br><span class="line"><span class="string">    :param p_embedding_num: (int): p-tuning token 的个数</span></span><br><span class="line"><span class="string">    :param train_mode: 训练阶段 or 推理阶段</span></span><br><span class="line"><span class="string">    :param return_tensor: 是否返回tensor类型，如不是，则返回numpy类型。</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    dict (str: np.array) -&gt; tokenized_output = &#123;</span></span><br><span class="line"><span class="string">                    &#x27;input_ids&#x27;: [[101, 3928, ...], [101, 4395, ...]],</span></span><br><span class="line"><span class="string">                    &#x27;token_type_ids&#x27;: [[0, 0, ...], [0, 0, ...]],</span></span><br><span class="line"><span class="string">                    &#x27;mask_positions&#x27;: [[5, 6, ...], [3, 4, ...]],</span></span><br><span class="line"><span class="string">                    &#x27;mask_labels&#x27;: [[183, 234], [298, 322], ...]</span></span><br><span class="line"><span class="string">                &#125;</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    tokenized_output = &#123;</span><br><span class="line">        <span class="string">&#x27;input_ids&#x27;</span>: [],</span><br><span class="line">        <span class="string">&#x27;attention_mask&#x27;</span>: [],</span><br><span class="line">        <span class="string">&#x27;mask_positions&#x27;</span>: [],  <span class="comment"># 记录label的位置（即MASK Token的位置）</span></span><br><span class="line">        <span class="string">&#x27;mask_labels&#x27;</span>: []  <span class="comment"># 记录MASK Token的原始值（即Label值）</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># print(f&quot;examples[&#x27;text&#x27;]--&gt;&#123;examples[&#x27;text&#x27;]&#125;&quot;)</span></span><br><span class="line">    <span class="comment"># 遍历文本数据集，其中每个文本数据被赋予一个索引和值</span></span><br><span class="line">    <span class="keyword">for</span> i, example <span class="keyword">in</span> <span class="built_in">enumerate</span>(examples[<span class="string">&#x27;text&#x27;</span>]):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># 将 prompt token(s) 插在 [CLS] 之后</span></span><br><span class="line">            start_mask_position = <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> train_mode:</span><br><span class="line">                <span class="comment"># print(f&quot;example--&gt;&#123;example&#125;&quot;)</span></span><br><span class="line">                <span class="comment"># strip() 方法用于移除字符串头尾指定的字符（默认为空格），这里用于去除可能存在的多余空格</span></span><br><span class="line">                <span class="comment"># split(&#x27;\t&#x27;, 1) 方法用于按照制表符(&#x27;\t&#x27;)将字符串分割成两部分，限制分割次数为1，确保只分割第一个制表符</span></span><br><span class="line">                label, content = example.strip().split(<span class="string">&#x27;\t&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">                <span class="comment"># print(f&#x27;label--&gt;&#123;label&#125;&#x27;)</span></span><br><span class="line">                <span class="comment"># print(f&#x27;content--&gt;&#123;content&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># 使用tokenizer对标签进行编码，label token 转 id</span></span><br><span class="line">                mask_labels = tokenizer(text=label)</span><br><span class="line">                <span class="comment"># print(f&#x27;mask_labels--&gt;&#123;mask_labels&#125;&#x27;)</span></span><br><span class="line">                <span class="comment"># 从字典中获取input_ids，并丢掉[CLS]和[SEP]</span></span><br><span class="line">                mask_labels = mask_labels[<span class="string">&#x27;input_ids&#x27;</span>][<span class="number">1</span>:-<span class="number">1</span>]</span><br><span class="line">                <span class="comment"># 将 label 长度限制为最长</span></span><br><span class="line">                mask_labels = mask_labels[:max_label_len]</span><br><span class="line">                <span class="comment"># 将 label 补到最长</span></span><br><span class="line">                mask_labels += [tokenizer.pad_token_id] * (max_label_len - <span class="built_in">len</span>(mask_labels))  <span class="comment"># 将 label 补到最长</span></span><br><span class="line">                <span class="comment"># print(f&#x27;mask_labels--&gt;&#123;mask_labels&#125;&#x27;)</span></span><br><span class="line">                <span class="comment"># 将编码后的标签添加到tokenized_output字典中的&#x27;mask_labels&#x27;列表中</span></span><br><span class="line">                tokenized_output[<span class="string">&#x27;mask_labels&#x27;</span>].append(mask_labels)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 如果不是训练模式，直接将文本内容进行修剪并使用</span></span><br><span class="line">                content = example.strip()</span><br><span class="line">            encoded_inputs = tokenizer(text=content,truncation=<span class="literal">True</span>,max_length=max_seq_len,padding=<span class="string">&#x27;max_length&#x27;</span>)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取编码后的输入</span></span><br><span class="line">        input_ids = encoded_inputs[<span class="string">&#x27;input_ids&#x27;</span>]</span><br><span class="line">        <span class="comment"># print(f&#x27;input_ids--&gt;&#123;input_ids&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;原始的input_id的长度--&gt;&#123;len(input_ids)&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1.生成 MASK Tokens, 和label长度一致</span></span><br><span class="line">        mask_tokens = [<span class="string">&#x27;[MASK]&#x27;</span>] * max_label_len</span><br><span class="line">        <span class="comment"># print(f&#x27;mask_tokens--&gt;&#123;mask_tokens&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 将 MASK Tokens 转为 id</span></span><br><span class="line">        mask_ids = tokenizer.convert_tokens_to_ids(mask_tokens)</span><br><span class="line">        <span class="comment"># print(f&#x27;mask_ids--&gt;&#123;mask_ids&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2.构建 prompt token(s)</span></span><br><span class="line">        <span class="comment"># 根据p_embedding_num生成对应的特殊token列表</span></span><br><span class="line">        p_tokens = [<span class="string">&quot;[unused&#123;&#125;]&quot;</span>.<span class="built_in">format</span>(i + <span class="number">1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(p_embedding_num)]</span><br><span class="line">        <span class="comment"># print(f&#x27;p_tokens--&gt;&#123;p_tokens&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># token 转 id</span></span><br><span class="line">        p_tokens_ids = tokenizer.convert_tokens_to_ids(p_tokens)</span><br><span class="line">        <span class="comment"># print(f&#x27;p_tokens_ids--&gt;&#123;p_tokens_ids&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 根据 最大长度-p_token长度-label长度-1，裁剪content的长度 (裁剪[SEP]前的token, 所以-1)</span></span><br><span class="line">        tmp_input_ids = input_ids[:max_seq_len - <span class="built_in">len</span>(mask_ids) - <span class="built_in">len</span>(p_tokens_ids) - <span class="number">1</span>]</span><br><span class="line">        <span class="comment"># print(f&#x27;tmp_input_ids1--&gt;&#123;tmp_input_ids&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;tmp_input_ids1--&gt;&#123;len(tmp_input_ids)&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3.插入 MASK -&gt; [CLS][MASK][MASK]世界杯...[SEP]</span></span><br><span class="line">        tmp_input_ids = tmp_input_ids[:start_mask_position] + mask_ids + tmp_input_ids[start_mask_position:] + [input_ids[-<span class="number">1</span>]]</span><br><span class="line">        <span class="comment"># print(f&#x27;插入mask和sep之后的 tmp_input_ids--&#123;tmp_input_ids&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;插入mask和sep之后的 tmp_input_ids长度--&#123;len(tmp_input_ids)&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4.插入 prompt -&gt; [unused1][unused2]...[CLS][MASK]...[SEP]</span></span><br><span class="line">        input_ids = p_tokens_ids + tmp_input_ids</span><br><span class="line">        <span class="comment"># print(f&#x27;插入模版之后的 input_ids--&gt;&#123;input_ids&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;插入模版之后的 input_ids长度--&gt;&#123;len(input_ids)&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将新的输入添加到tokenized_output字典中</span></span><br><span class="line">        tokenized_output[<span class="string">&#x27;input_ids&#x27;</span>].append(input_ids)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将 Mask Tokens 的位置记录下来</span></span><br><span class="line">        mask_positions = [<span class="built_in">len</span>(p_tokens_ids) + start_mask_position + i</span><br><span class="line">                          <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(max_label_len)]</span><br><span class="line">        <span class="comment"># print(f&#x27;mask_positions--&gt;&#123;mask_positions&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 将 Mask Tokens 的位置记录下来</span></span><br><span class="line">        tokenized_output[<span class="string">&#x27;mask_positions&#x27;</span>].append(mask_positions)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果输入需要token_type_ids，可以进行添加</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;token_type_ids&#x27;</span> <span class="keyword">in</span> encoded_inputs:  <span class="comment"># 兼容不需要 token_type_id 的模型, e.g. Roberta-Base</span></span><br><span class="line">            tmp = encoded_inputs[<span class="string">&#x27;token_type_ids&#x27;</span>]</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;token_type_ids&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> tokenized_output:</span><br><span class="line">                tokenized_output[<span class="string">&#x27;token_type_ids&#x27;</span>] = [tmp]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                tokenized_output[<span class="string">&#x27;token_type_ids&#x27;</span>].append(tmp)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print(f&#x27;原始的attention_mask--&gt;&#123;encoded_inputs[&quot;attention_mask&quot;]&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 修改attention_mask的0和1的位置，因为插入了prompt和MASK Tokens，影响了原来的句子padding的部分，所以需要重新生成</span></span><br><span class="line">        attention_mask = get_attention_mask(input_ids)</span><br><span class="line">        <span class="comment"># print(f&#x27;修改的attention_mask--&gt;&#123;attention_mask&#125;&#x27;)</span></span><br><span class="line">        tokenized_output[<span class="string">&#x27;attention_mask&#x27;</span>].append(attention_mask)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># break</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历tokenized_output字典，其中k是键，v是值</span></span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> tokenized_output.items():</span><br><span class="line">        <span class="comment"># 如果return_tensor为True，将值转换为torch.LongTensor类型</span></span><br><span class="line">        <span class="keyword">if</span> return_tensor:</span><br><span class="line">            tokenized_output[k] = torch.LongTensor(v)</span><br><span class="line">        <span class="comment"># 否则，将值转换为numpy数组</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            tokenized_output[k] = np.array(v)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tokenized_output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_attention_mask</span>(<span class="params">alist</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    生成注意力掩码。</span></span><br><span class="line"><span class="string">	对于输入的列表，将其中的每个元素与0进行比较，如果元素大于0，则在输出列表中对应位置设置为1，否则设置为0。</span></span><br><span class="line"><span class="string">	这个函数的目的是为了创建一个掩码，用于在注意力机制中指示哪些位置是有效的（即大于0），哪些位置是无效的（即等于0）。</span></span><br><span class="line"><span class="string">    :param alist: (list): 一个包含数字的列表，用于生成注意力掩码。</span></span><br><span class="line"><span class="string">    :return: list: 一个与输入列表长度相同的列表，其中原始列表中大于0的位置被设置为1，等于0的位置被设置为0。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 使用numpy的where函数来创建掩码：元素大于0则输出1，否则输出0</span></span><br><span class="line">    new_a = np.where(np.array(alist) &gt; <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 将生成的掩码数组转换回列表格式并返回</span></span><br><span class="line">    <span class="keyword">return</span> new_a.tolist()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    pc = ProjectConfig()</span><br><span class="line">    train_dataset = load_dataset(<span class="string">&#x27;text&#x27;</span>, data_files=&#123;<span class="string">&#x27;train&#x27;</span>: pc.train_path&#125;)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">type</span>(train_dataset))</span><br><span class="line">    <span class="comment"># print(train_dataset)</span></span><br><span class="line">    <span class="comment"># print(train_dataset[&#x27;train&#x27;][&#x27;text&#x27;])</span></span><br><span class="line">    tokenizer = AutoTokenizer.from_pretrained(pc.pre_model)</span><br><span class="line">    tokenized_output = convert_example(examples=train_dataset[<span class="string">&#x27;train&#x27;</span>],</span><br><span class="line">                                       tokenizer=tokenizer,</span><br><span class="line">                                       max_seq_len=<span class="number">20</span>,</span><br><span class="line">                                       max_label_len=<span class="number">2</span>,</span><br><span class="line">                                       p_embedding_num=<span class="number">6</span>,</span><br><span class="line">                                       train_mode=<span class="literal">True</span>,</span><br><span class="line">                                       return_tensor=<span class="literal">False</span>)</span><br><span class="line">    <span class="built_in">print</span>(tokenized_output)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">type</span>(tokenized_output[<span class="string">&#x27;mask_positions&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<blockquote>
<p>打印结果展示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;input_ids&#x27;</span>: array([[   <span class="number">1</span>,    <span class="number">2</span>,    <span class="number">3</span>, ..., <span class="number">1912</span>, <span class="number">6225</span>,  <span class="number">102</span>],</span><br><span class="line"> [   <span class="number">1</span>,    <span class="number">2</span>,    <span class="number">3</span>, ..., <span class="number">3300</span>, <span class="number">5741</span>,  <span class="number">102</span>],</span><br><span class="line"> [   <span class="number">1</span>,    <span class="number">2</span>,    <span class="number">3</span>, ..., <span class="number">6574</span>, <span class="number">7030</span>,    <span class="number">0</span>],</span><br><span class="line"> ...,</span><br><span class="line"> [   <span class="number">1</span>,    <span class="number">2</span>,    <span class="number">3</span>, ..., <span class="number">8024</span>, <span class="number">2571</span>,    <span class="number">0</span>],</span><br><span class="line"> [   <span class="number">1</span>,    <span class="number">2</span>,    <span class="number">3</span>, ..., <span class="number">3221</span>, <span class="number">3175</span>,  <span class="number">102</span>],</span><br><span class="line"> [   <span class="number">1</span>,    <span class="number">2</span>,    <span class="number">3</span>, ..., <span class="number">5277</span>, <span class="number">3688</span>,  <span class="number">102</span>]]), </span><br><span class="line"><span class="string">&#x27;attention_mask&#x27;</span>: array([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, ..., <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line"> [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, ..., <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line"> [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, ..., <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line"> ...,</span><br><span class="line"> [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, ..., <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, ..., <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line"> [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, ..., <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]]), </span><br><span class="line"><span class="string">&#x27;mask_positions&#x27;</span>: array([[<span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line"> [<span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line"> [<span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line"> ...,</span><br><span class="line"> [<span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line"> [<span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line"> [<span class="number">7</span>, <span class="number">8</span>]]), </span><br><span class="line"><span class="string">&#x27;mask_labels&#x27;</span>: array([[<span class="number">4510</span>, <span class="number">5554</span>],</span><br><span class="line"> [<span class="number">3717</span>, <span class="number">3362</span>],</span><br><span class="line"> [<span class="number">2398</span>, <span class="number">3352</span>],</span><br><span class="line"> ...,</span><br><span class="line"> [<span class="number">3819</span>, <span class="number">3861</span>],</span><br><span class="line"> [<span class="number">6983</span>, <span class="number">2421</span>],</span><br><span class="line"> [<span class="number">3819</span>, <span class="number">3861</span>]]), </span><br><span class="line"><span class="string">&#x27;token_type_ids&#x27;</span>: array([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> ...,</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]])&#125;</span><br></pre></td></tr></table></figure></blockquote>
<hr>
<h4 id="3-2-data-loader-py"><a href="#3-2-data-loader-py" class="headerlink" title="3.2 data_loader.py"></a>3.2 data_loader.py</h4><ul>
<li><p>目的：定义数据加载器</p>
</li>
<li><p>代码如下：</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, default_data_collator</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> prompt_tasks.P_Tuning.data_handle.data_preprocess <span class="keyword">import</span> convert_example</span><br><span class="line"><span class="keyword">from</span> prompt_tasks.P_Tuning.ptune_config <span class="keyword">import</span> ProjectConfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化项目配置文件</span></span><br><span class="line">pc = ProjectConfig()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用项目配置文件中指定的预训练模型，初始化一个自动分词器</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(pc.pre_model)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_data</span>():</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    加载并处理数据集。</span></span><br><span class="line"><span class="string">	该函数从指定路径加载训练和开发数据集，并将它们转换为适合模型训练的格式。</span></span><br><span class="line"><span class="string">	使用Hugging Face的`load_dataset`函数加载数据，然后使用`partial`函数创建一个带有固定参数的新函数`new_func`，</span></span><br><span class="line"><span class="string">	用于转换数据集示例。转换后的数据集使用`DataLoader`包装，以便于批量处理和训练过程中使用。</span></span><br><span class="line"><span class="string">    :return: train_dataloader: 训练数据加载器。</span></span><br><span class="line"><span class="string">             dev_dataloader: 测试数据加载器。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 加载数据集，包括训练和测试集</span></span><br><span class="line">    dataset = load_dataset(<span class="string">&#x27;text&#x27;</span>, data_files=&#123;<span class="string">&#x27;train&#x27;</span>: pc.train_path,</span><br><span class="line">                                               <span class="string">&#x27;dev&#x27;</span>: pc.dev_path&#125;)</span><br><span class="line">    <span class="comment"># print(f&#x27;dataset--&gt;&#123;dataset&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建一个带有固定参数的函数，用于转换数据集示例</span></span><br><span class="line">    new_func = partial(convert_example,</span><br><span class="line">                       tokenizer=tokenizer,</span><br><span class="line">                       max_seq_len=pc.max_seq_len,</span><br><span class="line">                       max_label_len=pc.max_label_len,</span><br><span class="line">                       p_embedding_num=pc.p_embedding_num)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 应用转换函数到数据集上</span></span><br><span class="line">    dataset = dataset.<span class="built_in">map</span>(new_func, batched=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 分离训练和测试数据集</span></span><br><span class="line">    train_dataset = dataset[<span class="string">&quot;train&quot;</span>]</span><br><span class="line">    <span class="comment"># print(f&#x27;train_dataset--&gt;&#123;train_dataset&#125;&#x27;)</span></span><br><span class="line">    dev_dataset = dataset[<span class="string">&quot;dev&quot;</span>]</span><br><span class="line">    <span class="comment"># print(f&#x27;dev_dataset--&gt;&#123;dev_dataset&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建训练数据加载器</span></span><br><span class="line">    train_dataloader = DataLoader(train_dataset,</span><br><span class="line">                                  shuffle=<span class="literal">True</span>,</span><br><span class="line">                                  collate_fn=default_data_collator,</span><br><span class="line">                                  batch_size=pc.batch_size)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建测试数据加载器</span></span><br><span class="line">    dev_dataloader = DataLoader(dev_dataset,</span><br><span class="line">                                collate_fn=default_data_collator,</span><br><span class="line">                                batch_size=pc.batch_size)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回训练和测试数据加载器</span></span><br><span class="line">    <span class="keyword">return</span> train_dataloader, dev_dataloader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 加载训练和测试数据</span></span><br><span class="line">    train_dataloader, dev_dataloader = get_data()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印训练和测试数据加载器的长度</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;len(train_dataloader)--&gt;<span class="subst">&#123;<span class="built_in">len</span>(train_dataloader)&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;len(dev_dataloader)--&gt;<span class="subst">&#123;<span class="built_in">len</span>(dev_dataloader)&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历训练数据加载器，查看数据</span></span><br><span class="line">    <span class="keyword">for</span> i, value <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataloader):</span><br><span class="line">        <span class="built_in">print</span>(value)</span><br><span class="line">        <span class="comment"># 打印输入ID的Tensor类型</span></span><br><span class="line">        <span class="built_in">print</span>(value[<span class="string">&#x27;input_ids&#x27;</span>].dtype)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p>打印结果展示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;input_ids&#x27;</span>: tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">     [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">     [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">     ...,</span><br><span class="line">     [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">     [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">     [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]]), </span><br><span class="line"><span class="string">&#x27;attention_mask&#x27;</span>: tensor([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">     [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">     [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">     ...,</span><br><span class="line">     [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">     [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">     [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]]), </span><br><span class="line"><span class="string">&#x27;mask_positions&#x27;</span>: tensor([[<span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">     [<span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">     [<span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">     [<span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">     [<span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">     [<span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">     [<span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">     [<span class="number">7</span>, <span class="number">8</span>]]), </span><br><span class="line"><span class="string">&#x27;mask_labels&#x27;</span>: tensor([[<span class="number">6132</span>, <span class="number">3302</span>],</span><br><span class="line">     [<span class="number">3717</span>, <span class="number">3362</span>],</span><br><span class="line">     [<span class="number">6132</span>, <span class="number">3302</span>],</span><br><span class="line">     [<span class="number">6983</span>, <span class="number">2421</span>],</span><br><span class="line">     [<span class="number">6983</span>, <span class="number">2421</span>],</span><br><span class="line">     [<span class="number">6132</span>, <span class="number">3302</span>],</span><br><span class="line">     [<span class="number">3717</span>, <span class="number">3362</span>],</span><br><span class="line">     [<span class="number">2398</span>, <span class="number">3352</span>]]), </span><br><span class="line"><span class="string">&#x27;token_type_ids&#x27;</span>: tensor([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">     [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">     [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">     ...,</span><br><span class="line">     [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">     [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">     [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]])&#125;</span><br><span class="line">torch.int64</span><br></pre></td></tr></table></figure></blockquote>
<h2 id="七、BERT-P-Tuning方式模型搭建与训练【实现】"><a href="#七、BERT-P-Tuning方式模型搭建与训练【实现】" class="headerlink" title="七、BERT+P-Tuning方式模型搭建与训练【实现】"></a>七、BERT+P-Tuning方式模型搭建与训练【实现】</h2><p>本项目中完成BERT+P-Tuning模型搭建、训练及应用的步骤如下（注意：因为本项目中使用的是BERT预训练模型，所以直接加载即可，无需重复搭建模型架构）:</p>
<ul>
<li>1.实现模型工具类函数</li>
<li>2.实现模型训练函数,验证函数</li>
<li>3.实现模型预测函数</li>
</ul>
<hr>
<h3 id="1、实现模型工具类函数-1"><a href="#1、实现模型工具类函数-1" class="headerlink" title="1、实现模型工具类函数"></a>1、实现模型工具类函数</h3><ul>
<li>目的：模型在训练、验证、预测时需要的函数</li>
<li>代码路径：llm_tuning&#x2F;prompt_tasks&#x2F;P_Tuning&#x2F;utils</li>
<li>utils文件夹共包含3个py脚本：verbalizer.py、metirc_utils.py以及common_utils.py</li>
</ul>
<hr>
<h4 id="1-1-verbalizer-py-1"><a href="#1-1-verbalizer-py-1" class="headerlink" title="1.1 verbalizer.py"></a>1.1 verbalizer.py</h4><ul>
<li>目的：定义一个Verbalizer类，用于将一个Label对应到其子Label的映射。</li>
<li>具体代码如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Union 是 typing 模块中定义的一个类,用于表示多个类型中的任意一种类型</span></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Union</span>, <span class="type">List</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> prompt_tasks.P_Tuning.ptune_config <span class="keyword">import</span> ProjectConfig</span><br><span class="line"></span><br><span class="line">pc = ProjectConfig()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Verbalizer类，用于将一个Label对应到其子Label的映射。</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Verbalizer</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 verbalizer_file: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">                 tokenizer, max_label_len: <span class="built_in">int</span></span></span><br><span class="line"><span class="params">                 </span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param verbalizer_file: verbalizer文件存放地址。</span></span><br><span class="line"><span class="string">        :param tokenizer: 用于文本和id之间的转换。</span></span><br><span class="line"><span class="string">        :param max_label_len: 标签长度，若大于则截断，若小于则补齐</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.tokenizer = tokenizer</span><br><span class="line">        self.label_dict = self.load_label_dict(verbalizer_file)</span><br><span class="line">        self.max_label_len = max_label_len</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_label_dict</span>(<span class="params">self, verbalizer_file: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        读取本地文件，构建verbalizer字典。</span></span><br><span class="line"><span class="string">        :param verbalizer_file: verbalizer文件存放地址。</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        dict -&gt; &#123;</span></span><br><span class="line"><span class="string">            &#x27;体育&#x27;: [&#x27;篮球&#x27;, &#x27;足球&#x27;,&#x27;网球&#x27;, &#x27;排球&#x27;,  ...],</span></span><br><span class="line"><span class="string">            &#x27;酒店&#x27;: [&#x27;宾馆&#x27;, &#x27;旅馆&#x27;, &#x27;旅店&#x27;, &#x27;酒店&#x27;, ...],</span></span><br><span class="line"><span class="string">            ...</span></span><br><span class="line"><span class="string">            &#125;</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化一个空字典，用于存储标签和子标签的关系</span></span><br><span class="line">        label_dict = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打开verbalizer文件，以只读模式，使用utf8编码</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(verbalizer_file, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="comment"># 读取文件的每一行</span></span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                <span class="comment"># 移除行尾的换行符，并按制表符(&#x27;\t&#x27;)分割标签和子标签</span></span><br><span class="line">                label, sub_labels = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">                <span class="comment"># 将子标签按逗号(,)分割成列表，使用set去重后再转回列表，存储到label_dict中</span></span><br><span class="line">                label_dict[label] = <span class="built_in">list</span>(<span class="built_in">set</span>(sub_labels.split(<span class="string">&#x27;,&#x27;</span>)))</span><br><span class="line">        <span class="comment"># 返回处理后的标签和子标签的字典</span></span><br><span class="line">        <span class="keyword">return</span> label_dict</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">find_sub_labels</span>(<span class="params">self, label: <span class="type">Union</span>[<span class="built_in">list</span>, <span class="built_in">str</span>]</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        通过主标签找到所有的子标签。</span></span><br><span class="line"><span class="string">        :param label: 标签, 文本型 或 id_list, e.g. -&gt; &#x27;体育&#x27; or [860, 5509]</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        dict -&gt; &#123;</span></span><br><span class="line"><span class="string">            &#x27;sub_labels&#x27;: [&#x27;足球&#x27;, &#x27;网球&#x27;],</span></span><br><span class="line"><span class="string">            &#x27;token_ids&#x27;: [[6639, 4413], [5381, 4413]]</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 如果传入的label为id列表，则通过tokenizer转换回字符串</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(label) == <span class="built_in">list</span>:</span><br><span class="line">            <span class="comment"># 移除label中的pad_token_id，直到label中不再包含它</span></span><br><span class="line">            <span class="keyword">while</span> self.tokenizer.pad_token_id <span class="keyword">in</span> label:</span><br><span class="line">                label.remove(self.tokenizer.pad_token_id)</span><br><span class="line">            <span class="comment"># 将处理后的id列表转换为tokens，并拼接成字符串</span></span><br><span class="line">            label = <span class="string">&#x27;&#x27;</span>.join(self.tokenizer.convert_ids_to_tokens(label))</span><br><span class="line">        <span class="comment"># print(f&#x27;label--&gt;&#123;label&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 检查转换后的label是否在标签字典中，如果不在则抛出异常</span></span><br><span class="line">        <span class="keyword">if</span> label <span class="keyword">not</span> <span class="keyword">in</span> self.label_dict:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">f&#x27;Lable Error: &quot;<span class="subst">&#123;label&#125;</span>&quot; 不在 label_dict <span class="subst">&#123;<span class="built_in">list</span>(self.label_dict)&#125;</span>.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 从标签字典中获取与label对应的子标签</span></span><br><span class="line">        sub_labels = self.label_dict[label]</span><br><span class="line">        <span class="comment"># print(f&#x27;sub_labels--&gt;&#123;sub_labels&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 将子标签作为结果的一个部分存储在字典中</span></span><br><span class="line">        ret = &#123;<span class="string">&#x27;sub_labels&#x27;</span>: sub_labels&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对每个子标签进行token化，不含特殊符号</span></span><br><span class="line">        token_ids = [token_id <span class="keyword">for</span> token_id <span class="keyword">in</span> self.tokenizer(sub_labels, add_special_tokens=<span class="literal">False</span>)[<span class="string">&#x27;input_ids&#x27;</span>]]</span><br><span class="line">        <span class="comment"># print(f&#x27;token_ids--&gt;&#123;token_ids&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 遍历所有的token_ids，进行截断与补齐操作</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(token_ids)):</span><br><span class="line">            <span class="comment"># 对标签进行截断</span></span><br><span class="line">            token_ids[i] = token_ids[i][:self.max_label_len]</span><br><span class="line">            <span class="comment"># 如果长度不足max_label_len，则使用pad_token_id进行补齐</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(token_ids[i]) &lt; self.max_label_len:</span><br><span class="line">                token_ids[i] = token_ids[i] + [self.tokenizer.pad_token_id] * (self.max_label_len - <span class="built_in">len</span>(token_ids[i]))</span><br><span class="line">        <span class="comment"># 将处理后的token_ids存入ret字典中</span></span><br><span class="line">        ret[<span class="string">&#x27;token_ids&#x27;</span>] = token_ids</span><br><span class="line">        <span class="keyword">return</span> ret</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">batch_find_sub_labels</span>(<span class="params">self, label: <span class="type">List</span>[<span class="type">Union</span>[<span class="built_in">list</span>, <span class="built_in">str</span>]]</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        批量找到子标签。</span></span><br><span class="line"><span class="string">        :param label: 标签列表, [[4510, 5554], [860, 5509]] or [&#x27;体育&#x27;, &#x27;电脑&#x27;]</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        list -&gt; [</span></span><br><span class="line"><span class="string">                &#123;</span></span><br><span class="line"><span class="string">                    &#x27;sub_labels&#x27;: [&#x27;笔记本&#x27;, &#x27;电脑&#x27;],</span></span><br><span class="line"><span class="string">                    &#x27;token_ids&#x27;: [[5011, 6381, 3315], [4510, 5554]]</span></span><br><span class="line"><span class="string">                &#125;,</span></span><br><span class="line"><span class="string">                ...</span></span><br><span class="line"><span class="string">            ]</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> [self.find_sub_labels(l) <span class="keyword">for</span> l <span class="keyword">in</span> label]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_common_sub_str</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                           str1: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">                           str2: <span class="built_in">str</span></span></span><br><span class="line"><span class="params">                           </span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        寻找最大公共子串(连续子序列)。</span></span><br><span class="line"><span class="string">        :param str1: abcd</span></span><br><span class="line"><span class="string">        :param str2: abadbcdba</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化两个字符串的长度</span></span><br><span class="line">        lstr1, lstr2 = <span class="built_in">len</span>(str1), <span class="built_in">len</span>(str2)</span><br><span class="line">        <span class="comment"># 生成0矩阵，为方便后续计算，比字符串长度多了一列，生成一个 lstr1+1 * lstr2+1 的二维矩阵</span></span><br><span class="line">        record = [[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(lstr2 + <span class="number">1</span>)] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(lstr1 + <span class="number">1</span>)]</span><br><span class="line">        <span class="comment"># 初始化最长匹配对应在str1中的最后一位</span></span><br><span class="line">        p = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 初始化最长匹配长度</span></span><br><span class="line">        maxNum = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 遍历两个字符串，寻找最长公共子串</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, lstr1 + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, lstr2 + <span class="number">1</span>):</span><br><span class="line">                <span class="comment"># 当发现相同字符时</span></span><br><span class="line">                <span class="keyword">if</span> str1[i - <span class="number">1</span>] == str2[j - <span class="number">1</span>]:</span><br><span class="line">                    <span class="comment"># 在record矩阵中记录匹配长度</span></span><br><span class="line">                    record[i][j] = record[i - <span class="number">1</span>][j - <span class="number">1</span>] + <span class="number">1</span></span><br><span class="line">                    <span class="comment"># 更新最长匹配长度和对应在str1中的最后一位</span></span><br><span class="line">                    <span class="keyword">if</span> record[i][j] &gt; maxNum:</span><br><span class="line">                        maxNum = record[i][j]</span><br><span class="line">                        p = i</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 返回最长公共子串和其长度</span></span><br><span class="line">        <span class="keyword">return</span> str1[p - maxNum:p], maxNum</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">hard_mapping</span>(<span class="params">self, sub_label: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        强匹配函数，当模型生成的子label不存在时，通过最大公共子串找到重合度最高的主label。</span></span><br><span class="line"><span class="string">        :param sub_label: 子label</span></span><br><span class="line"><span class="string">        :return: 主label</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化变量label和max_overlap_str，用于记录最大重叠度的标签和对应的重叠度值</span></span><br><span class="line">        label, max_overlap_str = <span class="string">&#x27;&#x27;</span>, <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 遍历标签字典，其中main_label是主标签，sub_labels是与主标签相关的子标签列表</span></span><br><span class="line">        <span class="keyword">for</span> main_label, sub_labels <span class="keyword">in</span> self.label_dict.items():</span><br><span class="line">            overlap_num = <span class="number">0</span></span><br><span class="line">            <span class="comment"># 对于每个子标签，计算它与当前推理标签之间的最长公共子串长度总和</span></span><br><span class="line">            <span class="keyword">for</span> s_label <span class="keyword">in</span> sub_labels:</span><br><span class="line">                <span class="comment"># 累加每个子标签与当前推理标签之间的最长公共子串长度</span></span><br><span class="line">                overlap_num += self.get_common_sub_str(sub_label, s_label)[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 如果当前的重叠度大于或等于之前的最大重叠度，则更新最大重叠度和对应的标签</span></span><br><span class="line">            <span class="keyword">if</span> overlap_num &gt;= max_overlap_str:</span><br><span class="line">                max_overlap_str = overlap_num</span><br><span class="line">                label = main_label</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> label</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">find_main_label</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                        sub_label: <span class="type">Union</span>[<span class="built_in">list</span>, <span class="built_in">str</span>],</span></span><br><span class="line"><span class="params">                        hard_mapping=<span class="literal">True</span></span></span><br><span class="line"><span class="params">                        </span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        通过子标签找到父标签。</span></span><br><span class="line"><span class="string">        :param sub_label: 子标签, 文本型 或 id_list, e.g. -&gt; &#x27;苹果&#x27; or [5741, 3362]</span></span><br><span class="line"><span class="string">        :param hard_mapping: 当生成的词语不存在时，是否一定要匹配到一个最相似的label。</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        dict -&gt; &#123;</span></span><br><span class="line"><span class="string">            &#x27;label&#x27;: &#x27;水果&#x27;,</span></span><br><span class="line"><span class="string">            &#x27;token_ids&#x27;: [3717, 3362]</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 如果传入的sub_label为id列表，则通过tokenizer转换回字符串</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(sub_label) == <span class="built_in">list</span>:</span><br><span class="line">            pad_token_id = self.tokenizer.pad_token_id</span><br><span class="line">            <span class="comment"># 移除列表中的[PAD]token，避免影响后续处理</span></span><br><span class="line">            <span class="keyword">while</span> pad_token_id <span class="keyword">in</span> sub_label:</span><br><span class="line">                sub_label.remove(pad_token_id)</span><br><span class="line">            <span class="comment"># 将id列表转换为对应的字符串</span></span><br><span class="line">            sub_label = <span class="string">&#x27;&#x27;</span>.join(self.tokenizer.convert_ids_to_tokens(sub_label))</span><br><span class="line">        <span class="comment"># print(f&#x27;sub_label--&gt;&#123;sub_label&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 初始化主标签为&#x27;无&#x27;，作为未找到特定子标签时的默认值</span></span><br><span class="line">        main_label = <span class="string">&#x27;无&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 遍历标签字典，寻找与子标签匹配的主标签</span></span><br><span class="line">        <span class="keyword">for</span> label, sub_labels <span class="keyword">in</span> self.label_dict.items():</span><br><span class="line">            <span class="comment"># 检查当前子标签是否在字典中对应的子标签列表中</span></span><br><span class="line">            <span class="keyword">if</span> sub_label <span class="keyword">in</span> sub_labels:</span><br><span class="line">                <span class="comment"># 当找到匹配时，更新主标签并终止循环</span></span><br><span class="line">                main_label = label</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="comment"># print(f&#x27;main_label--&gt;&#123;main_label&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 如果主标签为&#x27;无&#x27;且启用了强匹配功能，则使用强匹配方法更新主标签</span></span><br><span class="line">        <span class="keyword">if</span> main_label == <span class="string">&#x27;无&#x27;</span> <span class="keyword">and</span> hard_mapping:</span><br><span class="line">            main_label = self.hard_mapping(sub_label)</span><br><span class="line">        <span class="comment"># print(&#x27;强匹配&#x27;, main_label)</span></span><br><span class="line">        ret = &#123;</span><br><span class="line">            <span class="string">&#x27;label&#x27;</span>: main_label,</span><br><span class="line">            <span class="string">&#x27;token_ids&#x27;</span>: self.tokenizer(main_label, add_special_tokens=<span class="literal">False</span>)[<span class="string">&#x27;input_ids&#x27;</span>]</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ret</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">batch_find_main_label</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                              sub_label: <span class="type">List</span>[<span class="type">Union</span>[<span class="built_in">list</span>, <span class="built_in">str</span>]],</span></span><br><span class="line"><span class="params">                              hard_mapping=<span class="literal">True</span></span></span><br><span class="line"><span class="params">                              </span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        批量通过子标签找父标签。</span></span><br><span class="line"><span class="string">        :param sub_label: 子标签列表, [&#x27;苹果&#x27;, ...] or [[5741, 3362], ...]</span></span><br><span class="line"><span class="string">        :param hard_mapping:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        list: [</span></span><br><span class="line"><span class="string">                &#123;</span></span><br><span class="line"><span class="string">                &#x27;label&#x27;: &#x27;水果&#x27;,</span></span><br><span class="line"><span class="string">                &#x27;token_ids&#x27;: [3717, 3362]</span></span><br><span class="line"><span class="string">                &#125;,</span></span><br><span class="line"><span class="string">                ...</span></span><br><span class="line"><span class="string">        ]</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> [self.find_main_label(l, hard_mapping) <span class="keyword">for</span> l <span class="keyword">in</span> sub_label]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    tokenizer = AutoTokenizer.from_pretrained(pc.pre_model)</span><br><span class="line">    verbalizer = Verbalizer(</span><br><span class="line">        verbalizer_file=pc.verbalizer,</span><br><span class="line">        tokenizer=tokenizer,</span><br><span class="line">        max_label_len=<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;label_dict--&gt;<span class="subst">&#123;verbalizer.label_dict&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查找单个子标签</span></span><br><span class="line">    label = <span class="string">&#x27;电脑&#x27;</span></span><br><span class="line">    ret = verbalizer.find_sub_labels(label)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;ret--&gt;<span class="subst">&#123;ret&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;*&#x27;</span> * <span class="number">80</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查找多个子标签</span></span><br><span class="line">    labels = [<span class="string">&#x27;电脑&#x27;</span>, <span class="string">&#x27;衣服&#x27;</span>]</span><br><span class="line">    <span class="comment"># labels = [[4510, 5554], [6132, 3302]]</span></span><br><span class="line">    result = verbalizer.batch_find_sub_labels(labels)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;result--&gt;<span class="subst">&#123;result&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;*&#x27;</span> * <span class="number">80</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查找单个子标签对应的父标签</span></span><br><span class="line">    <span class="comment"># sub_label = [4510, 5554]</span></span><br><span class="line">    sub_label = <span class="string">&#x27;衣电&#x27;</span></span><br><span class="line">    ret = verbalizer.find_main_label(sub_label)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;ret--&gt;<span class="subst">&#123;ret&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;*&#x27;</span> * <span class="number">80</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查找多个子标签对应的父标签</span></span><br><span class="line">    <span class="comment"># sub_label = [&#x27;衣服&#x27;, &#x27;牛奶&#x27;]</span></span><br><span class="line">    sub_label = [[<span class="number">6132</span>, <span class="number">3302</span>], [<span class="number">5885</span>, <span class="number">4281</span>]]</span><br><span class="line">    ret = verbalizer.batch_find_main_label(sub_label, hard_mapping=<span class="literal">True</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;ret--&gt;<span class="subst">&#123;ret&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p>print结果显示:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">label_dict--&gt;&#123;<span class="string">&#x27;电脑&#x27;</span>: [<span class="string">&#x27;电脑&#x27;</span>], <span class="string">&#x27;水果&#x27;</span>: [<span class="string">&#x27;水果&#x27;</span>], <span class="string">&#x27;平板&#x27;</span>: [<span class="string">&#x27;平板&#x27;</span>], <span class="string">&#x27;衣服&#x27;</span>: [<span class="string">&#x27;衣服&#x27;</span>], <span class="string">&#x27;酒店&#x27;</span>: [<span class="string">&#x27;酒店&#x27;</span>], <span class="string">&#x27;洗浴&#x27;</span>: [<span class="string">&#x27;洗浴&#x27;</span>], <span class="string">&#x27;书籍&#x27;</span>: [<span class="string">&#x27;书籍&#x27;</span>], <span class="string">&#x27;蒙牛&#x27;</span>: [<span class="string">&#x27;蒙牛&#x27;</span>], <span class="string">&#x27;手机&#x27;</span>: [<span class="string">&#x27;手机&#x27;</span>], <span class="string">&#x27;电器&#x27;</span>: [<span class="string">&#x27;电器&#x27;</span>]&#125;</span><br><span class="line">ret--&gt;&#123;<span class="string">&#x27;sub_labels&#x27;</span>: [<span class="string">&#x27;电脑&#x27;</span>], <span class="string">&#x27;token_ids&#x27;</span>: [[<span class="number">4510</span>, <span class="number">5554</span>]]&#125;</span><br><span class="line">********************************************************************************</span><br><span class="line">result--&gt;[&#123;<span class="string">&#x27;sub_labels&#x27;</span>: [<span class="string">&#x27;电脑&#x27;</span>], <span class="string">&#x27;token_ids&#x27;</span>: [[<span class="number">4510</span>, <span class="number">5554</span>]]&#125;, &#123;<span class="string">&#x27;sub_labels&#x27;</span>: [<span class="string">&#x27;衣服&#x27;</span>], <span class="string">&#x27;token_ids&#x27;</span>: [[<span class="number">6132</span>, <span class="number">3302</span>]]&#125;]</span><br><span class="line">********************************************************************************</span><br><span class="line">ret--&gt;&#123;<span class="string">&#x27;label&#x27;</span>: <span class="string">&#x27;电器&#x27;</span>, <span class="string">&#x27;token_ids&#x27;</span>: [<span class="number">4510</span>, <span class="number">1690</span>]&#125;</span><br><span class="line">********************************************************************************</span><br><span class="line">ret--&gt;[&#123;<span class="string">&#x27;label&#x27;</span>: <span class="string">&#x27;衣服&#x27;</span>, <span class="string">&#x27;token_ids&#x27;</span>: [<span class="number">6132</span>, <span class="number">3302</span>]&#125;, &#123;<span class="string">&#x27;label&#x27;</span>: <span class="string">&#x27;蒙牛&#x27;</span>, <span class="string">&#x27;token_ids&#x27;</span>: [<span class="number">5885</span>, <span class="number">4281</span>]&#125;]</span><br></pre></td></tr></table></figure></blockquote>
<hr>
<h4 id="1-2-common-utils-py-1"><a href="#1-2-common-utils-py-1" class="headerlink" title="1.2 common_utils.py"></a>1.2 common_utils.py</h4><ul>
<li>目的：定义损失函数、将mask_position位置的token logits转换为token的id。</li>
<li>脚本里面包含两个函数：mlm_loss()以及convert_logits_to_ids()</li>
<li>代码如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mlm_loss</span>(<span class="params">logits,</span></span><br><span class="line"><span class="params">             mask_positions,</span></span><br><span class="line"><span class="params">             sub_mask_labels,</span></span><br><span class="line"><span class="params">             cross_entropy_criterion,</span></span><br><span class="line"><span class="params">             device</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    计算指定位置的mask token的output与label之间的cross entropy loss。</span></span><br><span class="line"><span class="string">    :param logits: (torch.tensor): 模型原始输出 -&gt; (batch_size, seq_len, vocab_size)</span></span><br><span class="line"><span class="string">    :param mask_positions: (torch.tensor): mask token的位置  -&gt; (batch_size, mask_label_num)</span></span><br><span class="line"><span class="string">    :param sub_mask_labels: (list): mask token的sub label, 由于每个label的sub_label数目不同，所以这里是个变长的list,</span></span><br><span class="line"><span class="string">                                    e.g. -&gt; [</span></span><br><span class="line"><span class="string">                                        [[2398, 3352]],</span></span><br><span class="line"><span class="string">                                        [[2398, 3352], [3819, 3861]]</span></span><br><span class="line"><span class="string">                                    ]</span></span><br><span class="line"><span class="string">    :param cross_entropy_criterion: (CrossEntropyLoss): CE Loss计算器</span></span><br><span class="line"><span class="string">    :param device: (str): cpu还是gpu</span></span><br><span class="line"><span class="string">    :return: CE Loss</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    获取logits的尺寸信息，为后续计算做准备</span></span><br><span class="line"><span class="string">    logits.size()返回一个包含三个维度的元组</span></span><br><span class="line"><span class="string">    第一个维度(batch_size)代表批次大小，即一次处理的数据批次包含的样本数量</span></span><br><span class="line"><span class="string">    第二个维度(seq_len)代表序列长度，即每个样本中包含的序列元素数量</span></span><br><span class="line"><span class="string">    第三个维度(vocab_size)代表词汇表大小，即每个序列元素可能的类别数量</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    batch_size, seq_len, vocab_size = logits.size()</span><br><span class="line">    <span class="comment"># print(f&#x27;模型预测结果logits--&gt;&#123;logits.size()&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;mask_positions--&gt;&#123;mask_positions.shape&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;sub_mask_labels--&gt;&#123;sub_mask_labels&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化loss变量为None，用于后续可能的损失计算</span></span><br><span class="line">    loss = <span class="literal">None</span></span><br><span class="line">    <span class="comment"># 遍历 logits、sub_mask_labels 和 mask_positions 的元素</span></span><br><span class="line">    <span class="keyword">for</span> single_value <span class="keyword">in</span> <span class="built_in">zip</span>(logits, sub_mask_labels, mask_positions):</span><br><span class="line">        <span class="comment"># 获取当前token的 logits</span></span><br><span class="line">        single_logits = single_value[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># print(f&#x27;single_logits--&gt;&#123;single_logits.shape&#125;&#x27;)  # 形状[512, 21128]</span></span><br><span class="line">        <span class="comment"># 获取当前token的 sub_mask_labels</span></span><br><span class="line">        single_sub_mask_labels = single_value[<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># print(f&#x27;single_sub_mask_labels--&gt;&#123;single_sub_mask_labels&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 获取当前token的 mask_positions</span></span><br><span class="line">        single_mask_positions = single_value[<span class="number">2</span>]</span><br><span class="line">        <span class="comment"># print(f&#x27;single_mask_positions--&gt;&#123;single_mask_positions&#125;&#x27;)  # 形状size[2]--&gt;具体值([5, 6])</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 从单个序列的logits中，提取出被掩码位置的logits</span></span><br><span class="line">        single_mask_logits = single_logits[single_mask_positions]  <span class="comment"># (mask_label_num, vocab_size)</span></span><br><span class="line">        <span class="comment"># 打印被掩码位置logits的形状，以验证其是否符合预期</span></span><br><span class="line">        <span class="comment"># print(f&#x27;single_mask_logits--&gt;&#123;single_mask_logits.shape&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 模型训练时主标签对应的所有子标签都有相似的特征值, 在计算CE Loss时，需要将每个子标签的对应的损失求平均，因此需要将预测的概率值进行扩展</span></span><br><span class="line">        <span class="comment"># 对单个 single_mask_logits 进行扩展，使其在第一个维度上重复，以匹配 single_sub_mask_labels 的数量</span></span><br><span class="line">        <span class="comment"># 使用repeat设置重复的倍数 (sub_label_num, mask_label_num, vocab_size)</span></span><br><span class="line">        single_mask_logits = single_mask_logits.repeat(<span class="built_in">len</span>(single_sub_mask_labels), <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 打印重复后的single_mask_logits的形状，以便调试和验证重复操作的效果</span></span><br><span class="line">        <span class="comment"># print(f&#x27;重复后的single_mask_logits--&gt;&#123;single_mask_logits.shape&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将三维张量调整为二维，以便计算损失</span></span><br><span class="line">        single_mask_logits = single_mask_logits.reshape(-<span class="number">1</span>, vocab_size)  <span class="comment"># (sub_label_num * mask_label_num, vocab_size)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;调整成二维后的single_mask_logits--&gt;&#123;single_mask_logits.shape&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将子标签转换为张量，并调整形状以匹配模型预测的结果</span></span><br><span class="line">        single_sub_mask_labels = torch.LongTensor(single_sub_mask_labels).to(device)  <span class="comment"># (sub_label_num, mask_label_num)</span></span><br><span class="line">        <span class="comment"># 计算损失值时真实子标签维度为1维，因此需要将其展平以匹配模型预测的结果</span></span><br><span class="line">        single_sub_mask_labels = single_sub_mask_labels.reshape(-<span class="number">1</span>, <span class="number">1</span>).squeeze()  <span class="comment"># (sub_label_num * mask_label_num)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;真实子标签mask值：single_sub_mask_labels--&gt;&#123;single_sub_mask_labels.shape&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;真实子标签mask值：single_sub_mask_labels--&gt;&#123;single_sub_mask_labels&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算当前批次所有子标签的损失</span></span><br><span class="line">        cur_loss = cross_entropy_criterion(single_mask_logits, single_sub_mask_labels)</span><br><span class="line">        <span class="comment"># 计算当前批次所有子标签的平均损失</span></span><br><span class="line">        cur_loss = cur_loss / <span class="built_in">len</span>(single_sub_mask_labels)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果当前损失loss未被初始化（即为None），则将其设置为当前批次的损失cur_loss</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> loss:</span><br><span class="line">            loss = cur_loss</span><br><span class="line">        <span class="comment"># 如果当前损失loss已经存在，则将当前批次的损失cur_loss累加到loss中</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            loss += cur_loss</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算平均损失：将累计的损失loss除以批次大小batch_size</span></span><br><span class="line">    loss = loss / batch_size  <span class="comment"># (1,)</span></span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_logits_to_ids</span>(<span class="params"></span></span><br><span class="line"><span class="params">        logits: torch.tensor,</span></span><br><span class="line"><span class="params">        mask_positions: torch.tensor</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    输入Language Model的词表概率分布（LMModel的logits），将mask_position位置的token logits转换为token的id。</span></span><br><span class="line"><span class="string">    :param logits: (torch.tensor): model output -&gt; (batch, seq_len, vocab_size) [8, 512, 21128]</span></span><br><span class="line"><span class="string">    :param mask_positions: (torch.tensor): mask token的位置 -&gt; (batch, mask_label_num) [8, 2]</span></span><br><span class="line"><span class="string">    :return: 对应mask position上最大概率的推理token -&gt; (batch, mask_label_num) [8, 2]</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 获取标签的长度，mask_positions.size()返回的是一个包含维度的元组，[1]表示获取第二个维度的大小</span></span><br><span class="line">    label_length = mask_positions.size()[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># print(f&#x27;label_length--&gt;&#123;label_length&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取批次大小、序列长度和词汇表大小，logits.size()返回的是一个包含维度的元组</span></span><br><span class="line">    batch_size, seq_len, vocab_size = logits.size()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化一个空列表，用于存储重塑后的 mask_positions</span></span><br><span class="line">    mask_positions_after_reshaped = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># print(f&#x27;mask_positions.detach().cpu().numpy().tolist()--&gt;&#123;mask_positions.detach().cpu().numpy().tolist()&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># 遍历每个批次的mask_positions</span></span><br><span class="line">    <span class="keyword">for</span> batch, mask_pos <span class="keyword">in</span> <span class="built_in">enumerate</span>(mask_positions.detach().cpu().numpy().tolist()):</span><br><span class="line">        <span class="comment"># 遍历每个mask位置</span></span><br><span class="line">        <span class="keyword">for</span> pos <span class="keyword">in</span> mask_pos:</span><br><span class="line">            <span class="comment"># 将批次号和序列中的mask位置结合起来，得到重塑后的mask_positions</span></span><br><span class="line">            mask_positions_after_reshaped.append(batch * seq_len + pos)</span><br><span class="line">    <span class="comment"># print(f&#x27;mask_positions_after_reshaped--&gt;&#123;mask_positions_after_reshaped&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;原始的logits--&gt;&#123;logits.shape&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将原始的logits重塑为(batch_size * seq_len, vocab_size)的形状</span></span><br><span class="line">    logits = logits.reshape(batch_size * seq_len, -<span class="number">1</span>)  <span class="comment"># (batch_size * seq_len, vocab_size)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;改变原始模型输出的结果形状--&gt;&#123;logits.shape&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从重塑后的logits中，选择出被掩码位置的logits</span></span><br><span class="line">    mask_logits = logits[mask_positions_after_reshaped]</span><br><span class="line">    <span class="comment"># print(f&#x27;被掩码位置的logits--&gt;&#123;mask_logits.shape&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取每个样本mask位置所预测的tokens</span></span><br><span class="line">    predict_tokens = mask_logits.argmax(dim=-<span class="number">1</span>)  <span class="comment"># (batch * label_num)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;获取每个样本mask位置预测的tokens&#x27;, predict_tokens)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将每个样本mask位置预测的tokens重塑为(batch, label_num)的形状</span></span><br><span class="line">    predict_tokens = predict_tokens.reshape(-<span class="number">1</span>, label_length)  <span class="comment"># (batch, label_num)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;predict_tokens--&gt;&#123;predict_tokens&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> predict_tokens</span><br></pre></td></tr></table></figure>



<h4 id="1-3-metirc-utils-py-1"><a href="#1-3-metirc-utils-py-1" class="headerlink" title="1.3 metirc_utils.py"></a>1.3 metirc_utils.py</h4><ul>
<li>目的：定义（多）分类问题下的指标评估（acc, precision, recall, f1）。</li>
<li>代码如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, precision_score, f1_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> recall_score, confusion_matrix</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ClassEvaluator</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 初始化真实结果和预测结果的列表</span></span><br><span class="line">        self.goldens = []  <span class="comment"># 存储真实结果数据</span></span><br><span class="line">        self.predictions = []  <span class="comment"># 存储预测结果数据</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_batch</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                  pred_batch: <span class="type">List</span>[<span class="type">List</span>],</span></span><br><span class="line"><span class="params">                  gold_batch: <span class="type">List</span>[<span class="type">List</span>]</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        添加一个batch中的prediction和gold列表，用于后续统一计算。</span></span><br><span class="line"><span class="string">        :param pred_batch: (list): 模型预测标签列表, e.g. -&gt;  [[&#x27;体&#x27;, &#x27;育&#x27;], [&#x27;财&#x27;, &#x27;经&#x27;], ...]</span></span><br><span class="line"><span class="string">        :param gold_batch: (list): 真实标签标签列表, e.g. -&gt;  [[&#x27;体&#x27;, &#x27;育&#x27;], [&#x27;财&#x27;, &#x27;经&#x27;], ...]</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 确保预测批次和真实批次长度一致，这是后续处理的前提条件</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(pred_batch) == <span class="built_in">len</span>(gold_batch)</span><br><span class="line">        <span class="comment"># print(f&#x27;pred_batch0--&gt;&#123;pred_batch&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;gold_batch0--&gt;&#123;gold_batch&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 若遇到多个子标签构成一个标签的情况</span></span><br><span class="line">        <span class="comment"># 判断gold_batch的第一个元素是否为列表或元组类型</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(gold_batch[<span class="number">0</span>]) <span class="keyword">in</span> [<span class="built_in">list</span>, <span class="built_in">tuple</span>]:</span><br><span class="line">            <span class="comment"># 如果是，则将pred_batch中的每个元素转换为字符串后拼接起来</span></span><br><span class="line">            pred_batch = [<span class="string">&#x27;&#x27;</span>.join([<span class="built_in">str</span>(e) <span class="keyword">for</span> e <span class="keyword">in</span> ele]) <span class="keyword">for</span> ele <span class="keyword">in</span> pred_batch]</span><br><span class="line">            <span class="comment"># 同样地，也将gold_batch中的每个元素转换为字符串后拼接起来</span></span><br><span class="line">            gold_batch = [<span class="string">&#x27;&#x27;</span>.join([<span class="built_in">str</span>(e) <span class="keyword">for</span> e <span class="keyword">in</span> ele]) <span class="keyword">for</span> ele <span class="keyword">in</span> gold_batch]</span><br><span class="line">        <span class="comment"># print(f&#x27;pred_batch--&gt;&#123;pred_batch&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;gold_batch--&gt;&#123;gold_batch&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将真实结果的批次数据添加到self.goldens列表中</span></span><br><span class="line">        self.goldens.extend(gold_batch)</span><br><span class="line">        <span class="comment"># print(f&#x27;self.goldens--&gt;&#123;self.goldens&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 将预测结果的批次数据添加到self.predictions列表中</span></span><br><span class="line">        self.predictions.extend(pred_batch)</span><br><span class="line">        <span class="comment"># print(f&#x27;self.predictions--&gt;&#123;self.predictions&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compute</span>(<span class="params">self, round_num=<span class="number">2</span></span>) -&gt; <span class="built_in">dict</span>:</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        根据当前类中累积的变量值，计算当前的P, R, F1。</span></span><br><span class="line"><span class="string">        :param round_num: (int): 计算结果保留小数点后几位, 默认小数点后2位。</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        dict -&gt; &#123;</span></span><br><span class="line"><span class="string">            &#x27;accuracy&#x27;: 准确率,</span></span><br><span class="line"><span class="string">            &#x27;precision&#x27;: 精准率,</span></span><br><span class="line"><span class="string">            &#x27;recall&#x27;: 召回率,</span></span><br><span class="line"><span class="string">            &#x27;f1&#x27;: f1值,</span></span><br><span class="line"><span class="string">            &#x27;class_metrics&#x27;: &#123;</span></span><br><span class="line"><span class="string">                &#x27;0&#x27;: &#123;</span></span><br><span class="line"><span class="string">                        &#x27;precision&#x27;: 该类别下的precision,</span></span><br><span class="line"><span class="string">                        &#x27;recall&#x27;: 该类别下的recall,</span></span><br><span class="line"><span class="string">                        &#x27;f1&#x27;: 该类别下的f1</span></span><br><span class="line"><span class="string">                    &#125;,</span></span><br><span class="line"><span class="string">                ...</span></span><br><span class="line"><span class="string">            &#125;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># print(f&#x27;self.goldens--&gt;&#123;self.goldens&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;self.predictions--&gt;&#123;self.predictions&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 初始化类别集合、类别指标字典和结果字典，用于存储全局指标</span></span><br><span class="line">        <span class="comment"># 将 self.goldens 和 self.predictions 的集合合并，并进行排序，结果存储在变量 classes 中。</span></span><br><span class="line">        classes = <span class="built_in">sorted</span>(<span class="built_in">list</span>(<span class="built_in">set</span>(self.goldens) | <span class="built_in">set</span>(self.predictions)))</span><br><span class="line">        class_metrics = &#123;&#125;</span><br><span class="line">        res = &#123;&#125;</span><br><span class="line">        <span class="comment"># print(f&#x27;classes--&gt;&#123;classes&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 构建全局指标</span></span><br><span class="line">        <span class="comment"># 计算并存储全局准确率</span></span><br><span class="line">        res[<span class="string">&#x27;accuracy&#x27;</span>] = <span class="built_in">round</span>(accuracy_score(self.goldens, self.predictions), round_num)</span><br><span class="line">        <span class="comment"># 计算并存储全局精确率</span></span><br><span class="line">        res[<span class="string">&#x27;precision&#x27;</span>] = <span class="built_in">round</span>(precision_score(self.goldens, self.predictions, average=<span class="string">&#x27;weighted&#x27;</span>), round_num)</span><br><span class="line">        <span class="comment"># 计算并存储全局召回率</span></span><br><span class="line">        res[<span class="string">&#x27;recall&#x27;</span>] = <span class="built_in">round</span>(recall_score(self.goldens, self.predictions, average=<span class="string">&#x27;weighted&#x27;</span>), round_num)</span><br><span class="line">        <span class="comment"># 计算并存储全局F1分数</span></span><br><span class="line">        res[<span class="string">&#x27;f1&#x27;</span>] = <span class="built_in">round</span>(f1_score(self.goldens, self.predictions, average=<span class="string">&#x27;weighted&#x27;</span>), round_num)</span><br><span class="line">        <span class="comment"># print(f&#x27;res--&gt;&#123;res&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># 计算混淆矩阵，并将其转换为numpy数组，形状为(n_class, n_class)</span></span><br><span class="line">            conf_matrix = np.array(confusion_matrix(self.goldens, self.predictions))</span><br><span class="line">            <span class="comment"># print(f&#x27;conf_matrix--&gt;&#123;conf_matrix&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># 确保混淆矩阵的维度与类别数量匹配</span></span><br><span class="line">            <span class="keyword">assert</span> conf_matrix.shape[<span class="number">0</span>] == <span class="built_in">len</span>(classes)</span><br><span class="line">            <span class="comment"># 遍历每个类别，计算精确度(precision)、召回率(recall)和F1分数(f1)</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(conf_matrix.shape[<span class="number">0</span>]):</span><br><span class="line">                <span class="comment"># 计算当前类别的精确度</span></span><br><span class="line">                precision = <span class="number">0</span> <span class="keyword">if</span> <span class="built_in">sum</span>(conf_matrix[:, i]) == <span class="number">0</span> <span class="keyword">else</span> (conf_matrix[i, i] / <span class="built_in">sum</span>(conf_matrix[:, i]))</span><br><span class="line">                <span class="comment"># 计算当前类别的召回率</span></span><br><span class="line">                recall = <span class="number">0</span> <span class="keyword">if</span> <span class="built_in">sum</span>(conf_matrix[i, :]) == <span class="number">0</span> <span class="keyword">else</span> (conf_matrix[i, i] / <span class="built_in">sum</span>(conf_matrix[i, :]))</span><br><span class="line">                <span class="comment"># 计算当前类别的F1分数</span></span><br><span class="line">                f1 = <span class="number">0</span> <span class="keyword">if</span> (precision + recall) == <span class="number">0</span> <span class="keyword">else</span> (<span class="number">2</span> * precision * recall / (precision + recall))</span><br><span class="line">                <span class="comment"># 将当前类别的精确度、召回率和F1分数保存到字典中</span></span><br><span class="line">                class_metrics[classes[i]] = &#123;</span><br><span class="line">                    <span class="string">&#x27;precision&#x27;</span>: <span class="built_in">round</span>(precision, round_num),</span><br><span class="line">                    <span class="string">&#x27;recall&#x27;</span>: <span class="built_in">round</span>(recall, round_num),</span><br><span class="line">                    <span class="string">&#x27;f1&#x27;</span>: <span class="built_in">round</span>(f1, round_num)</span><br><span class="line">                &#125;</span><br><span class="line">            <span class="comment"># 将所有类别的指标保存到结果字典中</span></span><br><span class="line">            res[<span class="string">&#x27;class_metrics&#x27;</span>] = class_metrics</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="comment"># 异常处理：当计算类别指标时发生异常，打印警告信息和相关数据</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;[Warning] Something wrong when calculate class_metrics: <span class="subst">&#123;e&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;--&gt; goldens: <span class="subst">&#123;<span class="built_in">set</span>(self.goldens)&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;--&gt; predictions: <span class="subst">&#123;<span class="built_in">set</span>(self.predictions)&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;--&gt; diff elements: <span class="subst">&#123;<span class="built_in">set</span>(self.predictions) - <span class="built_in">set</span>(self.goldens)&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="comment"># 将结果字典中的类别指标设置为空字典</span></span><br><span class="line">            res[<span class="string">&#x27;class_metrics&#x27;</span>] = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">		重置积累的数值。</span></span><br><span class="line"><span class="string">		&quot;&quot;&quot;</span></span><br><span class="line">        self.goldens = []</span><br><span class="line">        self.predictions = []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    metric = ClassEvaluator()</span><br><span class="line">    metric.add_batch(</span><br><span class="line">        [[<span class="string">&#x27;财&#x27;</span>, <span class="string">&#x27;经&#x27;</span>], [<span class="string">&#x27;财&#x27;</span>, <span class="string">&#x27;经&#x27;</span>], [<span class="string">&#x27;体&#x27;</span>, <span class="string">&#x27;育&#x27;</span>], [<span class="string">&#x27;体&#x27;</span>, <span class="string">&#x27;育&#x27;</span>], [<span class="string">&#x27;计&#x27;</span>, <span class="string">&#x27;算&#x27;</span>, <span class="string">&#x27;机&#x27;</span>]],</span><br><span class="line">        [[<span class="string">&#x27;体&#x27;</span>, <span class="string">&#x27;育&#x27;</span>], [<span class="string">&#x27;财&#x27;</span>, <span class="string">&#x27;经&#x27;</span>], [<span class="string">&#x27;体&#x27;</span>, <span class="string">&#x27;育&#x27;</span>], [<span class="string">&#x27;计&#x27;</span>, <span class="string">&#x27;算&#x27;</span>, <span class="string">&#x27;机&#x27;</span>], [<span class="string">&#x27;计&#x27;</span>, <span class="string">&#x27;算&#x27;</span>, <span class="string">&#x27;机&#x27;</span>]],</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># metric.add_batch(</span></span><br><span class="line">    <span class="comment">#     [0, 0, 1, 1, 0],</span></span><br><span class="line">    <span class="comment">#     [1, 1, 1, 0, 0]</span></span><br><span class="line">    <span class="comment"># )</span></span><br><span class="line">    res = metric.compute()</span><br><span class="line">    <span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>print代码结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;accuracy&#x27;</span>: <span class="number">0.6</span>, </span><br><span class="line"><span class="string">&#x27;precision&#x27;</span>: <span class="number">0.7</span>, </span><br><span class="line"><span class="string">&#x27;recall&#x27;</span>: <span class="number">0.6</span>, </span><br><span class="line"><span class="string">&#x27;f1&#x27;</span>: <span class="number">0.6</span>, </span><br><span class="line"><span class="string">&#x27;class_metrics&#x27;</span>: </span><br><span class="line">&#123;<span class="string">&#x27;体育&#x27;</span>: &#123;<span class="string">&#x27;precision&#x27;</span>: np.float64(<span class="number">0.5</span>), <span class="string">&#x27;recall&#x27;</span>: np.float64(<span class="number">0.5</span>), <span class="string">&#x27;f1&#x27;</span>: np.float64(<span class="number">0.5</span>)&#125;, </span><br><span class="line"><span class="string">&#x27;计算机&#x27;</span>: &#123;<span class="string">&#x27;precision&#x27;</span>: np.float64(<span class="number">1.0</span>), <span class="string">&#x27;recall&#x27;</span>: np.float64(<span class="number">0.5</span>), <span class="string">&#x27;f1&#x27;</span>: np.float64(<span class="number">0.67</span>)&#125;, </span><br><span class="line"><span class="string">&#x27;财经&#x27;</span>: &#123;<span class="string">&#x27;precision&#x27;</span>: np.float64(<span class="number">0.5</span>), <span class="string">&#x27;recall&#x27;</span>: np.float64(<span class="number">1.0</span>), <span class="string">&#x27;f1&#x27;</span>: np.float64(<span class="number">0.67</span>)&#125;</span><br><span class="line">&#125;&#125;</span><br></pre></td></tr></table></figure></blockquote>
<h3 id="2、实现模型训练函数-验证函数-1"><a href="#2、实现模型训练函数-验证函数-1" class="headerlink" title="2、实现模型训练函数,验证函数"></a>2、实现模型训练函数,验证函数</h3><ul>
<li><p>目的：实现模型的训练和验证，脚本里面包含两个函数：model2train()和evaluate_model()</p>
</li>
<li><p>代码路径：llm_tuning&#x2F;prompt_tasks&#x2F;P_Tuning&#x2F;train.py</p>
<p>代码如下：</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForMaskedLM, AutoTokenizer, get_scheduler</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.data_handle.data_loader <span class="keyword">import</span> get_data</span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.pet_config <span class="keyword">import</span> ProjectConfig</span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.utils.common_utils <span class="keyword">import</span> mlm_loss, convert_logits_to_ids</span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.utils.metirc_utils <span class="keyword">import</span> ClassEvaluator</span><br><span class="line"><span class="keyword">from</span> prompt_tasks.PET.utils.verbalizer <span class="keyword">import</span> Verbalizer</span><br><span class="line"></span><br><span class="line">pc = ProjectConfig()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">model2train</span>():</span><br><span class="line">    <span class="comment"># 加载训练数据和验证数据</span></span><br><span class="line">    train_dataloader, dev_dataloader = get_data()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载预训练模型</span></span><br><span class="line">    model = AutoModelForMaskedLM.from_pretrained(pc.pre_model).to(pc.device)</span><br><span class="line">    <span class="comment"># print(f&#x27;预训练模型带MLM头的--&gt;&#123;model&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># 加载分词器</span></span><br><span class="line">    tokenizer = AutoTokenizer.from_pretrained(pc.pre_model)</span><br><span class="line">    <span class="comment"># 加载映射词表</span></span><br><span class="line">    verbalizer = Verbalizer(verbalizer_file=pc.verbalizer,</span><br><span class="line">                            tokenizer=tokenizer,</span><br><span class="line">                            max_label_len=pc.max_label_len)</span><br><span class="line">    <span class="comment"># print(f&#x27;verbalizer--&gt;&#123;verbalizer.label_dict&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 不需要权重衰减的参数</span></span><br><span class="line">    no_decay = [<span class="string">&quot;bias&quot;</span>, <span class="string">&quot;LayerNorm.weight&quot;</span>]</span><br><span class="line">    <span class="comment"># print(type(model.parameters()))</span></span><br><span class="line">    <span class="comment"># 定义优化器的参数组，以便对模型的不同部分应用不同的权重衰减</span></span><br><span class="line">    optimizer_grouped_parameters = [</span><br><span class="line">        <span class="comment"># 第一组参数：包含所有适用权重衰减的模型参数</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;params&quot;</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> model.named_parameters() <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">any</span>(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)],</span><br><span class="line">            <span class="string">&quot;weight_decay&quot;</span>: pc.weight_decay,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="comment"># 第二组参数：包含所有不适用权重衰减的模型参数</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;params&quot;</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> model.named_parameters() <span class="keyword">if</span> <span class="built_in">any</span>(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)],</span><br><span class="line">            <span class="string">&quot;weight_decay&quot;</span>: <span class="number">0.0</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">    ]</span><br><span class="line">    <span class="comment"># 初始化AdamW优化器，用于模型参数的优化</span></span><br><span class="line">    <span class="comment"># AdamW是Adam算法的变体，加入了权重衰减（L2正则化），有助于防止过拟合</span></span><br><span class="line">    <span class="comment"># 参数optimizer_grouped_parameters是分组的模型参数，允许对不同的参数应用不同的学习率或正则化强度</span></span><br><span class="line">    optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=pc.learning_rate)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据训练轮数计算最大训练步数，以便于scheduler动态调整lr</span></span><br><span class="line">    num_update_steps_per_epoch = <span class="built_in">len</span>(train_dataloader)</span><br><span class="line">    <span class="comment"># 指定总的训练步数，它会被学习率调度器用来确定学习率的变化规律，确保学习率在整个训练过程中得以合理地调节</span></span><br><span class="line">    max_train_steps = pc.epochs * num_update_steps_per_epoch</span><br><span class="line">    <span class="comment"># 计算预热阶段的训练步数，用于初始化学习率调度</span></span><br><span class="line">    warm_steps = <span class="built_in">int</span>(pc.warmup_ratio * max_train_steps)  <span class="comment"># 预热阶段的训练步数</span></span><br><span class="line">    <span class="comment"># 创建学习率调度器，使用线性调度策略，根据训练的进行逐步调整学习率</span></span><br><span class="line">    lr_scheduler = get_scheduler(</span><br><span class="line">        name=<span class="string">&#x27;linear&#x27;</span>,</span><br><span class="line">        optimizer=optimizer,</span><br><span class="line">        num_warmup_steps=warm_steps,</span><br><span class="line">        num_training_steps=max_train_steps)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化损失列表，用于记录训练过程中的损失值</span></span><br><span class="line">    loss_list = []</span><br><span class="line">    <span class="comment"># 记录训练开始的时间，用于计算训练时长</span></span><br><span class="line">    tic_train = time.time()</span><br><span class="line">    <span class="comment"># 创建分类评估器，用于评估模型性能</span></span><br><span class="line">    metric = ClassEvaluator()</span><br><span class="line">    <span class="comment"># 定义损失函数，用于计算模型预测值与真实标签之间的差异</span></span><br><span class="line">    criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">    <span class="comment"># 初始化训练次数和最佳F1分数，用于跟踪训练进度和模型性能</span></span><br><span class="line">    global_step, best_f1 = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;开始训练：&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(pc.epochs):</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> tqdm(train_dataloader, desc=<span class="string">&#x27;模型训练&#x27;</span>):</span><br><span class="line">            <span class="comment"># print(f&#x27;batch--&gt;&#123;batch&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># 将批次数据输入模型，获取logits</span></span><br><span class="line">            logits = model(input_ids=batch[<span class="string">&#x27;input_ids&#x27;</span>].to(pc.device),</span><br><span class="line">                           token_type_ids=batch[<span class="string">&#x27;token_type_ids&#x27;</span>].to(pc.device),</span><br><span class="line">                           attention_mask=batch[<span class="string">&#x27;attention_mask&#x27;</span>].to(pc.device)).logits</span><br><span class="line">            <span class="comment"># print(f&#x27;logits-&gt;&#123;logits.shape&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 真实标签</span></span><br><span class="line">            mask_labels = batch[<span class="string">&#x27;mask_labels&#x27;</span>].numpy().tolist()</span><br><span class="line">            <span class="comment"># print(f&#x27;mask_labels---&gt;&#123;mask_labels&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># 提取子标签</span></span><br><span class="line">            sub_labels = verbalizer.batch_find_sub_labels(mask_labels)</span><br><span class="line">            <span class="comment"># print(f&#x27;sub_labels---&gt;&#123;sub_labels&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># 获取子标签的token_ids</span></span><br><span class="line">            sub_labels = [ele[<span class="string">&#x27;token_ids&#x27;</span>] <span class="keyword">for</span> ele <span class="keyword">in</span> sub_labels]</span><br><span class="line">            <span class="comment"># print(f&#x27;sub_labels_token_ids---&gt;&#123;sub_labels&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 计算掩码语言模型的损失值</span></span><br><span class="line">            loss = mlm_loss(logits,</span><br><span class="line">                            batch[<span class="string">&#x27;mask_positions&#x27;</span>].to(pc.device),</span><br><span class="line">                            sub_labels,</span><br><span class="line">                            criterion,</span><br><span class="line">                            pc.device)</span><br><span class="line">            <span class="comment"># print(f&#x27;计算损失值--&gt;&#123;loss&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># 清零优化器的梯度</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            <span class="comment"># 反向传播计算梯度</span></span><br><span class="line">            loss.backward()</span><br><span class="line">            <span class="comment"># 更新模型参数</span></span><br><span class="line">            optimizer.step()</span><br><span class="line">            <span class="comment"># 更新学习率调度器</span></span><br><span class="line">            lr_scheduler.step()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 将损失值添加到损失列表中</span></span><br><span class="line">            loss_list.append(loss)</span><br><span class="line">            <span class="comment"># 训练次数增加1</span></span><br><span class="line">            global_step += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 打印训练日志</span></span><br><span class="line">            <span class="keyword">if</span> global_step % pc.logging_steps == <span class="number">0</span>:</span><br><span class="line">                time_diff = time.time() - tic_train</span><br><span class="line">                loss_avg = <span class="built_in">sum</span>(loss_list) / <span class="built_in">len</span>(loss_list)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;global step %d, epoch: %d, loss: %.5f, speed: %.2f step/s&quot;</span></span><br><span class="line">                      % (global_step, epoch, loss_avg, pc.logging_steps / time_diff))</span><br><span class="line">                tic_train = time.time()</span><br><span class="line">        <span class="comment"># 模型验证</span></span><br><span class="line">        <span class="comment"># 使用给定的模型、评估指标、数据加载器、分词器和标记化器进行模型评估</span></span><br><span class="line">        acc, precision, recall, f1, class_metrics = evaluate_model(model,</span><br><span class="line">                                                                   metric,</span><br><span class="line">                                                                   dev_dataloader,</span><br><span class="line">                                                                   tokenizer,</span><br><span class="line">                                                                   verbalizer)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打印评估结果中的精确度、召回率和F1分数</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;验证集的 precision: %.5f, recall: %.5f, F1: %.5f&quot;</span> % (precision, recall, f1))</span><br><span class="line">        <span class="comment"># 如果当前F1分数高于最佳F1分数，则更新最佳F1分数和相关模型及分词器</span></span><br><span class="line">        <span class="keyword">if</span> f1 &gt; best_f1:</span><br><span class="line">            <span class="built_in">print</span>(</span><br><span class="line">                <span class="string">f&quot;最好的f1分数被更新: <span class="subst">&#123;best_f1:<span class="number">.5</span>f&#125;</span> --&gt; <span class="subst">&#123;f1:<span class="number">.5</span>f&#125;</span>&quot;</span></span><br><span class="line">            )</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;每种类型的Metrics为: <span class="subst">&#123;class_metrics&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="comment"># 更新当前最佳的F1分数</span></span><br><span class="line">            best_f1 = f1</span><br><span class="line">            <span class="comment"># 定义当前保存模型和分词器的目录</span></span><br><span class="line">            cur_save_dir = os.path.join(pc.save_dir, <span class="string">&quot;model_best&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(cur_save_dir)</span><br><span class="line">            <span class="comment"># 检查并创建保存目录（如果不存在）</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(cur_save_dir):</span><br><span class="line">                os.makedirs(cur_save_dir)</span><br><span class="line">            <span class="comment"># 保存模型到指定目录</span></span><br><span class="line">            model.save_pretrained(cur_save_dir)</span><br><span class="line">            <span class="comment"># 保存分词器到指定目录</span></span><br><span class="line">            tokenizer.save_pretrained(cur_save_dir)</span><br><span class="line">        tic_train = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;训练结束&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate_model</span>(<span class="params">model,</span></span><br><span class="line"><span class="params">                   metric,</span></span><br><span class="line"><span class="params">                   data_loader,</span></span><br><span class="line"><span class="params">                   tokenizer,</span></span><br><span class="line"><span class="params">                   verbalizer</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    在测试集上评估当前模型的训练效果。</span></span><br><span class="line"><span class="string">    :param model: 当前模型</span></span><br><span class="line"><span class="string">    :param metric: 评估指标类(metric)</span></span><br><span class="line"><span class="string">    :param data_loader: 测试集的dataloader</span></span><br><span class="line"><span class="string">    :param tokenizer: 分词器</span></span><br><span class="line"><span class="string">    :param verbalizer: 映射表</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    metric.reset()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> step, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(data_loader, desc=<span class="string">&#x27;模型验证&#x27;</span>)):</span><br><span class="line">            <span class="comment"># print(f&#x27;batch--&gt;&#123;batch&#125;&#x27;)</span></span><br><span class="line">            logits = model(input_ids=batch[<span class="string">&#x27;input_ids&#x27;</span>].to(pc.device),</span><br><span class="line">                           token_type_ids=batch[<span class="string">&#x27;token_type_ids&#x27;</span>].to(pc.device),</span><br><span class="line">                           attention_mask=batch[<span class="string">&#x27;attention_mask&#x27;</span>].to(pc.device)).logits</span><br><span class="line">            <span class="comment"># print(f&#x27;验证集模型预测的结果————&gt;&#123;logits.shape&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">            mask_labels = batch[<span class="string">&#x27;mask_labels&#x27;</span>].numpy().tolist()  <span class="comment"># (batch, label_num)</span></span><br><span class="line">            <span class="comment"># print(f&quot;mask_labels-0--&gt;&#123;mask_labels&#125;&quot;)</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(mask_labels)):  <span class="comment"># 去掉label中的[PAD] token</span></span><br><span class="line">                <span class="keyword">while</span> tokenizer.pad_token_id <span class="keyword">in</span> mask_labels[i]:</span><br><span class="line">                    mask_labels[i].remove(tokenizer.pad_token_id)</span><br><span class="line">            <span class="comment"># print(f&#x27;mask_labels-1--&gt;&#123;mask_labels&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># 将mask_labels id转换为文字</span></span><br><span class="line">            mask_labels = [<span class="string">&#x27;&#x27;</span>.join(tokenizer.convert_ids_to_tokens(t)) <span class="keyword">for</span> t <span class="keyword">in</span> mask_labels]</span><br><span class="line">            <span class="comment"># print(f&#x27;真实的结果主标签：mask_labels_str--&gt;&#123;mask_labels&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 获取模型预测的子标签</span></span><br><span class="line">            predictions = convert_logits_to_ids(logits,</span><br><span class="line">                                                batch[<span class="string">&#x27;mask_positions&#x27;</span>]).cpu().numpy().tolist()  <span class="comment"># (batch, label_num)</span></span><br><span class="line">            <span class="comment"># print(f&#x27;模型预测的子标签的结果--&gt;&#123;predictions&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 根据模型预测的子标签，找到子label属于的主label</span></span><br><span class="line">            predictions = verbalizer.batch_find_main_label(predictions)  <span class="comment"># 找到子label属于的主label</span></span><br><span class="line">            <span class="comment"># print(f&quot;找到模型预测的子标签对应的主标签的结果--&gt;&#123;predictions&#125;&#x27;)&quot;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 获得预测的主标签名</span></span><br><span class="line">            predictions = [ele[<span class="string">&#x27;label&#x27;</span>] <span class="keyword">for</span> ele <span class="keyword">in</span> predictions]</span><br><span class="line">            <span class="comment"># print(f&quot;只获得预测的主标签的结果string--&gt;&#123;predictions&#125;&#x27;)&quot;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 调用add_batch方法, 将模型预测的主标签与真实主标签保存到metric属性中</span></span><br><span class="line">            metric.add_batch(pred_batch=predictions, gold_batch=mask_labels)</span><br><span class="line">    eval_metric = metric.compute()</span><br><span class="line">    model.train()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> eval_metric[<span class="string">&#x27;accuracy&#x27;</span>], eval_metric[<span class="string">&#x27;precision&#x27;</span>], \</span><br><span class="line">        eval_metric[<span class="string">&#x27;recall&#x27;</span>], eval_metric[<span class="string">&#x27;f1&#x27;</span>], \</span><br><span class="line">        eval_metric[<span class="string">&#x27;class_metrics&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    model2train()</span><br></pre></td></tr></table></figure>



<ul>
<li>输出结果:</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="keyword">global</span> step <span class="number">350</span>, epoch: <span class="number">43</span>, loss: <span class="number">0.10804</span>, speed: <span class="number">1.20</span> step/s</span><br><span class="line"><span class="keyword">global</span> step <span class="number">360</span>, epoch: <span class="number">44</span>, loss: <span class="number">0.10504</span>, speed: <span class="number">1.22</span> step/s</span><br><span class="line"><span class="keyword">global</span> step <span class="number">370</span>, epoch: <span class="number">46</span>, loss: <span class="number">0.10220</span>, speed: <span class="number">1.21</span> step/s</span><br><span class="line"><span class="keyword">global</span> step <span class="number">380</span>, epoch: <span class="number">47</span>, loss: <span class="number">0.09951</span>, speed: <span class="number">1.20</span> step/s</span><br><span class="line"><span class="keyword">global</span> step <span class="number">390</span>, epoch: <span class="number">48</span>, loss: <span class="number">0.09696</span>, speed: <span class="number">1.20</span> step/s</span><br><span class="line"><span class="keyword">global</span> step <span class="number">400</span>, epoch: <span class="number">49</span>, loss: <span class="number">0.09454</span>, speed: <span class="number">1.22</span> step/s</span><br><span class="line">Evaluation precision: <span class="number">0.76000</span>, recall: <span class="number">0.70000</span>, F1: <span class="number">0.70000</span></span><br></pre></td></tr></table></figure>

<hr>
<blockquote>
<ul>
<li>结论: BERT+P-Tuning模型在训练集上的表现是Precion: 76%</li>
<li>注意：本项目中只用了60条样本，在接近400条样本上精确率就已经达到了76%，如果想让指标更高，可以扩增样本。</li>
</ul>
</blockquote>
<p>提升模型性能：</p>
<p>增加训练数据集（100条左右的数据）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">手机	外观时尚新潮，适合年轻人展现个性。</span><br><span class="line">手机	屏幕显示效果非常出色，观看视频和浏览网页很舒适。</span><br><span class="line">电脑	使用了一段时间的这款电脑，硬盘采用WD，运行流畅无卡顿，温度控制较好，性价比令人满意。</span><br><span class="line">手机	手机反应灵敏，操作界面简洁易用，非常满意。</span><br><span class="line">电器	产品性能稳定，很不错哦！购买时有点担心，但收到货后发现是正品，大家可以放心购买。</span><br></pre></td></tr></table></figure>

<p>修改验证集脏数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 原始标签和评论文本内容不符</span></span><br><span class="line">平板	手机很好，就是客服垃圾特别是元豆</span><br><span class="line"><span class="comment"># 修改后</span></span><br><span class="line">手机	手机很好，就是客服垃圾特别是元豆</span><br></pre></td></tr></table></figure>

<blockquote>
<p>模型表现：</p>
<p>Evaluation precision: 0.79000, recall: 0.70000, F1: 0.71000</p>
</blockquote>
<h3 id="3、实现模型预测函数-1"><a href="#3、实现模型预测函数-1" class="headerlink" title="3、实现模型预测函数"></a>3、实现模型预测函数</h3><ul>
<li>目的：加载训练好的模型并测试效果</li>
<li>代码路径：llm_tuning&#x2F;prompt_tasks&#x2F;P_Tuning&#x2F;inference.py</li>
</ul>
<p>​		代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForMaskedLM</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> prompt_tasks.P_Tuning.data_handle.data_preprocess <span class="keyword">import</span> convert_example</span><br><span class="line"><span class="keyword">from</span> prompt_tasks.P_Tuning.ptune_config <span class="keyword">import</span> ProjectConfig</span><br><span class="line"><span class="keyword">from</span> prompt_tasks.P_Tuning.utils.common_utils <span class="keyword">import</span> convert_logits_to_ids</span><br><span class="line"><span class="keyword">from</span> prompt_tasks.P_Tuning.utils.verbalizer <span class="keyword">import</span> Verbalizer</span><br><span class="line"></span><br><span class="line">pc = ProjectConfig()</span><br><span class="line"></span><br><span class="line">model_path = os.path.join(pc.save_dir, <span class="string">&#x27;model_best&#x27;</span>)</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_path)</span><br><span class="line">model = AutoModelForMaskedLM.from_pretrained(model_path).to(pc.device)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">max_label_len = <span class="number">2</span>  <span class="comment"># 标签最大长度</span></span><br><span class="line">p_embedding_num = <span class="number">6</span></span><br><span class="line">verbalizer = Verbalizer(</span><br><span class="line">    verbalizer_file=pc.verbalizer,</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    max_label_len=max_label_len)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">inference</span>(<span class="params">contents: <span class="type">List</span>[<span class="built_in">str</span>]</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    推理函数，输入原始句子，输出mask label的预测值。</span></span><br><span class="line"><span class="string">    :param contents:</span></span><br><span class="line"><span class="string">    :return: 描原始句子列表。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> (torch.no_grad()):</span><br><span class="line">        start_time = time.time()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将内容封装为示例字典，准备进行标记化处理</span></span><br><span class="line">        examples = &#123;<span class="string">&#x27;text&#x27;</span>: contents&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对示例进行标记化处理，返回标记化输出</span></span><br><span class="line">        tokenized_output = convert_example(</span><br><span class="line">            examples,</span><br><span class="line">            tokenizer,</span><br><span class="line">            max_seq_len=<span class="number">128</span>,</span><br><span class="line">            max_label_len=max_label_len,</span><br><span class="line">            p_embedding_num=p_embedding_num,</span><br><span class="line">            train_mode=<span class="literal">False</span>,</span><br><span class="line">            return_tensor=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 使用模型进行预测，获取logits</span></span><br><span class="line">        logits = model(input_ids=tokenized_output[<span class="string">&#x27;input_ids&#x27;</span>].to(pc.device),</span><br><span class="line">                       token_type_ids=tokenized_output[<span class="string">&#x27;token_type_ids&#x27;</span>].to(pc.device),</span><br><span class="line">                       attention_mask=tokenized_output[<span class="string">&#x27;attention_mask&#x27;</span>].to(pc.device)).logits</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将logits转换为预测标签</span></span><br><span class="line">        predictions = convert_logits_to_ids(logits, tokenized_output[<span class="string">&#x27;mask_positions&#x27;</span>]</span><br><span class="line">                                            ).cpu().numpy().tolist()  <span class="comment"># (batch, label_num)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 找到子label属于的主label</span></span><br><span class="line">        predictions = verbalizer.batch_find_main_label(predictions)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取预测的标签</span></span><br><span class="line">        predictions = [ele[<span class="string">&#x27;label&#x27;</span>] <span class="keyword">for</span> ele <span class="keyword">in</span> predictions]</span><br><span class="line"></span><br><span class="line">        used = time.time() - start_time</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;耗时 <span class="subst">&#123;used&#125;</span> 秒。&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> predictions</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    contents = [</span><br><span class="line">        <span class="string">&#x27;天台很好看，躺在躺椅上很悠闲，因为活动所以我觉得性价比还不错，适合一家出行，特别是去迪士尼也蛮近的，下次有机会肯定还会再来的，值得推荐&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;环境，设施，很棒，周边配套设施齐全，前台小姐姐超级漂亮！酒店很赞，早餐不错，服务态度很好，前台美眉很漂亮。性价比超高的一家酒店。强烈推荐&#x27;</span>,</span><br><span class="line">        <span class="string">&quot;物流超快，隔天就到了，还没用，屯着出游的时候用的，听方便的，占地小&quot;</span>,</span><br><span class="line">        <span class="string">&quot;福行市来到无早集市，因为是喜欢的面包店，所以跑来集市看看。第一眼就看到了，之前在微店买了小刘，这次买了老刘，还有一直喜欢的巧克力磅蛋糕。好奇老板为啥不做柠檬磅蛋糕了，微店一直都是买不到的状态。因为不爱碱水硬欧之类的，所以期待老板多来点其他小点，饼干一直也是大爱，那天好像也没看到&quot;</span>,</span><br><span class="line">        <span class="string">&quot;服务很用心，房型也很舒服，小朋友很喜欢，下次去嘉定还会再选择。床铺柔软舒适，晚上休息很安逸，隔音效果不错赞，下次还会来&quot;</span></span><br><span class="line">    ]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;针对下面的文本评论，请分别给出对应所属类别：&quot;</span>)</span><br><span class="line">    res = inference(contents)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;推断的类别为：&#x27;</span>, res)</span><br><span class="line">    new_dict = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(contents)):</span><br><span class="line">        new_dict[contents[i]] = res[i]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;new_dict--&gt;<span class="subst">&#123;new_dict&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>结果展示</li>
</ul>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&#123;</span></span><br><span class="line">    <span class="attr">&#x27;天台很好看，躺在躺椅上很悠闲，因为活动所以我觉得性价比还不错，适合一家出</span></span><br><span class="line"><span class="attr">行，特别是去迪士尼也蛮近的，下次有机会肯定还会再来的，值得推荐&#x27;</span>: <span class="string">&#x27;酒店&#x27;,</span></span><br><span class="line">    <span class="attr">&#x27;环境，设施，很棒，周边配套设施齐全，前台小姐姐超级漂亮！酒店很赞，早餐不</span></span><br><span class="line"><span class="attr">错，服务态度很好，前台美眉很漂亮。性价比超高的一家酒店。强烈推荐&#x27;</span>: <span class="string">&#x27;酒店&#x27;,</span></span><br><span class="line">    <span class="attr">&#x27;物流超快，隔天就到了，还没用，屯着出游的时候用的，听方便的，占地小&#x27;</span>: <span class="string">&#x27;衣服&#x27;,</span></span><br><span class="line">    <span class="attr">&#x27;福行市来到无早集市，因为是喜欢的面包店，所以跑来集市看看。第一眼就看到了</span></span><br><span class="line"><span class="attr">，之前在微店买了小刘，这次买了老刘，还有一直喜欢的巧克力磅蛋糕。好奇老板为啥不做</span></span><br><span class="line"><span class="attr">柠檬磅蛋糕了，微店一直都是买不到的状态。因为不爱碱水硬欧之类的，所以期待老板多来</span></span><br><span class="line"><span class="attr">点其他小点，饼干一直也是大爱，那天好像也没看到&#x27;</span>: <span class="string">&#x27;平板&#x27;,</span></span><br><span class="line">    <span class="attr">&#x27;服务很用心，房型也很舒服，小朋友很喜欢，下次去嘉定还会再选择。床铺柔软舒</span></span><br><span class="line"><span class="attr">适，晚上休息很安逸，隔音效果不错赞，下次还会来&#x27;</span>: <span class="string">&#x27;酒店&#x27;</span></span><br><span class="line"><span class="attr">&#125;</span></span><br></pre></td></tr></table></figure>

<h1 id="P04-基于ChatGLM微调多任务实战"><a href="#P04-基于ChatGLM微调多任务实战" class="headerlink" title="P04_基于ChatGLM微调多任务实战"></a>P04_基于ChatGLM微调多任务实战</h1><h2 id="1-项目介绍【理解】"><a href="#1-项目介绍【理解】" class="headerlink" title="1. 项目介绍【理解】"></a>1. 项目介绍【理解】</h2><hr>
<h3 id="1-1-项目简介"><a href="#1-1-项目简介" class="headerlink" title="1.1. 项目简介"></a>1.1. 项目简介</h3><p>LLM（Large Language Model）通常拥有大量的先验知识，使得其在许多自然语言处理任务上都有着不错的性能。但，想要直接利用 LLM 完成一些任务会存在一些答案解析上的困难，如规范化输出格式，严格服从输入信息等。因此，在这个项目中我们对大模型 <a target="_blank" rel="noopener" href="https://github.com/THUDM/ChatGLM-6B">ChatGLM-6B</a> 进行 Finetune，使其能够更好的对齐我们所需要的输出格式。</p>
<h3 id="1-2-ChatGLM-6B模型"><a href="#1-2-ChatGLM-6B模型" class="headerlink" title="1.2. ChatGLM-6B模型"></a>1.2. ChatGLM-6B模型</h3><h4 id="1-2-1-模型介绍"><a href="#1-2-1-模型介绍" class="headerlink" title="1.2.1 模型介绍"></a>1.2.1 模型介绍</h4><p>ChatGLM-6B 是清华大学提出的一个开源、支持中英双语的对话语言模型，基于 General Language Model (GLM) 架构，具有 62 亿参数。该模型使用了和 ChatGPT 相似的技术，经过约 1T 标识符的中英双语训练(中英文比例为 1:1)，辅以监督微调、反馈自助、人类反馈强化学习等技术的加持，62 亿参数的 ChatGLM-6B 已经能生成相当符合人类偏好的回答（目前中文支持最好）。</p>
<p>相比原始Decoder模块，ChatGLM-6B模型结构有如下改动点：</p>
<ul>
<li><strong>embedding 层梯度缩减</strong>：为了提升训练稳定性，减小了 embedding 层的梯度。梯度缩减的效果相当于把 embedding 层的梯度缩小了 10 倍，减小了梯度的范数。</li>
<li><strong>layer normalization</strong>：采用了基于 Deep Norm 的 post layer norm。</li>
<li><strong>激活函数</strong>：替换ReLU激活函数采用了 GeGLU 激活函数。</li>
<li><strong>位置编码</strong>：去除了绝对位置编码，采用了旋转位置编码 RoPE。</li>
</ul>
<h4 id="1-2-2-模型配置-6B"><a href="#1-2-2-模型配置-6B" class="headerlink" title="1.2.2 模型配置(6B)"></a>1.2.2 模型配置(6B)</h4><table>
<thead>
<tr>
<th align="center">配置</th>
<th align="center">数据</th>
</tr>
</thead>
<tbody><tr>
<td align="center">参数</td>
<td align="center">6.2B</td>
</tr>
<tr>
<td align="center">隐藏层维度</td>
<td align="center">4096</td>
</tr>
<tr>
<td align="center">层数</td>
<td align="center">28</td>
</tr>
<tr>
<td align="center">注意力头数</td>
<td align="center">32</td>
</tr>
<tr>
<td align="center">训练数据</td>
<td align="center">1T</td>
</tr>
<tr>
<td align="center">词表大小</td>
<td align="center">130528</td>
</tr>
<tr>
<td align="center">最大长度</td>
<td align="center">2048</td>
</tr>
</tbody></table>
<hr>
<h4 id="1-2-3-硬件要求-官网介绍"><a href="#1-2-3-硬件要求-官网介绍" class="headerlink" title="1.2.3 硬件要求(官网介绍)"></a>1.2.3 硬件要求(官网介绍)</h4><table>
<thead>
<tr>
<th align="center">量化等级</th>
<th align="center">最低GPU显存（推理）</th>
<th align="center">最低GPU显存（高效参数微调）</th>
</tr>
</thead>
<tbody><tr>
<td align="center">FP16(无量化)</td>
<td align="center">13GB</td>
<td align="center">14GB</td>
</tr>
<tr>
<td align="center">INT8</td>
<td align="center">10GB</td>
<td align="center">9GB</td>
</tr>
<tr>
<td align="center">INT4</td>
<td align="center">6GB</td>
<td align="center">7GB</td>
</tr>
</tbody></table>
<hr>
<blockquote>
<p>注意：显存的占用除了跟模型参数大小有关系外，还和文本支持最大长度有关</p>
</blockquote>
<h4 id="1-2-4-模型特点"><a href="#1-2-4-模型特点" class="headerlink" title="1.2.4 模型特点"></a>1.2.4 模型特点</h4><ul>
<li>优点<ul>
<li>1.较低的部署门槛： INT4 精度下，只需6GB显存，使得 ChatGLM-6B 可以部署在消费级显卡上进行推理。</li>
<li>2.更长的序列长度： 相比 GLM-10B（序列长度1024），ChatGLM2-6B 序列长度达32K，支持更长对话和应用。</li>
<li>人类类意图对齐训练</li>
</ul>
</li>
<li>缺点：<ul>
<li>模型容量小，相对较弱的模型记忆和语言能力。</li>
<li>较弱的多轮对话能力。</li>
</ul>
</li>
</ul>
<h3 id="1-3-环境配置"><a href="#1-3-环境配置" class="headerlink" title="1.3. 环境配置"></a>1.3. 环境配置</h3><h4 id="1-3-1-基础环境配置："><a href="#1-3-1-基础环境配置：" class="headerlink" title="1.3.1 基础环境配置："></a>1.3.1 基础环境配置：</h4><p>本次环境依赖于AutoDL算力：<a target="_blank" rel="noopener" href="https://www.autodl.com/home">https://www.autodl.com/home</a></p>
<ul>
<li>操作系统: ubuntu22.04</li>
<li>CPUs: 14 core(s)，内存：100G</li>
<li>GPUs: 1卡， A800， 80GB GPUs</li>
<li>Python: 3.10</li>
<li>Pytorh: 2.5.1</li>
<li>Cuda: 12.4</li>
<li>价格：5.98元&#x2F;小时</li>
</ul>
<h4 id="1-3-2-安装依赖包："><a href="#1-3-2-安装依赖包：" class="headerlink" title="1.3.2 安装依赖包："></a>1.3.2 安装依赖包：</h4><ol>
<li>创建一个虚拟环境，您可以把 <code>llm_env</code> 修改为任意你想要新建的环境名称：</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n llm_env python=3.10</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>激活新建虚拟环境</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate llm_env</span><br></pre></td></tr></table></figure>

<p>注意： <strong>如果激活失败，则先运行 conda init，然后退出终端，重新打开一个终端。</strong> </p>
<ol start="3">
<li>安装相应的依赖包：</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- 成功切换到llm_env后安装</span><br><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>

<blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">protobuf&gt;=<span class="number">3.19</span><span class="number">.5</span>,&lt;<span class="number">3.20</span><span class="number">.1</span></span><br><span class="line">transformers==<span class="number">4.33</span></span><br><span class="line">icetk</span><br><span class="line">cpm_kernels</span><br><span class="line">streamlit==<span class="number">1.18</span><span class="number">.0</span></span><br><span class="line">matplotlib</span><br><span class="line">datasets</span><br><span class="line">accelerate&gt;=<span class="number">0.20</span><span class="number">.3</span></span><br><span class="line">packaging&gt;=<span class="number">20.0</span></span><br><span class="line">psutil</span><br><span class="line">pyyaml</span><br><span class="line">peft==<span class="number">0.3</span><span class="number">.0</span></span><br></pre></td></tr></table></figure>

<p>requirements.txt文件内容如上所示</p>
</blockquote>
<hr>
<h4 id="1-3-3-预训练模型下载："><a href="#1-3-3-预训练模型下载：" class="headerlink" title="1.3.3 预训练模型下载："></a>1.3.3 预训练模型下载：</h4><ul>
<li>创建目录</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/autodl-tmp/llm_tuning/THUDM/chatglm-6b</span><br><span class="line">cd /root/autodl-tmp/llm_tuning/THUDM/chatglm-6b</span><br></pre></td></tr></table></figure>

<ul>
<li>安装modelscope</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install modelscope</span><br></pre></td></tr></table></figure>

<ul>
<li>下载chatglm-6b</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">modelscope download --model ZhipuAI/ChatGLM-6B --local_dir ./</span><br></pre></td></tr></table></figure>

<ul>
<li>python文件下载</li>
</ul>
<p>如果configuration_chatglm.py、modeling_chatglm.py、quantization.py、tokenization_chatglm.py文件没有下载成功，则手动下载，然后添加到chatglm-6b的文件夹中。</p>
<p>下载位置：<a target="_blank" rel="noopener" href="https://modelscope.cn/models/ZhipuAI/ChatGLM-6B/files">https://modelscope.cn/models/ZhipuAI/ChatGLM-6B/files</a></p>
<h3 id="1-4-项目架构"><a href="#1-4-项目架构" class="headerlink" title="1.4. 项目架构"></a>1.4. 项目架构</h3><p>项目架构流程图：</p>
<div align=center><img src="./img/7-1-1.png" style="zoom:40%" ><img/></div>

<p>项目代码架构图：</p>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250822045752984.png" alt="image-20250822045752984"></p>
<h2 id="2-数据预处理【掌握】"><a href="#2-数据预处理【掌握】" class="headerlink" title="2.数据预处理【掌握】"></a>2.数据预处理【掌握】</h2><ul>
<li>本项目中对数据部分的预处理步骤如下:<ol>
<li>查看项目数据集</li>
<li>编写Config类项目文件配置代码</li>
<li>编写数据处理相关代码</li>
</ol>
</li>
</ul>
<h3 id="2-1-查看项目数据集"><a href="#2-1-查看项目数据集" class="headerlink" title="2.1 查看项目数据集"></a>2.1 查看项目数据集</h3><ul>
<li><p>数据存放位置：llm_tuning&#x2F;ptune_chatglm&#x2F;data</p>
</li>
<li><p>data文件夹里面包含3个jsonl文档，分别为：mixed_train_dataset.jsonl、mixed_dev_dataset.jsonl、dataset.jsonl</p>
</li>
</ul>
<hr>
<h4 id="2-1-1-train-jsonl"><a href="#2-1-1-train-jsonl" class="headerlink" title="2.1.1 train.jsonl"></a>2.1.1 train.jsonl</h4><ul>
<li><p>mixed_train_dataset.jsonl为训练数据集，因为我们本次项目同时进行「信息抽取+文本分类」两项任务，因此数据中混合了两种任务数据类型。举例展示如下：</p>
<ul>
<li>信息抽取数据示例</li>
<li>Instruction 部分告诉模型现在需要做「阅读理解」任务，Input 部分告知模型要抽取的句子以及输出的格式。</li>
</ul>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;context&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Instruction: 你现在是一个很厉害的阅读理解器，严格按照人类指令进行回答。\nInput: 找到句子中的三元组信息并输出成json给我:\n\n九玄珠是在纵横中文网连载的一部小说，作者是龙马。\nAnswer: &quot;</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;target&quot;</span><span class="punctuation">:</span> <span class="string">&quot;```json\n[&#123;\&quot;predicate\&quot;: \&quot;连载网站\&quot;, \&quot;object_type\&quot;: \&quot;网站\&quot;, \&quot;subject_type\&quot;: \&quot;网络小说\&quot;, \&quot;object\&quot;: \&quot;纵横中文网\&quot;, \&quot;subject\&quot;: \&quot;九玄珠\&quot;&#125;, &#123;\&quot;predicate\&quot;: \&quot;作者\&quot;, \&quot;object_type\&quot;: \&quot;人物\&quot;, \&quot;subject_type\&quot;: \&quot;图书作品\&quot;, \&quot;object\&quot;: \&quot;龙马\&quot;, \&quot;subject\&quot;: \&quot;九玄珠\&quot;&#125;]\n```&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>文本数据示例</li>
<li>Instruction 部分告诉模型现在需要做「阅读理解」任务，Input 部分告知模型要抽取的句子以及输出的格式。</li>
</ul>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;context&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Instruction: 你现在是一个很厉害的阅读理解器，严格按照人类指令进行回答。\nInput: 下面句子可能是一条关于什么的评论，用列表形式回答：\n\n很不错，很新鲜，快递小哥服务很好，水果也挺甜挺脆的\nAnswer: &quot;</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;target&quot;</span><span class="punctuation">:</span> <span class="string">&quot;[\&quot;水果\&quot;]&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<blockquote>
<p>训练集中一共包含902条数据，每一条数据都分为 <code>context</code> 和 <code>target</code> 两部分：</p>
<ol>
<li><code>context</code> 部分是接受用户的输入。2.<code> target</code> 部分用于指定模型的输出。</li>
</ol>
<p>在 <code>context</code> 中又包括 2 个部分：</p>
<ol>
<li>Instruction：用于告知模型的具体指令，当需要一个模型同时解决多个任务时可以设定不同的 Instruction 来帮助模型判别当前应当做什么任务。</li>
<li>Input：当前用户的输入。</li>
</ol>
</blockquote>
<hr>
<h4 id="2-1-2-dev-jsonl"><a href="#2-1-2-dev-jsonl" class="headerlink" title="2.1.2 dev.jsonl"></a>2.1.2 dev.jsonl</h4><ul>
<li>mixed_dev_dataset.jsonl为验证数据集，数据格式同train.jsonl。</li>
</ul>
<hr>
<p>如果想使用自定义数据训练，只需要仿照上述示例数据构建数据集即可。</p>
<h3 id="2-2-编写项目Config类配置文件"><a href="#2-2-编写项目Config类配置文件" class="headerlink" title="2.2 编写项目Config类配置文件"></a>2.2 编写项目Config类配置文件</h3><ul>
<li><p>代码路径：llm_tuning&#x2F;ptune_chatglm&#x2F;glm_config.py</p>
</li>
<li><p>config文件目的：配置项目常用变量，一般这些变量属于不经常改变的，比如：训练文件路径、模型训练次数、模型超参数等等</p>
</li>
</ul>
<p>具体代码实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os.path</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">base_dir = os.path.dirname(os.path.abspath(__file__))</span><br><span class="line"><span class="comment"># print(f&#x27;base_dir--&gt;&#123;base_dir&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ProjectConfig</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 定义是否使用GPU</span></span><br><span class="line">        self.device = <span class="string">&#x27;cuda:0&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line">        <span class="comment"># self.device = &#x27;mps:0&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;</span></span><br><span class="line">        <span class="comment"># 定义ChatGLM-6B模型的路径</span></span><br><span class="line">        self.pre_model = os.path.join(base_dir, <span class="string">&#x27;../THUDM/model/chatglm-6b-int4&#x27;</span>)</span><br><span class="line">        <span class="comment"># 定义训练数据的路径</span></span><br><span class="line">        self.train_path = os.path.join(base_dir, <span class="string">&#x27;data/mixed_train_dataset.jsonl&#x27;</span>)</span><br><span class="line">        <span class="comment"># 定义验证集的路径</span></span><br><span class="line">        self.dev_path = os.path.join(base_dir, <span class="string">&#x27;data/mixed_dev_dataset.jsonl&#x27;</span>)</span><br><span class="line">        <span class="comment"># 是否使用LoRA方法微调</span></span><br><span class="line">        self.use_lora = <span class="literal">True</span></span><br><span class="line">        <span class="comment"># 是否使用P-Tuing方法微调</span></span><br><span class="line">        self.use_ptuning = <span class="literal">False</span></span><br><span class="line">        <span class="comment"># 秩==8</span></span><br><span class="line">        self.lora_rank = <span class="number">8</span></span><br><span class="line">        <span class="comment"># 一个批次多少样本</span></span><br><span class="line">        self.batch_size = <span class="number">4</span></span><br><span class="line">        <span class="comment"># 训练几轮</span></span><br><span class="line">        self.epochs = <span class="number">2</span></span><br><span class="line">        <span class="comment"># 学习率</span></span><br><span class="line">        self.learning_rate = <span class="number">3e-5</span></span><br><span class="line">        <span class="comment"># 权重权重系数</span></span><br><span class="line">        self.weight_decay = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 学习率预热比例</span></span><br><span class="line">        self.warmup_ratio = <span class="number">0.06</span></span><br><span class="line">        <span class="comment"># context文本的输入长度限制</span></span><br><span class="line">        self.max_source_seq_len = <span class="number">100</span></span><br><span class="line">        <span class="comment"># target文本长度限制</span></span><br><span class="line">        self.max_target_seq_len = <span class="number">100</span></span><br><span class="line">        <span class="comment"># 每隔多少步打印日志</span></span><br><span class="line">        self.logging_steps = <span class="number">10</span></span><br><span class="line">        <span class="comment"># 每隔多少步保存</span></span><br><span class="line">        self.save_freq = <span class="number">200</span></span><br><span class="line">        <span class="comment"># 如果你使用了P-Tuing，要定义伪tokens的长度</span></span><br><span class="line">        self.pre_seq_len = <span class="number">200</span></span><br><span class="line">        self.prefix_projection = <span class="literal">False</span>  <span class="comment"># 默认为False,即p-tuning,如果为True，即p-tuning-v2</span></span><br><span class="line">        <span class="comment"># 保存模型的路径</span></span><br><span class="line">        self.save_dir = os.path.join(base_dir, <span class="string">&#x27;save_model&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    pc = ProjectConfig()</span><br><span class="line">    <span class="built_in">print</span>(pc.save_dir)</span><br></pre></td></tr></table></figure>

<h3 id="2-3-编写数据处理相关代码"><a href="#2-3-编写数据处理相关代码" class="headerlink" title="2.3 编写数据处理相关代码"></a>2.3 编写数据处理相关代码</h3><ul>
<li>代码路径：llm_tuning&#x2F;ptune_chatglm&#x2F;data_handle</li>
<li>data_handle文件夹中一共包含两个py脚本：data_preprocess.py、data_loader.py</li>
</ul>
<h4 id="2-3-1-data-preprocess-py"><a href="#2-3-1-data-preprocess-py" class="headerlink" title="2.3.1 data_preprocess.py"></a>2.3.1 data_preprocess.py</h4><ul>
<li>模型输入和标签的构建思路：</li>
</ul>
<img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250822121925643.png" alt="image-20250822121925643" style="zoom:80%;" />

<ul>
<li>目的: 将样本数据转换为模型接受的输入数据<ul>
<li>定义数据转换方法convert_example()</li>
<li>定义获取训练或验证数据最大长度方法get_max_length()</li>
</ul>
</li>
</ul>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">project_root = os.path.join(os.path.dirname(os.path.abspath(__file__)), <span class="string">&#x27;../..&#x27;</span>)</span><br><span class="line"><span class="comment"># print(f&#x27;project_root--&gt;&#123;project_root&#125;&#x27;)</span></span><br><span class="line">sys.path.append(project_root)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="comment"># 返回的字符串包含有关异常的详细信</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> ptune_chatglm.glm_config <span class="keyword">import</span> ProjectConfig</span><br><span class="line"></span><br><span class="line">pc = ProjectConfig()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_example_chatglm</span>(<span class="params"></span></span><br><span class="line"><span class="params">        examples: <span class="built_in">dict</span>,</span></span><br><span class="line"><span class="params">        tokenizer,</span></span><br><span class="line"><span class="params">        max_source_seq_len: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        max_target_seq_len: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    将样本数据转换为Prompt-tuning模型接收的输入数据。</span></span><br><span class="line"><span class="string">    :param examples: (dict): 训练数据样本,</span></span><br><span class="line"><span class="string">    e.g. -&gt; &#123;</span></span><br><span class="line"><span class="string">            &quot;text&quot;: [</span></span><br><span class="line"><span class="string">                        &#x27;&#123;&quot;context&quot;: &quot;年基准利率4.35%。从实际看...&quot;, &quot;target&quot;: &quot;2017年银行贷款基准利率&quot;&#125;&#x27;,</span></span><br><span class="line"><span class="string">                        ...</span></span><br><span class="line"><span class="string">            ]</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    :param tokenizer: 分词器</span></span><br><span class="line"><span class="string">    :param max_source_seq_len: (int): prompt最大长度</span></span><br><span class="line"><span class="string">    :param max_target_seq_len: (int): 答案最大长度</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    dict (str: np.array) -&gt;</span></span><br><span class="line"><span class="string">    tokenized_output = &#123;</span></span><br><span class="line"><span class="string">        &#x27;input_ids&#x27;: [[1525, 10, ...], [758, 2345, ...]],</span></span><br><span class="line"><span class="string">        &#x27;labels&#x27;: [[822, 10, ...], [125, 58...]]</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 初始化一个字典，用于存储编码后的输入ID和对应的标签</span></span><br><span class="line">    tokenized_output = &#123;</span><br><span class="line">        <span class="string">&#x27;input_ids&#x27;</span>: [],  <span class="comment"># 存储编码后的输入ID列表</span></span><br><span class="line">        <span class="string">&#x27;labels&#x27;</span>: []  <span class="comment"># 存储对应的标签列表</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 设定句子的最大长度</span></span><br><span class="line">    max_seq_len = max_source_seq_len + max_target_seq_len</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历每个样本</span></span><br><span class="line">    <span class="keyword">for</span> example <span class="keyword">in</span> tqdm(examples[<span class="string">&#x27;text&#x27;</span>]):</span><br><span class="line">        <span class="comment"># print(f&#x27;example--&gt; &#123;example&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;type(example)--&gt; &#123;type(example)&#125;&#x27;)</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># 1.将字符串转成字典，取出问题和答案</span></span><br><span class="line">            example = json.loads(example)</span><br><span class="line">            <span class="comment"># print(f&#x27;example--&gt;&#123;example&#125;&#x27;)</span></span><br><span class="line">            context = example[<span class="string">&quot;context&quot;</span>]</span><br><span class="line">            target = example[<span class="string">&quot;target&quot;</span>]</span><br><span class="line">            <span class="comment"># print(f&#x27;context--&gt;\n&#123;context&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># print(f&#x27;context2len--&gt;&#123;len(context)&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># print(f&#x27;target--&gt;\n&#123;target&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 2.将问题和答案进行分词转成id</span></span><br><span class="line">            context_ids = tokenizer.encode(context, add_special_tokens=<span class="literal">False</span>)  <span class="comment"># 不需要添加特殊标记，原因是需要手动添加</span></span><br><span class="line">            <span class="comment"># print(f&#x27;context_ids---&gt;&#123;context_ids&#125;&#x27;)</span></span><br><span class="line">            target_ids = tokenizer.encode(target, add_special_tokens=<span class="literal">False</span>)</span><br><span class="line">            <span class="comment"># print(f&#x27;target_ids---&gt;&#123;target_ids&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 3.将问题和答案超过最大长度的进行截断</span></span><br><span class="line">            <span class="comment"># 如果问题长度超过 max_source_seq_len - 1，则截断，因为需要留出一个位置给[gMASK]</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(context_ids) &gt; max_source_seq_len - <span class="number">1</span>:</span><br><span class="line">                context_ids = context_ids[:max_source_seq_len - <span class="number">1</span>]</span><br><span class="line">            <span class="comment"># 如果答案长度超过 max_target_seq_len - 2 ，则截断，因为需要留两个位置给[sop]和[eop]</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(target_ids) &gt; max_target_seq_len - <span class="number">2</span>:</span><br><span class="line">                target_ids = target_ids[:max_target_seq_len - <span class="number">2</span>]</span><br><span class="line">            <span class="comment"># print(f&#x27;context_ids---&gt;&#123;context_ids&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># print(f&#x27;target_ids---&gt;&#123;target_ids&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 4.将问题和答案拼接起来作为input_ids</span></span><br><span class="line">            <span class="comment"># source_ids + [gMASK] + &lt;sop&gt;[也是bos] + target_ids + &lt;eop&gt;</span></span><br><span class="line">            input_ids = tokenizer.build_inputs_with_special_tokens(context_ids, target_ids)</span><br><span class="line">            <span class="comment"># print(f&#x27;input_ids---&gt;&#123;input_ids&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 5.将问题作为labels，需要将问题所在的位置设置为-100, 因为-100表示忽略，不计算损失</span></span><br><span class="line">            <span class="comment"># 查找bos_token_id的索引位置，这个索引位置就是问题结束的位置，也是问题的长度</span></span><br><span class="line">            context_length = input_ids.index(tokenizer.bos_token_id)</span><br><span class="line">            <span class="comment"># 将问题所在位置的id设置为-100，另外，答案所在的位置进行保留原id</span></span><br><span class="line">            labels = [-<span class="number">100</span>] * context_length + input_ids[context_length:]</span><br><span class="line">            <span class="comment"># print(f&#x27;labels---&gt;&#123;labels&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 6.需要将短的句子进行补齐，填充到max_seq_len</span></span><br><span class="line">            pad_len = max_seq_len - <span class="built_in">len</span>(input_ids)</span><br><span class="line">            <span class="comment"># input_ids需要使用pad_token_id进行填充</span></span><br><span class="line">            input_ids += [tokenizer.pad_token_id] * pad_len</span><br><span class="line">            <span class="comment"># print(f&#x27;input_ids---&gt;&#123;input_ids&#125;&#x27;)</span></span><br><span class="line">            <span class="comment"># labels需要使用-100进行填充</span></span><br><span class="line">            labels += [-<span class="number">100</span>] * pad_len</span><br><span class="line">            <span class="comment"># print(f&#x27;labels---&gt;&#123;labels&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 7.将处理好的input_ids和labels添加到tokenized_output中</span></span><br><span class="line">            tokenized_output[<span class="string">&#x27;input_ids&#x27;</span>].append(input_ids)</span><br><span class="line">            tokenized_output[<span class="string">&#x27;labels&#x27;</span>].append(labels)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;Exception--&gt;<span class="subst">&#123;e&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将输出中的每个值转换成numpy数组</span></span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> tokenized_output.items():</span><br><span class="line">            tokenized_output[k] = np.array(v)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tokenized_output</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_max_length</span>(<span class="params"></span></span><br><span class="line"><span class="params">        tokenizer,</span></span><br><span class="line"><span class="params">        dataset_file: <span class="built_in">str</span></span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    测试数据集最大的输入/输出tokens是多少。</span></span><br><span class="line"><span class="string">    :param tokenizer: 分词器</span></span><br><span class="line"><span class="string">    :param dataset_file: (str): _description_</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 初始化源序列长度列表和目标序列长度列表</span></span><br><span class="line">    source_seq_len_list = []</span><br><span class="line">    target_seq_len_list = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打开数据集文件以读取数据</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(dataset_file, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="comment"># 使用tqdm包装读取操作，以便显示进度条</span></span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> tqdm(f.readlines()):</span><br><span class="line">            <span class="comment"># 将每一行转换为JSON对象</span></span><br><span class="line">            line = json.loads(line)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 对源文本进行编码，并计算其序列长度</span></span><br><span class="line">            source_len = tokenizer.encode(line[<span class="string">&#x27;context&#x27;</span>])</span><br><span class="line">            source_seq_len_list.append(<span class="built_in">len</span>(source_len))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 对目标文本进行编码，并计算其序列长度</span></span><br><span class="line">            target_len = tokenizer.encode(line[<span class="string">&#x27;target&#x27;</span>])</span><br><span class="line">            target_seq_len_list.append(<span class="built_in">len</span>(target_len))</span><br><span class="line">            </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;【Source Sequence】 Max: <span class="subst">&#123;<span class="built_in">max</span>(source_seq_len_list)&#125;</span>, &quot;</span></span><br><span class="line">          <span class="string">f&quot;Avg: <span class="subst">&#123;<span class="built_in">int</span>(<span class="built_in">sum</span>(source_seq_len_list) / <span class="built_in">len</span>(source_seq_len_list))&#125;</span>, &quot;</span></span><br><span class="line">          <span class="string">f&quot;Middle: <span class="subst">&#123;<span class="built_in">sorted</span>(source_seq_len_list)[<span class="built_in">int</span>(<span class="built_in">len</span>(source_seq_len_list) / <span class="number">2</span>)]&#125;</span>.&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;【Target Sequence】 Max: <span class="subst">&#123;<span class="built_in">max</span>(target_seq_len_list)&#125;</span>, &quot;</span></span><br><span class="line">          <span class="string">f&quot;Avg: <span class="subst">&#123;<span class="built_in">int</span>(<span class="built_in">sum</span>(target_seq_len_list) / <span class="built_in">len</span>(target_seq_len_list))&#125;</span>, &quot;</span></span><br><span class="line">          <span class="string">f&quot;Middle: <span class="subst">&#123;<span class="built_in">sorted</span>(target_seq_len_list)[<span class="built_in">int</span>(<span class="built_in">len</span>(target_seq_len_list) / <span class="number">2</span>)]&#125;</span>.&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    examples = &#123;<span class="string">&#x27;text&#x27;</span>: [</span><br><span class="line">        <span class="string">&#x27;&#123;&quot;context&quot;: &quot;Instruction: 你现在是一个很厉害的阅读理解器，严格按照人类指令进行回答。\\nInput: 句子中包含了哪些信息，输出json：\\n\\n如何演好自己的角色，请读《演员自我修养&gt;《喜剧之王&gt;周星驰崛起于穷困潦倒之中的独门秘笈。\\nAnswer: &quot;, &quot;target&quot;: &quot;```json\\n[&#123;\\&quot;predicate\\&quot;: \\&quot;主演\\&quot;, \\&quot;object_type\\&quot;: \\&quot;人物\\&quot;, \\&quot;subject_type\\&quot;: \\&quot;影视作品\\&quot;, \\&quot;object\\&quot;: \\&quot;周星驰\\&quot;, \\&quot;subject\\&quot;: \\&quot;喜剧之王\\&quot;&#125;]\\n```&quot;&#125;&#x27;</span></span><br><span class="line">    ]&#125;</span><br><span class="line">    tokenizer = AutoTokenizer.from_pretrained(pc.pre_model, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    out = convert_example_chatglm(examples, tokenizer, <span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;input_ids shape:&#x27;</span>, out[<span class="string">&#x27;input_ids&#x27;</span>].shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;labels shape:&#x27;</span>, out[<span class="string">&#x27;labels&#x27;</span>].shape)</span><br><span class="line"></span><br><span class="line">    get_max_length(tokenizer, pc.train_path)</span><br></pre></td></tr></table></figure>



<hr>
<h4 id="2-3-2-data-loader-py"><a href="#2-3-2-data-loader-py" class="headerlink" title="2.3.2 data_loader.py"></a>2.3.2 data_loader.py</h4><ul>
<li><p>目的：定义数据加载器</p>
<p>代码如下：</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> default_data_collator, AutoTokenizer</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> ptune_chatglm.data_handle.data_preprocess <span class="keyword">import</span> convert_example_chatglm</span><br><span class="line"><span class="keyword">from</span> ptune_chatglm.glm_config <span class="keyword">import</span> ProjectConfig</span><br><span class="line"></span><br><span class="line">pc = ProjectConfig()</span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(pc.pre_model, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_data</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    加载并处理数据集。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    该函数从指定的文件路径加载数据集，并对其进行一系列的预处理操作，</span></span><br><span class="line"><span class="string">    包括数据的转换和分批，以便于后续的模型训练和评估。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># &#x27;text&#x27; 表示使用 内置的文本数据加载器。这个加载器会把 纯文本文件 按行读取，每一行作为一条样本，最终将这个样本放到text对应的列表里。</span></span><br><span class="line">    dataset = load_dataset(<span class="string">&#x27;text&#x27;</span>, data_files=&#123;<span class="string">&#x27;train&#x27;</span>: pc.train_path,</span><br><span class="line">                                                    <span class="string">&#x27;dev&#x27;</span>: pc.dev_path&#125;)</span><br><span class="line">    <span class="comment"># print(f&#x27;数据集--&gt;&#123;dataset&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建一个新的函数，用于部分应用convert_example_chatglm函数</span></span><br><span class="line">    new_func = partial(convert_example_chatglm,</span><br><span class="line">                       tokenizer=tokenizer,</span><br><span class="line">                       max_source_seq_len=pc.max_source_seq_len,</span><br><span class="line">                       max_target_seq_len=pc.max_target_seq_len)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 应用新的函数到数据集上，进行数据转换</span></span><br><span class="line">    dataset = dataset.<span class="built_in">map</span>(new_func, batched=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 提取训练集和测试集</span></span><br><span class="line">    train_dataset = dataset[<span class="string">&quot;train&quot;</span>]</span><br><span class="line">    dev_dataset = dataset[<span class="string">&quot;dev&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建训练集的数据加载器，用于批量处理训练数据</span></span><br><span class="line">    train_dataloader = DataLoader(train_dataset,</span><br><span class="line">                                  shuffle=<span class="literal">True</span>,</span><br><span class="line">                                  collate_fn=default_data_collator,</span><br><span class="line">                                  batch_size=pc.batch_size,</span><br><span class="line">                                  drop_last=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建测试集的数据加载器，用于批量处理测试数据</span></span><br><span class="line">    dev_dataloader = DataLoader(dev_dataset,</span><br><span class="line">                                collate_fn=default_data_collator,</span><br><span class="line">                                batch_size=pc.batch_size,</span><br><span class="line">                                drop_last=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_dataloader, dev_dataloader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    train_dataloader, dev_dataloader = get_data()</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">len</span>(train_dataloader))</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">len</span>(dev_dataloader))</span><br><span class="line">    <span class="keyword">for</span> i, value <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataloader):</span><br><span class="line">        <span class="built_in">print</span>(value)</span><br><span class="line">        <span class="built_in">print</span>(value[<span class="string">&#x27;input_ids&#x27;</span>].shape)</span><br><span class="line">        <span class="built_in">print</span>(value[<span class="string">&#x27;labels&#x27;</span>].shape)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<ul>
<li>打印结果：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">902</span></span><br><span class="line"><span class="number">122</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&#x27;input_ids&#x27;</span>: tensor([[ <span class="number">37010</span>,     <span class="number">12</span>,      <span class="number">5</span>,  <span class="number">76331</span>,  <span class="number">83362</span>,  <span class="number">92831</span>, </span><br><span class="line"><span class="number">103593</span>,  <span class="number">64464</span>,      <span class="number">6</span>,</span><br><span class="line">          <span class="number">77115</span>,  <span class="number">65077</span>,  <span class="number">72863</span>,  <span class="number">63891</span>,  <span class="number">66207</span>,  <span class="number">63823</span>,      <span class="number">4</span>,   <span class="number">3430</span>,     <span class="number">12</span>,</span><br><span class="line">          <span class="number">68327</span>,  <span class="number">74351</span>,  <span class="number">77756</span>,  <span class="number">66263</span>,  <span class="number">81577</span>,  <span class="number">64536</span>,      <span class="number">6</span>,  <span class="number">82145</span>,   <span class="number">2031</span>,</span><br><span class="line">          <span class="number">63825</span>,  <span class="number">69574</span>,  <span class="number">66207</span>,     <span class="number">12</span>,      <span class="number">4</span>,      <span class="number">4</span>,  <span class="number">64590</span>,  <span class="number">67748</span>,  <span class="number">69958</span>,</span><br><span class="line">          <span class="number">66152</span>,  <span class="number">63923</span>,  <span class="number">65024</span>,  <span class="number">64676</span>,  <span class="number">65102</span>,  <span class="number">66089</span>,  <span class="number">64101</span>,  <span class="number">73127</span>,  <span class="number">64025</span>,</span><br><span class="line">          <span class="number">64236</span>,      <span class="number">6</span>,  <span class="number">72996</span>,  <span class="number">73518</span>,  <span class="number">64236</span>,  <span class="number">82273</span>,  <span class="number">63823</span>,      <span class="number">4</span>,  <span class="number">13049</span>,</span><br><span class="line">             <span class="number">12</span>, <span class="number">130001</span>, <span class="number">130004</span>,      <span class="number">5</span>, <span class="number">125827</span>,   <span class="number">2031</span>,      <span class="number">4</span>, <span class="number">127903</span>,  <span class="number">38861</span>,</span><br><span class="line">             <span class="number">83</span>,     <span class="number">28</span>,  <span class="number">66845</span>,  <span class="number">67541</span>,     <span class="number">57</span>,     <span class="number">28</span>,   <span class="number">1932</span>,     <span class="number">24</span>,    <span class="number">317</span>,</span><br><span class="line">             <span class="number">83</span>,     <span class="number">28</span>,  <span class="number">64069</span>,     <span class="number">57</span>,     <span class="number">28</span>,   <span class="number">9832</span>,     <span class="number">24</span>,    <span class="number">317</span>,     <span class="number">83</span>,</span><br><span class="line">             <span class="number">28</span>,  <span class="number">65210</span>,     <span class="number">57</span>,     <span class="number">28</span>,   <span class="number">1932</span>,     <span class="number">83</span>,     <span class="number">28</span>,  <span class="number">73127</span>,  <span class="number">64025</span>,</span><br><span class="line">          <span class="number">64236</span>,     <span class="number">57</span>,     <span class="number">28</span>,   <span class="number">9832</span>,     <span class="number">83</span>,     <span class="number">28</span>,  <span class="number">64590</span>,  <span class="number">67748</span>,  <span class="number">69958</span>,</span><br><span class="line">          <span class="number">66152</span>, <span class="number">127731</span>,      <span class="number">4</span>, <span class="number">125827</span>, <span class="number">130005</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,</span><br><span class="line">              <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,</span><br><span class="line">              <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,</span><br><span class="line">              <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,</span><br><span class="line">              <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,</span><br><span class="line">              <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,</span><br><span class="line">              <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,</span><br><span class="line">              <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,</span><br><span class="line">              <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,</span><br><span class="line">              <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,</span><br><span class="line">              <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,      <span class="number">3</span>,</span><br><span class="line">              <span class="number">3</span>,      <span class="number">3</span>]]),</span><br><span class="line">    <span class="string">&#x27;labels&#x27;</span>: tensor([[  -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,  </span><br><span class="line">-<span class="number">100</span>,   -<span class="number">100</span>,</span><br><span class="line">           -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,</span><br><span class="line">           -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,</span><br><span class="line">           -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,</span><br><span class="line">           -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,</span><br><span class="line">           -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,</span><br><span class="line">           -<span class="number">100</span>,   -<span class="number">100</span>, <span class="number">130004</span>,      <span class="number">5</span>, <span class="number">125827</span>,   <span class="number">2031</span>,      <span class="number">4</span>, <span class="number">127903</span>,  <span class="number">38861</span>,</span><br><span class="line">             <span class="number">83</span>,     <span class="number">28</span>,  <span class="number">66845</span>,  <span class="number">67541</span>,     <span class="number">57</span>,     <span class="number">28</span>,   <span class="number">1932</span>,     <span class="number">24</span>,    <span class="number">317</span>,</span><br><span class="line">             <span class="number">83</span>,     <span class="number">28</span>,  <span class="number">64069</span>,     <span class="number">57</span>,     <span class="number">28</span>,   <span class="number">9832</span>,     <span class="number">24</span>,    <span class="number">317</span>,     <span class="number">83</span>,</span><br><span class="line">             <span class="number">28</span>,  <span class="number">65210</span>,     <span class="number">57</span>,     <span class="number">28</span>,   <span class="number">1932</span>,     <span class="number">83</span>,     <span class="number">28</span>,  <span class="number">73127</span>,  <span class="number">64025</span>,</span><br><span class="line">          <span class="number">64236</span>,     <span class="number">57</span>,     <span class="number">28</span>,   <span class="number">9832</span>,     <span class="number">83</span>,     <span class="number">28</span>,  <span class="number">64590</span>,  <span class="number">67748</span>,  <span class="number">69958</span>,</span><br><span class="line">          <span class="number">66152</span>, <span class="number">127731</span>,      <span class="number">4</span>, <span class="number">125827</span>, <span class="number">130005</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,</span><br><span class="line">           -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,</span><br><span class="line">           -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,</span><br><span class="line">           -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,</span><br><span class="line">           -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,</span><br><span class="line">           -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,</span><br><span class="line">           -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,</span><br><span class="line">           -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,</span><br><span class="line">           -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,</span><br><span class="line">           -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,</span><br><span class="line">           -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,   -<span class="number">100</span>,</span><br><span class="line">           -<span class="number">100</span>,   -<span class="number">100</span>]])</span><br><span class="line">&#125;</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">200</span>])</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">200</span>])</span><br></pre></td></tr></table></figure>

<h4 id="2-3-3-代码上传"><a href="#2-3-3-代码上传" class="headerlink" title="2.3.3 代码上传"></a>2.3.3 代码上传</h4><p>将写好的代码 ptune_chatglm 文件夹直接打包成zip文件。然后上传到autodl平台的 llm_tuning 文件夹下。</p>
<p>然后解压缩。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /root/autodl-tmp/llm_tuning/</span><br><span class="line">unzip ptune_chatglm.zip</span><br></pre></td></tr></table></figure>

<p>然后使用python xx.py的方式运行文件即可。</p>
<h2 id="3-模型搭建与训练【掌握】"><a href="#3-模型搭建与训练【掌握】" class="headerlink" title="3.模型搭建与训练【掌握】"></a>3.模型搭建与训练【掌握】</h2><p>本项目中完成ChatGLM+LoRA模型搭建、训练及应用的步骤如下（注意：因为本项目中使用的是ChatGLM预训练模型，所以直接加载即可，无需重复搭建模型架构）:</p>
<ul>
<li>1.实现模型工具类函数</li>
<li>2.实现模型训练函数,验证函数</li>
<li>3.实现模型预测函数</li>
</ul>
<h3 id="3-0-前置知识"><a href="#3-0-前置知识" class="headerlink" title="3.0 前置知识"></a>3.0 前置知识</h3><ul>
<li>&#x3D;&#x3D;lora模型配置：&#x3D;&#x3D;</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果使用lora方法微调</span></span><br><span class="line"><span class="keyword">if</span> pc.use_lora:</span><br><span class="line">    <span class="comment"># 将模型的输出头：数据类型转换为float32(确保)</span></span><br><span class="line">    model.lm_head = CastOutputToFloat(model.lm_head)</span><br><span class="line">    <span class="comment"># 定义LoRA配置</span></span><br><span class="line">    peft_config = peft.LoraConfig(</span><br><span class="line">        task_type=peft.TaskType.CAUSAL_LM,  <span class="comment"># 传统的语言模型</span></span><br><span class="line">        inference_mode=<span class="literal">False</span>,  <span class="comment"># 推理时为True，比如决定是否使用dropout</span></span><br><span class="line">        r=pc.lora_rank,  <span class="comment"># 低秩矩阵维度</span></span><br><span class="line">        lora_alpha=<span class="number">32</span>,  <span class="comment"># 缩放系数</span></span><br><span class="line">        lora_dropout=<span class="number">0.1</span></span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># print(f&#x27;peft_config--》&#123;peft_config&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># 根据LoRA配置获取LoRA模型</span></span><br><span class="line">    model = peft.get_peft_model(model, peft_config)</span><br></pre></td></tr></table></figure>

<ul>
<li>&#x3D;&#x3D;lora调用：&#x3D;&#x3D;</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">loss = model(</span><br><span class="line">    input_ids=batch[<span class="string">&#x27;input_ids&#x27;</span>].to(dtype=torch.long, device=pc.device),</span><br><span class="line">    labels=batch[<span class="string">&#x27;labels&#x27;</span>].to(dtype=torch.long, device=pc.device)</span><br><span class="line">).loss</span><br></pre></td></tr></table></figure>

<ul>
<li>&#x3D;&#x3D;lora模型保存：&#x3D;&#x3D;</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">save_model</span>(<span class="params">model, cur_save_dir: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    存储当前模型。</span></span><br><span class="line"><span class="string">    该函数根据条件判断，要么将模型直接保存，要么在保存前将LoRA（Low-Rank Adaptation）参数与原始模型合并后再保存。</span></span><br><span class="line"><span class="string">    这样做是为了确保无论是原始模型还是使用LoRA训练的模型，都可以被正确地保存和后续使用。</span></span><br><span class="line"><span class="string">    :param model: 待保存的模型。这可以是任何已经训练好的transformers模型。</span></span><br><span class="line"><span class="string">    :param cur_save_dir: (str): 存储路径。表示模型将被保存到的目录路径。</span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 检查是否使用了LoRA（低秩适应）技术</span></span><br><span class="line">    <span class="keyword">if</span> pc.use_lora:  <span class="comment"># merge lora params with origin model</span></span><br><span class="line">        <span class="comment"># 如果使用了LoRA，首先创建模型的深拷贝，以避免修改原始模型</span></span><br><span class="line">        merged_model = copy.deepcopy(model)</span><br><span class="line">        <span class="comment"># 直接保存的话，只会保存adapter即LoRA模型的参数，因此需要合并后再保存</span></span><br><span class="line">        merged_model = merged_model.merge_and_unload()</span><br><span class="line">        <span class="comment"># 保存合并后的模型到指定路径</span></span><br><span class="line">        merged_model.save_pretrained(cur_save_dir)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 如果没有使用LoRA，直接保存模型到指定路径</span></span><br><span class="line">        model.save_pretrained(cur_save_dir)</span><br></pre></td></tr></table></figure>



<p>&#x3D;&#x3D;ptuning的用法：&#x3D;&#x3D;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载预训练模型的配置</span></span><br><span class="line">config = AutoConfig.from_pretrained(pc.pre_model, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 如果使用ptuning微调手段</span></span><br><span class="line"><span class="keyword">if</span> pc.use_ptuning:</span><br><span class="line">    <span class="comment"># 设置前缀序列长度(soft prompt的长度)</span></span><br><span class="line">    config.pre_seq_len = pc.pre_seq_len</span><br><span class="line">    <span class="comment"># 可以指定是P-tuning-V1或者V2</span></span><br><span class="line">    config.prefix_projection = pc.prefix_projection</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="comment"># 如果pc对象的use_ptuning属性为真，则执行以下操作</span></span><br><span class="line"><span class="keyword">if</span> pc.use_ptuning:</span><br><span class="line">    <span class="comment"># 将模型的transformer部分的prefix_encoder组件转换为float精度</span></span><br><span class="line">    model.transformer.prefix_encoder.<span class="built_in">float</span>()</span><br></pre></td></tr></table></figure>



<hr>
<h3 id="3-1-实现模型工具类函数"><a href="#3-1-实现模型工具类函数" class="headerlink" title="3.1. 实现模型工具类函数"></a>3.1. 实现模型工具类函数</h3><ul>
<li>目的：模型在训练、验证、预测时需要的函数</li>
<li>代码路径：llm_tuning&#x2F;ptune_chatglm&#x2F;utils</li>
<li>utils文件夹共包含1个py脚本：common_utils.py</li>
</ul>
<hr>
<h4 id="3-1-1-common-utils-py"><a href="#3-1-1-common-utils-py" class="headerlink" title="3.1.1 common_utils.py"></a>3.1.1 common_utils.py</h4><ul>
<li><p>目的：定义数据类型转换类、分秒时之间转换以及模型保存函数。</p>
</li>
<li><p>脚本里面包含一个类以及两个函数：CastOutputToFloat、second2time()以及save_model()</p>
<ul>
<li>定义CastOutputToFloat类</li>
<li>定义second2time()函数</li>
<li>定义save_model()</li>
</ul>
</li>
<li><p>代码路径：llm_tuning&#x2F;ptune_chatglm&#x2F;utils&#x2F;common_utils.py</p>
<p>代码如下：</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> ptune_chatglm.glm_config <span class="keyword">import</span> ProjectConfig</span><br><span class="line"></span><br><span class="line">pc = ProjectConfig()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CastOutputToFloat</span>(nn.Sequential):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">	继承自nn.Sequential的类，用于将模型的输出转换为浮点类型。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	该类重写了forward方法，以确保模型输出被转换为torch.float32类型。</span></span><br><span class="line"><span class="string">	主要用途是在模型定义中作为最后一层，以确保输出类型符合预期。</span></span><br><span class="line"><span class="string">	&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        定义模型的前向传播过程，并将输出转换为浮点类型。</span></span><br><span class="line"><span class="string">        :param x: (Tensor): 输入张量，类型不受限。</span></span><br><span class="line"><span class="string">        :return: Tensor: 经过模型前向传播后的输出张量，转换为torch.float32类型。</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 调用父类的forward方法进行前向传播，然后将输出转换为torch.float32类型</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>().forward(x).to(torch.float32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">second2time</span>(<span class="params">seconds: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    将秒转换成时分秒。</span></span><br><span class="line"><span class="string">    :param seconds: (int): 需要转换的秒数。</span></span><br><span class="line"><span class="string">    :return: str: 转换后的小时、分钟和秒，以字符串形式返回。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 将秒数转换为分钟和秒</span></span><br><span class="line">    m, s = <span class="built_in">divmod</span>(seconds, <span class="number">60</span>)</span><br><span class="line">    <span class="comment"># 打印中间结果，分钟数和秒数</span></span><br><span class="line">    <span class="comment"># print(f&#x27;m--&gt;&#123;m&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># print(f&#x27;s--&gt;&#123;s&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># 将分钟数转换为小时和分钟</span></span><br><span class="line">    h, m = <span class="built_in">divmod</span>(m, <span class="number">60</span>)</span><br><span class="line">    <span class="comment"># 打印中间结果，小时数和分钟数</span></span><br><span class="line">    <span class="comment"># print(f&#x27;h--&gt;&#123;h&#125;&#x27;)</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;m--&gt;<span class="subst">&#123;m&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="comment"># 返回格式化的小时、分钟和秒</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;%02d:%02d:%02d&quot;</span> % (h, m, s)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_model</span>(<span class="params">model, cur_save_dir: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    存储当前模型。</span></span><br><span class="line"><span class="string">	该函数根据条件判断，要么将模型直接保存，要么在保存前将LoRA（Low-Rank Adaptation）参数与原始模型合并后再保存。</span></span><br><span class="line"><span class="string">	这样做是为了确保无论是原始模型还是使用LoRA训练的模型，都可以被正确地保存和后续使用。</span></span><br><span class="line"><span class="string">    :param model: 待保存的模型。这可以是任何已经训练好的transformers模型。</span></span><br><span class="line"><span class="string">    :param cur_save_dir: (str): 存储路径。表示模型将被保存到的目录路径。</span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 检查是否使用了LoRA（低秩适应）技术</span></span><br><span class="line">    <span class="keyword">if</span> pc.use_lora:  <span class="comment"># merge lora params with origin model</span></span><br><span class="line">        <span class="comment"># 如果使用了LoRA，首先创建模型的深拷贝，以避免修改原始模型</span></span><br><span class="line">        merged_model = copy.deepcopy(model)</span><br><span class="line">        <span class="comment"># 直接保存的话，只会保存adapter即LoRA模型的参数，因此需要合并后再保存</span></span><br><span class="line">        merged_model = merged_model.merge_and_unload()</span><br><span class="line">        <span class="comment"># 保存合并后的模型到指定路径</span></span><br><span class="line">        merged_model.save_pretrained(cur_save_dir)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 如果没有使用LoRA，直接保存模型到指定路径</span></span><br><span class="line">        model.save_pretrained(cur_save_dir)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="3-2-实现模型训练函数，验证函数"><a href="#3-2-实现模型训练函数，验证函数" class="headerlink" title="3.2. 实现模型训练函数，验证函数"></a>3.2. 实现模型训练函数，验证函数</h3><ul>
<li>目的：实现模型的训练和验证</li>
</ul>
<h4 id="优化点："><a href="#优化点：" class="headerlink" title="优化点："></a>优化点：</h4><p>&#x3D;&#x3D;优化点1：&#x3D;&#x3D;</p>
<p>model.config.use_cache &#x3D; False</p>
<p>含义：关闭模型使用 past key&#x2F;values（也叫 KV cache、attention cache）来重用之前层的注意力键值对。</p>
<p>效果：在训练时通常将其设为 <code>False</code>（尤其在启用 gradient checkpointing 时），因为缓存与 checkpointing 在某些实现上不兼容，会导致错误或额外内存&#x2F;计算问题。把它设为 <code>False</code> 可以避免相关冲突。并且现在不再进行缓存，可以降低显存的占用。</p>
<p><strong>在训练结束、用于部署&#x2F;推理时应把 <code>use_cache</code> 恢复为 <code>True</code> 以利用 KV 缓存加速。</strong></p>
<p>&#x3D;&#x3D;优化点2：&#x3D;&#x3D;</p>
<p>model.gradient_checkpointing_enable()</p>
<p>含义：开启&#x3D;&#x3D;梯度检查点&#x3D;&#x3D;。这是一个以<strong>牺牲计算时间换取显存</strong>的优化：前向时只保存一部分激活（checkpoints），在反向传播时对未保存的部分重新做一次（或多次）前向计算以得到梯度。</p>
<p>效果：&#x3D;&#x3D;显存减低，训练速度变慢。&#x3D;&#x3D;</p>
<p>&#x3D;&#x3D;优化点3：&#x3D;&#x3D;</p>
<p>model.enable_input_require_grads()</p>
<p>含义：允许把梯度“传到”输入层或做对输入嵌入的直接优化（例如 prompt tuning、微调 embedding、或某些 adapter&#x2F;PEFT 的实现里需要）。</p>
<p>&#x3D;&#x3D;优化点4：&#x3D;&#x3D;</p>
<p>直接降低预训练模型的精度：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model.half()将模型数据类型从默认的float32精度转换为更低的float16精度，减少内存</span></span><br><span class="line">model = model.half()</span><br></pre></td></tr></table></figure>

<p>混合精度训练：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># autocast是PyTorch中一种混合精度的技术，可在保持数值精度的情况下提高训练速度和减少显存占用。</span></span><br><span class="line"><span class="comment"># 该方法混合精度训练，如果在CPU环境中不起任何作用</span></span><br><span class="line"><span class="keyword">from</span> torch.cuda.amp <span class="keyword">import</span> autocast <span class="keyword">as</span> autocast</span><br><span class="line"> <span class="keyword">with</span> autocast():</span><br><span class="line">                    loss = model.forward(</span><br><span class="line">                        input_ids=batch[<span class="string">&#x27;input_ids&#x27;</span>].to(dtype=torch.long, device=pc.device),</span><br><span class="line">                        labels=batch[<span class="string">&#x27;labels&#x27;</span>].to(dtype=torch.long, device=pc.device)</span><br><span class="line">                    ).loss</span><br></pre></td></tr></table></figure>

<h4 id="代码："><a href="#代码：" class="headerlink" title="代码："></a>代码：</h4><ul>
<li><p>代码路径：llm_tuning&#x2F;ptune_chatglm&#x2F;train.py</p>
</li>
<li><p>脚本里面包含两个函数：model2train()和evaluate_model()</p>
<p>代码如下：</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">project_root = os.path.join(os.path.dirname(os.path.abspath(__file__)), <span class="string">&#x27;../&#x27;</span>)</span><br><span class="line"><span class="comment"># print(f&#x27;project_root--&gt;&#123;project_root&#125;&#x27;)</span></span><br><span class="line">sys.path.append(project_root)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> peft</span><br><span class="line"><span class="comment"># autocast是PyTorch中一种混合精度的技术，可在保持数值精度的情况下提高训练速度和减少显存占用。</span></span><br><span class="line"><span class="comment"># 该方法混合精度训练，如果在CPU环境中不起任何作用</span></span><br><span class="line"><span class="keyword">from</span> torch.cuda.amp <span class="keyword">import</span> autocast <span class="keyword">as</span> autocast</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoConfig, AutoModel, get_scheduler</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> ptune_chatglm.data_handle.data_loader <span class="keyword">import</span> get_data</span><br><span class="line"><span class="keyword">from</span> ptune_chatglm.glm_config <span class="keyword">import</span> ProjectConfig</span><br><span class="line"><span class="keyword">from</span> ptune_chatglm.utils.common_utils <span class="keyword">import</span> CastOutputToFloat, second2time, save_model</span><br><span class="line"></span><br><span class="line">pc = ProjectConfig()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">model2train</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    训练模型的主要函数。本函数完成从模型配置、数据加载到训练和评估的全过程。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1.获取训练和验证数据加载器</span></span><br><span class="line">    train_dataloader, dev_dataloader = get_data()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.加载模型</span></span><br><span class="line">    <span class="comment"># 加载预训练模型的配置</span></span><br><span class="line">    config = AutoConfig.from_pretrained(pc.pre_model, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># print(f&#x27;config--&gt;&#123;config&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果使用ptuning微调手段</span></span><br><span class="line">    <span class="keyword">if</span> pc.use_ptuning:</span><br><span class="line">        <span class="comment"># 设置前缀序列长度</span></span><br><span class="line">        config.pre_seq_len = pc.pre_seq_len</span><br><span class="line">        <span class="comment"># 可以指定是P-tuning-V1或者V2</span></span><br><span class="line">        config.prefix_projection = pc.prefix_projection</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载预训练模型ChatGLM-6B</span></span><br><span class="line">    model = AutoModel.from_pretrained(pc.pre_model,</span><br><span class="line">                                      config=config,</span><br><span class="line">                                      trust_remote_code=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;model--&gt;<span class="subst">&#123;model&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="comment"># for name, prameters in model.named_parameters():</span></span><br><span class="line">    <span class="comment">#     print(f&#x27;prameters类型--》&#123;prameters.dtype&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># model.half()将模型数据类型从默认的float32精度转换为更低的float16精度，减少内存</span></span><br><span class="line">    model = model.half()</span><br><span class="line">    <span class="comment"># print(model)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 不进行缓存，减少内存</span></span><br><span class="line">    model.config.use_cache = <span class="literal">False</span></span><br><span class="line">    <span class="comment"># 梯度检查点是一种优化技术，用于在反向传播过程中降低内存使用，保存部分激活值，未保存的反向传播时重新计算</span></span><br><span class="line">    model.gradient_checkpointing_enable()</span><br><span class="line">    <span class="comment"># 对输入层进行require_grads（进行参数更新，即微调）</span></span><br><span class="line">    model.enable_input_require_grads()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># print(f&#x27;model.transformer.prefix_encoder--&gt;&#123;model.transformer.prefix_encoder&#125;&#x27;)</span></span><br><span class="line">    <span class="comment"># 如果pc对象的use_ptuning属性为真，则执行以下操作</span></span><br><span class="line">    <span class="keyword">if</span> pc.use_ptuning:</span><br><span class="line">        <span class="comment"># 将模型的transformer部分的prefix_encoder组件转换为float精度</span></span><br><span class="line">        model.transformer.prefix_encoder.<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果使用lora方法微调</span></span><br><span class="line">    <span class="keyword">if</span> pc.use_lora:</span><br><span class="line">        <span class="comment"># 将模型的输出头：数据类型转换为float32(确保)</span></span><br><span class="line">        model.lm_head = CastOutputToFloat(model.lm_head)</span><br><span class="line">        <span class="comment"># 定义LoRA配置</span></span><br><span class="line">        peft_config = peft.LoraConfig(</span><br><span class="line">            task_type=peft.TaskType.CAUSAL_LM,  <span class="comment"># 传统的语言模型</span></span><br><span class="line">            inference_mode=<span class="literal">False</span>,  <span class="comment"># 推理时为True，比如决定是否使用dropout</span></span><br><span class="line">            r=pc.lora_rank,  <span class="comment"># 低秩矩阵维度</span></span><br><span class="line">            lora_alpha=<span class="number">32</span>,  <span class="comment"># 缩放系数</span></span><br><span class="line">            lora_dropout=<span class="number">0.1</span></span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># print(f&#x27;peft_config--》&#123;peft_config&#125;&#x27;)</span></span><br><span class="line">        <span class="comment"># 根据LoRA配置获取LoRA模型</span></span><br><span class="line">        model = peft.get_peft_model(model, peft_config)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># print(&#x27;*&#x27;*80)</span></span><br><span class="line">    <span class="comment"># 将模型移动到指定设备</span></span><br><span class="line">    model = model.to(pc.device)</span><br><span class="line">    <span class="comment"># 打印模型中所有可训练参数的信息</span></span><br><span class="line">    model.print_trainable_parameters()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义不需要权重衰减的参数名称列表</span></span><br><span class="line">    no_decay = [<span class="string">&quot;bias&quot;</span>, <span class="string">&quot;LayerNorm.weight&quot;</span>]</span><br><span class="line">    <span class="comment"># 初始化优化器参数分组，对模型中的参数进行精细控制的优化处理</span></span><br><span class="line">    optimizer_grouped_parameters = [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment"># 分组1：包含所有适用权重衰减的参数</span></span><br><span class="line">            <span class="string">&quot;params&quot;</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> model.named_parameters() <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">any</span>(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)],</span><br><span class="line">            <span class="string">&quot;weight_decay&quot;</span>: pc.weight_decay,  <span class="comment"># 适用预设的权重衰减率</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment"># 分组2：包含所有不适用权重衰减的参数</span></span><br><span class="line">            <span class="string">&quot;params&quot;</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> model.named_parameters() <span class="keyword">if</span> <span class="built_in">any</span>(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)],</span><br><span class="line">            <span class="string">&quot;weight_decay&quot;</span>: <span class="number">0.0</span>,  <span class="comment"># 不适用权重衰减</span></span><br><span class="line">        &#125;,</span><br><span class="line">    ]</span><br><span class="line">    <span class="comment"># 初始化AdamW优化器</span></span><br><span class="line">    optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=pc.learning_rate)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据训练轮数计算最大训练步数，以便于scheduler动态调整lr</span></span><br><span class="line">    num_update_steps_per_epoch = <span class="built_in">len</span>(train_dataloader)</span><br><span class="line">    <span class="comment"># 指定总的训练步数，它会被学习率调度器用来确定学习率的变化规律，确保学习率在整个训练过程中得以合理地调节</span></span><br><span class="line">    max_train_steps = pc.epochs * num_update_steps_per_epoch</span><br><span class="line">    <span class="comment"># 预热阶段的训练步数</span></span><br><span class="line">    warm_steps = <span class="built_in">int</span>(pc.warmup_ratio * max_train_steps)</span><br><span class="line">    <span class="comment"># 初始化学习率调度器</span></span><br><span class="line">    lr_scheduler = get_scheduler(</span><br><span class="line">        name=<span class="string">&#x27;linear&#x27;</span>,</span><br><span class="line">        optimizer=optimizer,</span><br><span class="line">        num_warmup_steps=warm_steps,</span><br><span class="line">        num_training_steps=max_train_steps,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.定义训练的一些参数变量</span></span><br><span class="line">    loss_list = []</span><br><span class="line">    tic_train = time.time()</span><br><span class="line">    global_step, best_eval_loss = <span class="number">0</span>, <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">    <span class="comment"># 4.开始训练循环</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, pc.epochs + <span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始训练&quot;</span>)</span><br><span class="line">        model.train()</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> train_dataloader:</span><br><span class="line">            <span class="keyword">if</span> pc.use_lora:</span><br><span class="line">                <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">                torch.cuda.amp.autocast是PyTorch中一种混合精度的技术（仅在GPU上训练时可使用）</span></span><br><span class="line"><span class="string">                混合精度训练主要涉及16位浮点数（FP16）和32位浮点数（FP32）的组合使用：</span></span><br><span class="line"><span class="string">                FP16：提供更高的计算速度和更低的内存使用，但是由于其表示范围较小，可能会导致数值不稳定或溢出。</span></span><br><span class="line"><span class="string">                FP32：用于保持数值稳定性，尤其是在权重更新阶段。</span></span><br><span class="line"><span class="string">                &quot;&quot;&quot;</span></span><br><span class="line">                <span class="keyword">with</span> autocast():</span><br><span class="line">                    loss = model(</span><br><span class="line">                        input_ids=batch[<span class="string">&#x27;input_ids&#x27;</span>].to(dtype=torch.long, device=pc.device),</span><br><span class="line">                        labels=batch[<span class="string">&#x27;labels&#x27;</span>].to(dtype=torch.long, device=pc.device)</span><br><span class="line">                    ).loss</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                loss = model(</span><br><span class="line">                    input_ids=batch[<span class="string">&#x27;input_ids&#x27;</span>].to(dtype=torch.long, device=pc.device),</span><br><span class="line">                    labels=batch[<span class="string">&#x27;labels&#x27;</span>].to(dtype=torch.long, device=pc.device)</span><br><span class="line">                ).loss</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 梯度清零</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            <span class="comment"># 反向传播</span></span><br><span class="line">            loss.backward()</span><br><span class="line">            <span class="comment"># 梯度更新</span></span><br><span class="line">            optimizer.step()</span><br><span class="line">            <span class="comment"># 更新学习率</span></span><br><span class="line">            lr_scheduler.step()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            loss_list.append(<span class="built_in">float</span>(loss.cpu().detach()))</span><br><span class="line">            global_step += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> global_step % pc.logging_steps == <span class="number">0</span>:</span><br><span class="line">                time_diff = time.time() - tic_train</span><br><span class="line">                loss_avg = <span class="built_in">sum</span>(loss_list) / <span class="built_in">len</span>(loss_list)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;全局步骤 %d ( %02.2f%% ) , 轮次: %d, 损失: %.5f, 速度: %.2f step/s, ETA: %s&quot;</span></span><br><span class="line">                      % (</span><br><span class="line">                          global_step,</span><br><span class="line">                          global_step / max_train_steps * <span class="number">100</span>,</span><br><span class="line">                          epoch,</span><br><span class="line">                          loss_avg,</span><br><span class="line">                          pc.logging_steps / time_diff,</span><br><span class="line">                          second2time(<span class="built_in">int</span>(max_train_steps - global_step) / (pc.logging_steps / time_diff))</span><br><span class="line">                      ))</span><br><span class="line">                tic_train = time.time()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># cur_save_dir = os.path.join(pc.save_dir, &quot;model_%d&quot; % global_step)</span></span><br><span class="line">        <span class="comment"># save_model(model, cur_save_dir)</span></span><br><span class="line">        <span class="comment"># print(f&#x27;Model has saved at &#123;cur_save_dir&#125;.&#x27;)</span></span><br><span class="line">        eval_loss = evaluate_model(model, dev_dataloader)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;评估集的损失为: %.5f&quot;</span> % (eval_loss))</span><br><span class="line">        <span class="keyword">if</span> eval_loss &lt; best_eval_loss:</span><br><span class="line">            <span class="built_in">print</span>(</span><br><span class="line">                <span class="string">f&quot;最小的损失已经更新：: <span class="subst">&#123;best_eval_loss:<span class="number">.5</span>f&#125;</span> --&gt; <span class="subst">&#123;eval_loss:<span class="number">.5</span>f&#125;</span>&quot;</span></span><br><span class="line">            )</span><br><span class="line">            best_eval_loss = eval_loss</span><br><span class="line">            cur_save_dir = os.path.join(pc.save_dir, <span class="string">&quot;model_best&quot;</span>)</span><br><span class="line">            save_model(model, cur_save_dir)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;最好的模型已经保存在： <span class="subst">&#123;cur_save_dir&#125;</span>.&#x27;</span>)</span><br><span class="line">        tic_train = time.time()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate_model</span>(<span class="params">model, dev_dataloader</span>):</span><br><span class="line">    <span class="comment"># 将模型设置为评估模式，以便在验证时不进行梯度更新</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化一个空列表来存储每个batch的loss值</span></span><br><span class="line">    loss_list = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在torch.no_grad()上下文中禁用梯度计算，以减少内存消耗和加快计算速度</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment"># 遍历验证数据加载器中的每个batch</span></span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> dev_dataloader:</span><br><span class="line">            <span class="comment"># 如果使用了LoRA（Low-Rank Adaptation）技术</span></span><br><span class="line">            <span class="keyword">if</span> pc.use_lora:</span><br><span class="line">                <span class="comment"># 使用autocast()自动混合精度训练，以提高效率和减少内存消耗</span></span><br><span class="line">                <span class="keyword">with</span> autocast():</span><br><span class="line">                    <span class="comment"># 进行模型前向传播并计算loss</span></span><br><span class="line">                    loss = model(</span><br><span class="line">                        input_ids=batch[<span class="string">&#x27;input_ids&#x27;</span>].to(dtype=torch.long, device=pc.device),</span><br><span class="line">                        labels=batch[<span class="string">&#x27;labels&#x27;</span>].to(dtype=torch.long, device=pc.device)</span><br><span class="line">                    ).loss</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 如果不使用LoRA，直接进行模型前向传播并计算loss</span></span><br><span class="line">                loss = model(</span><br><span class="line">                    input_ids=batch[<span class="string">&#x27;input_ids&#x27;</span>].to(dtype=torch.long, device=pc.device),</span><br><span class="line">                    labels=batch[<span class="string">&#x27;labels&#x27;</span>].to(dtype=torch.long, device=pc.device)</span><br><span class="line">                ).loss</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 将计算得到的loss值从GPU转移到CPU，并 detach 以释放计算图，防止内存泄漏</span></span><br><span class="line">            <span class="comment"># 然后将其作为浮点数添加到loss列表中</span></span><br><span class="line">            loss_list.append(<span class="built_in">float</span>(loss.cpu().detach()))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回平均loss值，即loss列表的总和除以loss的数量</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>(loss_list) / <span class="built_in">len</span>(loss_list)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    model2train()</span><br></pre></td></tr></table></figure>

<hr>
<ul>
<li>输出结果:</li>
</ul>
<div align=center><img src="./img/7-1-4.png" style="zoom:60%" ><img/></div>

<hr>
<h3 id="3-3-实现模型预测函数"><a href="#3-3-实现模型预测函数" class="headerlink" title="3.3. 实现模型预测函数"></a>3.3. 实现模型预测函数</h3><ul>
<li>目的：加载训练好的模型并测试效果</li>
</ul>
<h4 id="优化点：-1"><a href="#优化点：-1" class="headerlink" title="优化点："></a>优化点：</h4><ul>
<li>优化点：&#x3D;&#x3D;model.generate()与model()的区别&#x3D;&#x3D;</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">out = model.generate(</span><br><span class="line">            input_ids=batch[<span class="string">&quot;input_ids&quot;</span>].to(pc.device),</span><br><span class="line">            max_new_tokens=max_new_tokens,</span><br><span class="line">            temperature=<span class="number">0</span></span><br><span class="line">        )</span><br><span class="line">        out_text = tokenizer.decode(out[<span class="number">0</span>])</span><br><span class="line">        answer = out_text.split(<span class="string">&#x27;Answer: &#x27;</span>)[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model()</span><br></pre></td></tr></table></figure>

<ul>
<li><p>是<strong>一次前向（forward）调用</strong>，返回 <code>logits</code>（和 <code>past_key_values</code>、隐藏态等），不会自动做循环解码。</p>
</li>
<li><p>适合：你想自定义解码策略（自写采样、温度、惩罚、约束），或做单步推理 &#x2F; 获取中间 logits &#x2F; 做梯度计算（训练）时。</p>
</li>
<li><p>需要你自己管理：循环、<code>past_key_values</code>（KV cache）、终止条件、token 拼接等。</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.generate()</span><br></pre></td></tr></table></figure>

<ul>
<li><p>是 Hugging Face Transformers 提供的<strong>高层生成接口</strong>：它会自动运行解码循环（greedy &#x2F; beam &#x2F; top-k &#x2F; top-p &#x2F; sampling 等），管理 <code>past_key_values</code>、<code>attention_mask</code>、<code>eos</code> 停止、重复惩罚、长度限制等。</p>
</li>
<li><p>适合：你要快速得到文本输出，且常见的生成选项（temperature、max_new_tokens、do_sample、num_beams…）已经够用。</p>
<p>其中在 <code>generate(..., temperature=0)</code> 下，transformers 会把采样方式切为<strong>贪心（greedy）</strong>，即每步取概率最大的 token（等同于 <code>argmax</code>）。如果你用 <code>model()</code> 自己实现，也需要在 logits 上做 <code>argmax</code> 来实现相同行为；若 <code>temperature&gt;0</code>，你需要做 softmax + multinomial 来采样。</p>
</li>
<li><p>更简洁、安全、通常更快（内部有优化），并且处理好很多边界情况。</p>
</li>
</ul>
<h4 id="代码：-1"><a href="#代码：-1" class="headerlink" title="代码："></a>代码：</h4><ul>
<li>代码路径：llm_tuning&#x2F;prompt_tasks&#x2F;ptune_chatglm&#x2F;inference.py</li>
</ul>
<p>​	   具体代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">project_root = os.path.join(os.path.dirname(os.path.abspath(__file__)), <span class="string">&#x27;../&#x27;</span>)</span><br><span class="line"><span class="comment"># print(f&#x27;project_root--&gt;&#123;project_root&#125;&#x27;)</span></span><br><span class="line">sys.path.append(project_root)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> ptune_chatglm.glm_config <span class="keyword">import</span> ProjectConfig</span><br><span class="line"></span><br><span class="line">pc = ProjectConfig()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">inference</span>(<span class="params">model, tokenizer, instuction: <span class="built_in">str</span>, sentence: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        input_text = <span class="string">f&quot;Instruction: <span class="subst">&#123;instuction&#125;</span>\n&quot;</span></span><br><span class="line">        <span class="keyword">if</span> sentence:</span><br><span class="line">            input_text += <span class="string">f&quot;Input: <span class="subst">&#123;sentence&#125;</span>\n&quot;</span></span><br><span class="line">        input_text += <span class="string">f&quot;Answer: &quot;</span></span><br><span class="line">        batch = tokenizer(input_text, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">        <span class="comment"># 直接调用模型的generate方法，获取模型预测结果</span></span><br><span class="line">        out = model.generate(</span><br><span class="line">            input_ids=batch[<span class="string">&quot;input_ids&quot;</span>].to(pc.device),</span><br><span class="line">            max_new_tokens=max_new_tokens,</span><br><span class="line">            temperature=<span class="number">0</span></span><br><span class="line">        )</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;out--&gt;<span class="subst">&#123;out&#125;</span>&#x27;</span>)</span><br><span class="line">        out_text = tokenizer.decode(out[<span class="number">0</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;out_text--&gt;<span class="subst">&#123;out_text&#125;</span>&#x27;</span>)</span><br><span class="line">        answer = out_text.split(<span class="string">&#x27;Answer: &#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> answer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    max_new_tokens = <span class="number">300</span></span><br><span class="line">    model_path = os.path.join(pc.save_dir, <span class="string">&#x27;model_best&#x27;</span>)</span><br><span class="line">    tokenizer = AutoTokenizer.from_pretrained(</span><br><span class="line">        model_path,</span><br><span class="line">        trust_remote_code=<span class="literal">True</span></span><br><span class="line">    )</span><br><span class="line">    model = AutoModel.from_pretrained(</span><br><span class="line">        model_path,</span><br><span class="line">        trust_remote_code=<span class="literal">True</span></span><br><span class="line">    ).half().to(pc.device)</span><br><span class="line"></span><br><span class="line">    samples = [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&#x27;instruction&#x27;</span>: <span class="string">&quot;现在你是一个非常厉害的SPO抽取器。&quot;</span>,</span><br><span class="line">            <span class="string">&quot;input&quot;</span>: <span class="string">&quot;下面这句中包含了哪些三元组，用json列表的形式回答，不要输出除json外的其他答案。\n\n73获奖记录人物评价：黄磊是一个特别幸运的演员，拍第一部戏就碰到了导演陈凯歌，而且在他的下一部电影《夜半歌声》中演对手戏的张国荣、吴倩莲、黎明等都是著名的港台演员。&quot;</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&#x27;instruction&#x27;</span>: <span class="string">&quot;你现在是一个很厉害的阅读理解器，严格按照人类指令进行回答。&quot;</span>,</span><br><span class="line">            <span class="string">&quot;input&quot;</span>: <span class="string">&quot;下面子中的主语是什么类别，输出成列表形式。\n\n第N次入住了，就是方便去客户那里哈哈。还有啥说的&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    start = time.time()</span><br><span class="line">    <span class="keyword">for</span> i, sample <span class="keyword">in</span> <span class="built_in">enumerate</span>(samples):</span><br><span class="line">        res = inference(</span><br><span class="line">            model,</span><br><span class="line">            tokenizer,</span><br><span class="line">            sample[<span class="string">&#x27;instruction&#x27;</span>],</span><br><span class="line">            sample[<span class="string">&#x27;input&#x27;</span>]</span><br><span class="line">        )</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;res <span class="subst">&#123;i&#125;</span>: &#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(res)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Used <span class="subst">&#123;<span class="built_in">round</span>(time.time() - start, <span class="number">2</span>)&#125;</span>s.&#x27;</span>)</span><br></pre></td></tr></table></figure>

</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="https://liamjohnson-w.github.io">李俊泽</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://liamjohnson-w.github.io/2025/11/02/Fine-Tuning/">https://liamjohnson-w.github.io/2025/11/02/Fine-Tuning/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/AI/">AI</a></div><div class="post_share"><div class="social-share" data-image="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/pusheen11121.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> Donate</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2025/10/30/Agent_all/" title="Agent"><img class="cover" src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/Pusheen12222.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Agent</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2025/06/03/2025.06.03/" title="OLLAMA"><img class="cover" src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250603132906789.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-03</div><div class="title">OLLAMA</div></div></a></div><div><a href="/2025/10/25/Agent/" title="Agent-Note"><img class="cover" src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/Pusheen1121.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-25</div><div class="title">Agent-Note</div></div></a></div><div><a href="/2025/10/30/Agent_all/" title="Agent"><img class="cover" src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/Pusheen12222.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-30</div><div class="title">Agent</div></div></a></div><div><a href="/2025/06/22/NLP_Base/" title="NLP自然语言处理"><img class="cover" src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/%E7%94%9F%E6%88%90%E7%8C%AB%E5%92%AA%E5%9B%BE%E7%89%87%20(2).png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-22</div><div class="title">NLP自然语言处理</div></div></a></div><div><a href="/2025/07/18/Project/" title="Jason Project Demo"><img class="cover" src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/pusheen1.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="title">Jason Project Demo</div></div></a></div><div><a href="/2025/09/28/LLM_Base/" title="LLM大模型基础"><img class="cover" src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/pusheen112.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-28</div><div class="title">LLM大模型基础</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/tx.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">李俊泽</div><div class="author-info__description">机器都在学习,你有什么理由不学习?</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">240</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">58</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/weiswift/"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/weiswift" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:1265019024@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">博客为本人搭建 Github托管 仅记录学习过程 不做引流 不做排名 不打广告！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#P01-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E7%9A%84%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F%E3%80%90%E6%8E%8C%E6%8F%A1%E3%80%91"><span class="toc-number">1.</span> <span class="toc-text">P01_大模型微调的主要方式【掌握】</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1%E3%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%96%B9%E6%B3%95"><span class="toc-number">1.1.</span> <span class="toc-text">1、大模型Prompt-Tuning方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-NLP%E4%BB%BB%E5%8A%A1%E5%9B%9B%E7%A7%8D%E8%8C%83%E5%BC%8F"><span class="toc-number">1.1.1.</span> <span class="toc-text">1.1 NLP任务四种范式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-Fine-Tuning-%E5%BE%AE%E8%B0%83"><span class="toc-number">1.1.2.</span> <span class="toc-text">1.2 Fine-Tuning(微调)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-Prompt-Tuning-%E6%8F%90%E7%A4%BA%E5%BE%AE%E8%B0%83"><span class="toc-number">1.1.3.</span> <span class="toc-text">1.3 Prompt-Tuning(提示微调)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-Prompt-Tuning%E6%8A%80%E6%9C%AF%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B"><span class="toc-number">1.1.4.</span> <span class="toc-text">1.4 Prompt-Tuning技术发展历程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-5-%E9%9D%A2%E5%90%91%E8%B6%85%E5%A4%A7%E8%A7%84%E6%A8%A1%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84Prompt-Tuning"><span class="toc-number">1.1.5.</span> <span class="toc-text">1.5 面向超大规模语言模型的Prompt-Tuning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-6-%E9%9D%A2%E5%90%91%E5%B0%8F%E8%A7%84%E6%A8%A1%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84Prompt-Tuning"><span class="toc-number">1.1.6.</span> <span class="toc-text">1.6 面向小规模语言模型的Prompt-Tuning</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-6-1-Prompt-Tuning%E7%9A%84%E9%BC%BB%E7%A5%96%E2%80%94PET%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.6.1.</span> <span class="toc-text">1.6.1 Prompt-Tuning的鼻祖—PET模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-6-2-Prompt-Oriented-Fine-Tuning"><span class="toc-number">1.1.6.2.</span> <span class="toc-text">1.6.2 Prompt-Oriented Fine-Tuning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-6-3-Soft-Prompt%E5%8F%8A%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95"><span class="toc-number">1.1.6.3.</span> <span class="toc-text">1.6.3 Soft Prompt及微调方法</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-6-3-1-%E8%BF%9E%E7%BB%AD%E6%8F%90%E7%A4%BA%E6%A8%A1%E6%9D%BF"><span class="toc-number">1.1.6.3.1.</span> <span class="toc-text">1.6.3.1 连续提示模板</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-6-3-2-Prompt-Tuning%EF%BC%88NLG%E4%BB%BB%E5%8A%A1%EF%BC%89"><span class="toc-number">1.1.6.3.2.</span> <span class="toc-text">1.6.3.2 Prompt Tuning（NLG任务）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-6-3-3-P-tuning%EF%BC%88NLU%E4%BB%BB%E5%8A%A1%EF%BC%89"><span class="toc-number">1.1.6.3.3.</span> <span class="toc-text">1.6.3.3 P-tuning（NLU任务）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-6-3-4-PPT%EF%BC%88Pre-trained-Prompt-Tuning%EF%BC%89"><span class="toc-number">1.1.6.3.4.</span> <span class="toc-text">1.6.3.4 PPT（Pre-trained Prompt Tuning）</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2%E3%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8BPEFT%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95%E3%80%90%E6%8E%8C%E6%8F%A1%E3%80%91"><span class="toc-number">1.2.</span> <span class="toc-text">2、大模型PEFT微调方法【掌握】</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-Prefix-Tuning"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.1 Prefix Tuning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-Adapter-Tuning"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.2 Adapter Tuning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-LoRA"><span class="toc-number">1.2.3.</span> <span class="toc-text">2.3 LoRA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-QLoRA"><span class="toc-number">1.2.4.</span> <span class="toc-text">2.4 QLoRA</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8EGPT2%E7%9A%84%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA"><span class="toc-number">2.</span> <span class="toc-text">基于GPT2的医疗问诊机器人</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E7%9B%AE%E6%A0%87"><span class="toc-number">2.1.</span> <span class="toc-text">学习目标</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.2.</span> <span class="toc-text">1. 项目介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF"><span class="toc-number">2.2.1.</span> <span class="toc-text">1.1 项目背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="toc-number">2.2.2.</span> <span class="toc-text">1.2 环境准备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-%E9%A1%B9%E7%9B%AE%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84"><span class="toc-number">2.2.3.</span> <span class="toc-text">1.3 项目整体结构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="toc-number">2.3.</span> <span class="toc-text">2. 数据处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E6%95%B0%E6%8D%AE%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.3.1.</span> <span class="toc-text">2.1 数据介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="toc-number">2.3.2.</span> <span class="toc-text">2.2 数据处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-1-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">2.3.2.1.</span> <span class="toc-text">2.2.1 配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-1-%E6%95%B0%E6%8D%AE%E5%BC%A0%E9%87%8F%E8%BD%AC%E6%8D%A2"><span class="toc-number">2.3.2.2.</span> <span class="toc-text">2.2.1 数据张量转换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-2-%E8%8E%B7%E5%8F%96dataloader"><span class="toc-number">2.3.2.3.</span> <span class="toc-text">2.2.2 获取dataloader</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%881%EF%BC%89%E5%B0%81%E8%A3%85Dataset%E5%AF%B9%E8%B1%A1"><span class="toc-number">2.3.2.3.1.</span> <span class="toc-text">（1）封装Dataset对象</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%882%EF%BC%89%E5%B0%81%E8%A3%85DataLoader%E5%AF%B9%E8%B1%A1"><span class="toc-number">2.3.2.3.2.</span> <span class="toc-text">（2）封装DataLoader对象</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA"><span class="toc-number">2.4.</span> <span class="toc-text">3. 模型搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.4.1.</span> <span class="toc-text">3.1 模型架构介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-GPT2%E6%A8%A1%E5%9E%8B%E5%87%86%E5%A4%87"><span class="toc-number">2.4.2.</span> <span class="toc-text">3.2 GPT2模型准备</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%92%8C%E9%AA%8C%E8%AF%81"><span class="toc-number">2.5.</span> <span class="toc-text">4. 模型训练和验证</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.5.1.</span> <span class="toc-text">代码介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E4%BD%8D%E7%BD%AE"><span class="toc-number">2.5.2.</span> <span class="toc-text">代码位置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%B0%83%E7%94%A8"><span class="toc-number">2.5.3.</span> <span class="toc-text">模型调用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7"><span class="toc-number">2.5.4.</span> <span class="toc-text">训练技巧</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#trian-py%E4%BB%A3%E7%A0%81"><span class="toc-number">2.5.5.</span> <span class="toc-text">trian.py代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A1%A5%E5%85%85%E7%9F%A5%E8%AF%86%E7%82%B9"><span class="toc-number">2.5.6.</span> <span class="toc-text">补充知识点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#functions-tools-py%E4%BB%A3%E7%A0%81"><span class="toc-number">2.5.7.</span> <span class="toc-text">functions_tools.py代码</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%EF%BC%88%E4%BA%BA%E6%9C%BA%E4%BA%A4%E4%BA%92%EF%BC%89"><span class="toc-number">2.6.</span> <span class="toc-text">5. 模型预测（人机交互）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E5%9F%BA%E4%BA%8EFlask%E6%A1%86%E6%9E%B6web%E5%BC%80%E5%8F%91-%E4%BA%86%E8%A7%A3"><span class="toc-number">2.7.</span> <span class="toc-text">6. 基于Flask框架web开发(了解)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#P03-%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F"><span class="toc-number">3.</span> <span class="toc-text">P03_新零售行业评价决策系统</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D%E3%80%90%E7%90%86%E8%A7%A3%E3%80%91"><span class="toc-number">3.1.</span> <span class="toc-text">一、项目介绍【理解】</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF"><span class="toc-number">3.1.1.</span> <span class="toc-text">1、项目背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E8%AF%84%E8%AE%BA%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95"><span class="toc-number">3.1.2.</span> <span class="toc-text">2、评论文本分类实现方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-%E4%BC%A0%E7%BB%9F%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95"><span class="toc-number">3.1.2.1.</span> <span class="toc-text">2.1 传统的深度学习方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95"><span class="toc-number">3.1.2.2.</span> <span class="toc-text">2.2 模型微调方法</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81BERT-PET%E6%96%B9%E5%BC%8F%E4%BB%8B%E7%BB%8D%E3%80%90%E7%90%86%E8%A7%A3%E3%80%91"><span class="toc-number">3.2.</span> <span class="toc-text">二、BERT+PET方式介绍【理解】</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81-PET%E5%9B%9E%E9%A1%BE"><span class="toc-number">3.2.1.</span> <span class="toc-text">1、&#x3D;&#x3D;PET回顾&#x3D;&#x3D;</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="toc-number">3.2.2.</span> <span class="toc-text">2、 环境准备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81%E9%A1%B9%E7%9B%AE%E6%9E%B6%E6%9E%84"><span class="toc-number">3.2.3.</span> <span class="toc-text">3、项目架构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81BERT-PET%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E3%80%90%E7%90%86%E8%A7%A3%E3%80%91"><span class="toc-number">3.3.</span> <span class="toc-text">三、BERT+PET方式数据预处理【理解】</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E6%9F%A5%E7%9C%8B%E9%A1%B9%E7%9B%AE%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.3.1.</span> <span class="toc-text">1、查看项目数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-train-txt"><span class="toc-number">3.3.1.1.</span> <span class="toc-text">1.1 train.txt</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-dev-txt"><span class="toc-number">3.3.1.2.</span> <span class="toc-text">1.2 dev.txt</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-prompt-txt"><span class="toc-number">3.3.1.3.</span> <span class="toc-text">1.3 prompt.txt</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-verbalizer-txt"><span class="toc-number">3.3.1.4.</span> <span class="toc-text">1.4 verbalizer.txt</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E7%BC%96%E5%86%99Config%E7%B1%BB%E9%A1%B9%E7%9B%AE%E6%96%87%E4%BB%B6%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%A0%81"><span class="toc-number">3.3.2.</span> <span class="toc-text">2、编写Config类项目文件配置代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81%E7%BC%96%E5%86%99%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%9B%B8%E5%85%B3%E4%BB%A3%E7%A0%81"><span class="toc-number">3.3.3.</span> <span class="toc-text">3、编写数据处理相关代码</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-template-py"><span class="toc-number">3.3.3.1.</span> <span class="toc-text">3.1 &#x3D;&#x3D;template.py&#x3D;&#x3D;</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-data-preprocess-py"><span class="toc-number">3.3.3.2.</span> <span class="toc-text">3.2 &#x3D;&#x3D;data_preprocess.py&#x3D;&#x3D;</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-data-loader-py"><span class="toc-number">3.3.3.3.</span> <span class="toc-text">3.3 data_loader.py</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81PET%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E4%B8%8E%E8%AE%AD%E7%BB%83%E3%80%90%E5%AE%9E%E7%8E%B0%E3%80%91"><span class="toc-number">3.4.</span> <span class="toc-text">四、PET方式模型搭建与训练【实现】</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E5%AE%9E%E7%8E%B0%E6%A8%A1%E5%9E%8B%E5%B7%A5%E5%85%B7%E7%B1%BB%E5%87%BD%E6%95%B0"><span class="toc-number">3.4.1.</span> <span class="toc-text">1、实现模型工具类函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-verbalizer-py"><span class="toc-number">3.4.1.1.</span> <span class="toc-text">1.1 verbalizer.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-common-utils-py"><span class="toc-number">3.4.1.2.</span> <span class="toc-text">1.2 common_utils.py</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E8%AE%A1%E7%AE%97%E6%80%9D%E8%B7%AF-%EF%BC%9A"><span class="toc-number">3.4.1.2.1.</span> <span class="toc-text">&#x3D;&#x3D;损失计算思路&#x3D;&#x3D;：</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-metirc-utils-py"><span class="toc-number">3.4.1.3.</span> <span class="toc-text">1.3 metirc_utils.py</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E5%AE%9E%E7%8E%B0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%87%BD%E6%95%B0-%E9%AA%8C%E8%AF%81%E5%87%BD%E6%95%B0"><span class="toc-number">3.4.2.</span> <span class="toc-text">2、实现模型训练函数,验证函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81%E5%AE%9E%E7%8E%B0%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E5%87%BD%E6%95%B0"><span class="toc-number">3.4.3.</span> <span class="toc-text">3、实现模型预测函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81BERT-P-Tuning%E6%96%B9%E5%BC%8F%E4%BB%8B%E7%BB%8D%E3%80%90%E7%90%86%E8%A7%A3%E3%80%91"><span class="toc-number">3.5.</span> <span class="toc-text">五、BERT+P-Tuning方式介绍【理解】</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81P-Tuning%E5%9B%9E%E9%A1%BE"><span class="toc-number">3.5.1.</span> <span class="toc-text">1、P-Tuning回顾</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="toc-number">3.5.2.</span> <span class="toc-text">2、环境准备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81%E9%A1%B9%E7%9B%AE%E6%9E%B6%E6%9E%84-1"><span class="toc-number">3.5.3.</span> <span class="toc-text">3、项目架构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81BERT-P-Tuning%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E3%80%90%E7%90%86%E8%A7%A3%E3%80%91"><span class="toc-number">3.6.</span> <span class="toc-text">六、BERT+P-Tuning方式数据预处理【理解】</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E6%9F%A5%E7%9C%8B%E9%A1%B9%E7%9B%AE%E6%95%B0%E6%8D%AE%E9%9B%86-1"><span class="toc-number">3.6.1.</span> <span class="toc-text">1、查看项目数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-train-txt-1"><span class="toc-number">3.6.1.1.</span> <span class="toc-text">1.1 train.txt</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-dev-txt-1"><span class="toc-number">3.6.1.2.</span> <span class="toc-text">1.2 dev.txt</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-verbalizer-txt"><span class="toc-number">3.6.1.3.</span> <span class="toc-text">1.3 verbalizer.txt</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E7%BC%96%E5%86%99Config%E7%B1%BB%E9%A1%B9%E7%9B%AE%E6%96%87%E4%BB%B6%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%A0%81-1"><span class="toc-number">3.6.2.</span> <span class="toc-text">2、编写Config类项目文件配置代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81%E7%BC%96%E5%86%99%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%9B%B8%E5%85%B3%E4%BB%A3%E7%A0%81-1"><span class="toc-number">3.6.3.</span> <span class="toc-text">3、编写数据处理相关代码</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-data-preprocess-py"><span class="toc-number">3.6.3.1.</span> <span class="toc-text">3.1 data_preprocess.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-data-loader-py"><span class="toc-number">3.6.3.2.</span> <span class="toc-text">3.2 data_loader.py</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81BERT-P-Tuning%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E4%B8%8E%E8%AE%AD%E7%BB%83%E3%80%90%E5%AE%9E%E7%8E%B0%E3%80%91"><span class="toc-number">3.7.</span> <span class="toc-text">七、BERT+P-Tuning方式模型搭建与训练【实现】</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E5%AE%9E%E7%8E%B0%E6%A8%A1%E5%9E%8B%E5%B7%A5%E5%85%B7%E7%B1%BB%E5%87%BD%E6%95%B0-1"><span class="toc-number">3.7.1.</span> <span class="toc-text">1、实现模型工具类函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-verbalizer-py-1"><span class="toc-number">3.7.1.1.</span> <span class="toc-text">1.1 verbalizer.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-common-utils-py-1"><span class="toc-number">3.7.1.2.</span> <span class="toc-text">1.2 common_utils.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-metirc-utils-py-1"><span class="toc-number">3.7.1.3.</span> <span class="toc-text">1.3 metirc_utils.py</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E5%AE%9E%E7%8E%B0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%87%BD%E6%95%B0-%E9%AA%8C%E8%AF%81%E5%87%BD%E6%95%B0-1"><span class="toc-number">3.7.2.</span> <span class="toc-text">2、实现模型训练函数,验证函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81%E5%AE%9E%E7%8E%B0%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E5%87%BD%E6%95%B0-1"><span class="toc-number">3.7.3.</span> <span class="toc-text">3、实现模型预测函数</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#P04-%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98"><span class="toc-number">4.</span> <span class="toc-text">P04_基于ChatGLM微调多任务实战</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D%E3%80%90%E7%90%86%E8%A7%A3%E3%80%91"><span class="toc-number">4.1.</span> <span class="toc-text">1. 项目介绍【理解】</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E9%A1%B9%E7%9B%AE%E7%AE%80%E4%BB%8B"><span class="toc-number">4.1.1.</span> <span class="toc-text">1.1. 项目简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-ChatGLM-6B%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.1.2.</span> <span class="toc-text">1.2. ChatGLM-6B模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-1-%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D"><span class="toc-number">4.1.2.1.</span> <span class="toc-text">1.2.1 模型介绍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-2-%E6%A8%A1%E5%9E%8B%E9%85%8D%E7%BD%AE-6B"><span class="toc-number">4.1.2.2.</span> <span class="toc-text">1.2.2 模型配置(6B)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-3-%E7%A1%AC%E4%BB%B6%E8%A6%81%E6%B1%82-%E5%AE%98%E7%BD%91%E4%BB%8B%E7%BB%8D"><span class="toc-number">4.1.2.3.</span> <span class="toc-text">1.2.3 硬件要求(官网介绍)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-4-%E6%A8%A1%E5%9E%8B%E7%89%B9%E7%82%B9"><span class="toc-number">4.1.2.4.</span> <span class="toc-text">1.2.4 模型特点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE"><span class="toc-number">4.1.3.</span> <span class="toc-text">1.3. 环境配置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-1-%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%EF%BC%9A"><span class="toc-number">4.1.3.1.</span> <span class="toc-text">1.3.1 基础环境配置：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-2-%E5%AE%89%E8%A3%85%E4%BE%9D%E8%B5%96%E5%8C%85%EF%BC%9A"><span class="toc-number">4.1.3.2.</span> <span class="toc-text">1.3.2 安装依赖包：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-3-%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD%EF%BC%9A"><span class="toc-number">4.1.3.3.</span> <span class="toc-text">1.3.3 预训练模型下载：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-%E9%A1%B9%E7%9B%AE%E6%9E%B6%E6%9E%84"><span class="toc-number">4.1.4.</span> <span class="toc-text">1.4. 项目架构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E3%80%90%E6%8E%8C%E6%8F%A1%E3%80%91"><span class="toc-number">4.2.</span> <span class="toc-text">2.数据预处理【掌握】</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E6%9F%A5%E7%9C%8B%E9%A1%B9%E7%9B%AE%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">4.2.1.</span> <span class="toc-text">2.1 查看项目数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-1-train-jsonl"><span class="toc-number">4.2.1.1.</span> <span class="toc-text">2.1.1 train.jsonl</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-2-dev-jsonl"><span class="toc-number">4.2.1.2.</span> <span class="toc-text">2.1.2 dev.jsonl</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E7%BC%96%E5%86%99%E9%A1%B9%E7%9B%AEConfig%E7%B1%BB%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">4.2.2.</span> <span class="toc-text">2.2 编写项目Config类配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E7%BC%96%E5%86%99%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%9B%B8%E5%85%B3%E4%BB%A3%E7%A0%81"><span class="toc-number">4.2.3.</span> <span class="toc-text">2.3 编写数据处理相关代码</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-1-data-preprocess-py"><span class="toc-number">4.2.3.1.</span> <span class="toc-text">2.3.1 data_preprocess.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-2-data-loader-py"><span class="toc-number">4.2.3.2.</span> <span class="toc-text">2.3.2 data_loader.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-3-%E4%BB%A3%E7%A0%81%E4%B8%8A%E4%BC%A0"><span class="toc-number">4.2.3.3.</span> <span class="toc-text">2.3.3 代码上传</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E4%B8%8E%E8%AE%AD%E7%BB%83%E3%80%90%E6%8E%8C%E6%8F%A1%E3%80%91"><span class="toc-number">4.3.</span> <span class="toc-text">3.模型搭建与训练【掌握】</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-0-%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86"><span class="toc-number">4.3.1.</span> <span class="toc-text">3.0 前置知识</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E5%AE%9E%E7%8E%B0%E6%A8%A1%E5%9E%8B%E5%B7%A5%E5%85%B7%E7%B1%BB%E5%87%BD%E6%95%B0"><span class="toc-number">4.3.2.</span> <span class="toc-text">3.1. 实现模型工具类函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-1-common-utils-py"><span class="toc-number">4.3.2.1.</span> <span class="toc-text">3.1.1 common_utils.py</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E5%AE%9E%E7%8E%B0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%87%BD%E6%95%B0%EF%BC%8C%E9%AA%8C%E8%AF%81%E5%87%BD%E6%95%B0"><span class="toc-number">4.3.3.</span> <span class="toc-text">3.2. 实现模型训练函数，验证函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E7%82%B9%EF%BC%9A"><span class="toc-number">4.3.3.1.</span> <span class="toc-text">优化点：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%EF%BC%9A"><span class="toc-number">4.3.3.2.</span> <span class="toc-text">代码：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E5%AE%9E%E7%8E%B0%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E5%87%BD%E6%95%B0"><span class="toc-number">4.3.4.</span> <span class="toc-text">3.3. 实现模型预测函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E7%82%B9%EF%BC%9A-1"><span class="toc-number">4.3.4.1.</span> <span class="toc-text">优化点：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%EF%BC%9A-1"><span class="toc-number">4.3.4.2.</span> <span class="toc-text">代码：</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/11/02/Fine-Tuning/" title="Fine-Tuning"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/pusheen11121.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Fine-Tuning"/></a><div class="content"><a class="title" href="/2025/11/02/Fine-Tuning/" title="Fine-Tuning">Fine-Tuning</a><time datetime="2025-11-01T16:00:00.000Z" title="Created 2025-11-02 00:00:00">2025-11-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/10/30/Agent_all/" title="Agent"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/Pusheen12222.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Agent"/></a><div class="content"><a class="title" href="/2025/10/30/Agent_all/" title="Agent">Agent</a><time datetime="2025-10-29T16:00:00.000Z" title="Created 2025-10-30 00:00:00">2025-10-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/10/25/Agent/" title="Agent-Note"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/Pusheen1121.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Agent-Note"/></a><div class="content"><a class="title" href="/2025/10/25/Agent/" title="Agent-Note">Agent-Note</a><time datetime="2025-10-24T16:00:00.000Z" title="Created 2025-10-25 00:00:00">2025-10-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/10/21/RAG/" title="RAG"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/pusheen3.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="RAG"/></a><div class="content"><a class="title" href="/2025/10/21/RAG/" title="RAG">RAG</a><time datetime="2025-10-20T16:00:00.000Z" title="Created 2025-10-21 00:00:00">2025-10-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/28/LLM_Base/" title="LLM大模型基础"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/pusheen112.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LLM大模型基础"/></a><div class="content"><a class="title" href="/2025/09/28/LLM_Base/" title="LLM大模型基础">LLM大模型基础</a><time datetime="2025-09-27T16:00:00.000Z" title="Created 2025-09-28 00:00:00">2025-09-28</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By 李俊泽</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Welcome to 李俊泽 の <a target="_blank" rel="noopener" href="https://www.cnblogs.com/liam-sliversucks/">Blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? '' : ''

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div><canvas class="fireworks" mobile="true"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="true"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>