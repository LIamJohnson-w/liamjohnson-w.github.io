<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>机器学习 | SilverSucks</title><meta name="author" content="Johnson Liam"><meta name="copyright" content="Johnson Liam"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="AI人工智能 讲到AI人工智能首先得从图灵测试开始说起： 图灵测试就是：测试者与被测试者（一个人和一台机器）喘开的情况下，遍过一些装置（如键盘）向被测试者随意提问。多次测试（一般为5min之内），如果有超过30%的测试者不能确定被测试者是人还是机器，那么这台机器就通过了测试，并被认为具有人类智能。"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://github.com/weiswift/2025/06/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '机器学习',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-06-07 15:37:55'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"> <script src="/live2d-widget/autoload.js"></script><script src="/live2d-widget/autoload.js"> </script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/img/pic.webp" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">222</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">58</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Links</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-gamepad"></i><span> Games</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/mikutap/"><i class="fa-fw fa fa-music"></i><span> MikuTap 初音未来</span></a></li><li><a class="site-page child" href="/starbattle/"><i class="fa-fw fa fa-space-shuttle"></i><span> StartBattle 星际大战</span></a></li><li><a class="site-page child" href="/2048/"><i class="fa-fw fa fa-flag"></i><span> 2048 经典游戏</span></a></li><li><a class="site-page child" href="/battlecity/"><i class="fa-fw fa fa-arrow-circle-left"></i><span> BattleCity 坦克大战</span></a></li><li><a class="site-page child" href="/pacman/"><i class="fa-fw fa fa-bolt"></i><span> PacMan  吃豆人</span></a></li><li><a class="site-page child" href="/tetris/"><i class="fa-fw fa fa-arrows-alt"></i><span> Tetris 俄罗斯方块</span></a></li><li><a class="site-page child" href="/smallcat/"><i class="fa-fw fa fa-paw"></i><span> CatchCat 困住小猫</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-leaf"></i><span> Moments</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/diary/"><i class="fa-fw fas fa-bookmark"></i><span> Diary</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fa fa-hourglass-half"></i><span> Gallery</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-podcast"></i><span> More</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags标签</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About关于</span></a></li><li><a class="site-page child" href="/messageboard/"><i class="fa-fw fas fa-bookmark"></i><span> Messageboard留言板</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s1.ax1x.com/2023/04/18/p9i6u5D.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="SilverSucks"><span class="site-name">SilverSucks</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Links</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-gamepad"></i><span> Games</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/mikutap/"><i class="fa-fw fa fa-music"></i><span> MikuTap 初音未来</span></a></li><li><a class="site-page child" href="/starbattle/"><i class="fa-fw fa fa-space-shuttle"></i><span> StartBattle 星际大战</span></a></li><li><a class="site-page child" href="/2048/"><i class="fa-fw fa fa-flag"></i><span> 2048 经典游戏</span></a></li><li><a class="site-page child" href="/battlecity/"><i class="fa-fw fa fa-arrow-circle-left"></i><span> BattleCity 坦克大战</span></a></li><li><a class="site-page child" href="/pacman/"><i class="fa-fw fa fa-bolt"></i><span> PacMan  吃豆人</span></a></li><li><a class="site-page child" href="/tetris/"><i class="fa-fw fa fa-arrows-alt"></i><span> Tetris 俄罗斯方块</span></a></li><li><a class="site-page child" href="/smallcat/"><i class="fa-fw fa fa-paw"></i><span> CatchCat 困住小猫</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-leaf"></i><span> Moments</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/diary/"><i class="fa-fw fas fa-bookmark"></i><span> Diary</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fa fa-hourglass-half"></i><span> Gallery</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-podcast"></i><span> More</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags标签</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About关于</span></a></li><li><a class="site-page child" href="/messageboard/"><i class="fa-fw fas fa-bookmark"></i><span> Messageboard留言板</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">机器学习</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-06-03T16:00:00.000Z" title="Created 2025-06-04 00:00:00">2025-06-04</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-06-07T07:37:55.715Z" title="Updated 2025-06-07 15:37:55">2025-06-07</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="机器学习"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="AI人工智能"><a href="#AI人工智能" class="headerlink" title="AI人工智能"></a>AI人工智能</h1><blockquote>
<p>讲到AI人工智能首先得从<code>图灵测试</code>开始说起：</p>
<p>图灵测试就是：测试者与被测试者（一个人和一台机器）喘开的情况下，遍过一些装置（如键盘）向被测试者随意提问。<br>多次测试（一般为5min之内），如果有超过30%的测试者不能确定被测试者是人还是机器，那么这台机器就通过了测试，并被认为具有人类智能。</p>
<p><code>当有人骂你是人机的时候，你不要骂过去，你要说你还没通过图灵测试（这样别人就听不懂了doge）</code>。</p>
</blockquote>
<h2 id="人工智能的分类"><a href="#人工智能的分类" class="headerlink" title="人工智能的分类"></a>人工智能的分类</h2><p>通讯、感知与行动是现代人工智能的三个关键能力</p>
<p>与此对应的三个技术领域分别是</p>
<ul>
<li><code>计算机视觉（CV）</code><ul>
<li>计算机视觉（CV）是指机器感知环境的能力。这一技术类别中的经典任务有图像形成、图像处理、图像提取和图像的三维推理。物体检测和人脸识别是其比较成功的研究领域。</li>
</ul>
</li>
<li><code>自然语言处理（NLP）</code>:在NLP领域中，将覆盖文本挖掘&#x2F;分类、机器翻译和语音识别<ul>
<li>语音识别：是指识别语音（说出的语言）并将其转换成对应文本的技术。相反的任务（文本转语音&#x2F;TTS）也是这一领域内一个类似的研究主题。</li>
<li>文本挖掘：主要是指文本分类，该技术可用于理解、组织和分类结构化或非结构化文本文档。其涵盖的主要任务有句法分析、情绪分析和垃圾信息检测。</li>
<li>机器翻译（MT）：是利用机器的力量自动将一种自然语言（源语言）的文本翻译成另一种语言（目标语言）。</li>
</ul>
</li>
<li><code>机器人</code><ul>
<li>机器人学（Robotics）研究的是机器人的设计、制造、运作和应用，以及控制它们的计算机系统、传感反馈和信息处理。</li>
<li>机器人可以分成两大类：固定机器人和移动机器人。<ul>
<li>固定机器人通常被用于工业生产（比如用于装配线）。</li>
<li>常见的移动机器人应用有货运机器人、空中机器人和自动载具。机器人需要不同部件和系统的协作才能实现最优的作业。其中在硬件上包含传感器、反应器和控制器；另外还有能够实现感知能力的软件，比如定位、地图测绘和目标识别。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="机器学习基础"><a href="#机器学习基础" class="headerlink" title="机器学习基础"></a><font size=7 color='orange' face='华文楷体'>机器学习基础</font></h1><h2 id="机器学习的概念"><a href="#机器学习的概念" class="headerlink" title="机器学习的概念"></a>机器学习的概念</h2><p><code>机器学习是从数据中自动分析获得模型，并利用模型对未知数据进行预测</code></p>
<p>如下图所示：</p>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250605141520596.png" alt="image-20250605141520596"></p>
<h2 id="机器学习工作流程⭐️"><a href="#机器学习工作流程⭐️" class="headerlink" title="机器学习工作流程⭐️"></a><font size=5 color='red' face='华文楷体'>机器学习工作流程</font>⭐️</h2><ol>
<li><p>获取数据</p>
<ul>
<li>区分样本和特征</li>
<li>根据数据有无特征值和目标值区分第四步机器学习选择的算法：<ul>
<li>监督学习、无监督学习、强化学习、半监督学习算法</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>学习类型</th>
<th>In</th>
<th>Out</th>
<th>目的</th>
<th>案例</th>
</tr>
</thead>
<tbody><tr>
<td>监督学习（Supervised Learning）</td>
<td>有标签</td>
<td>有反馈</td>
<td>预测结果</td>
<td>猫狗分类、房价预测</td>
</tr>
<tr>
<td>无监督学习（Unsupervised Learning）</td>
<td>无标签</td>
<td>无反馈</td>
<td>发现潜在结构</td>
<td>“物以类聚，人以群分”</td>
</tr>
<tr>
<td>半监督学习（Semi-Supervised Learning）</td>
<td>部分有标签，部分无标签</td>
<td>有反馈</td>
<td>降低数据标记难度</td>
<td></td>
</tr>
<tr>
<td>强化学习（Reinforcement Learning）</td>
<td>决策流程及激励系统</td>
<td>一系列行动</td>
<td>长期利益最大化</td>
<td>学下棋</td>
</tr>
</tbody></table>
</li>
<li><p>数据基本处理</p>
</li>
<li><p>特征工程</p>
<ul>
<li>特征提取</li>
<li>特征预处理</li>
<li>特征降维</li>
</ul>
</li>
<li><p>机器学习（模型训练）</p>
<ul>
<li>选择合适的算法对模型进行训练</li>
</ul>
</li>
<li><p>模型评估</p>
<ul>
<li>结果达到要求，上线服务</li>
<li>没有达到要求，重新上面步骤</li>
</ul>
</li>
</ol>
<h3 id="获取数据"><a href="#获取数据" class="headerlink" title="获取数据"></a>获取数据</h3><blockquote>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250605142251204.png" alt="image-20250605142251204"></p>
<p>对于数据集:</p>
<ul>
<li>一行数据我们称为一个<code>样本</code></li>
<li>一列数据我们成为一个<code>特征</code></li>
<li>有些数据有目标值（标签值），有些数据没有目标值（如上表中，电影类型就是这个数据集的目标值）</li>
</ul>
<p>数据分割：</p>
<ul>
<li>数据类型一：特征值+目标值（目标值是连续的和离散的）</li>
<li>数据类型二：只有特征值，没有目标值</li>
</ul>
<p>针对上述的数据可以分类为<code>有监督学习</code>和<code>无监督学习</code>，可以看看之前的<a target="_blank" rel="noopener" href="https://liamjohnson-w.github.io/2023/08/07/2023.08.07/">Note</a>：</p>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/09.png" alt="09"></p>
<p>监督学习典型模型：Linear regression、Logistic regression、SVM、Neural Network等</p>
<p><strong>监督学习</strong>：监督学习指的是人们给机器标记好的数据，有特征值和目标值，比如：一大堆照片，人工先标记出哪些是猫的照片，哪些是狗的照片；训练模型；让模型判断其余照片是什么动物</p>
<p>监督学习一般有两个问题（分类问题、回归问题）</p>
<ul>
<li>分类问题：</li>
</ul>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/06.png" alt="img"></p>
<p>​		垃圾邮件识别就是一个分类问题，使用相应的机器学习算法判定邮件属于垃圾邮件还是非垃圾邮件。</p>
<ul>
<li>回归问题：<ul>
<li>数据中会给出大量的自变量和相应的连续因变量（对应输出结果），通过尝试寻找自变量和因变量的关系，就能够预测输出变量。</li>
<li>如房价的预测，根据房屋的面积以及房价的结果来进行后续的预测</li>
<li>还有股票基金的涨跌预测</li>
</ul>
</li>
</ul>
<p><strong>无监督学习</strong>：非监督学习(unsupervised learning)指的是人们给机器一大堆没有分类标记的数据，让机器可以对数据分类、检测异常等。相应的无监督学习只有一个聚类问题</p>
<ul>
<li>聚类问题：聚类是一种探索性数据分析技术，在没有任何相关先验信息的情况下（相当于不清楚数据的信息），它可以帮助我们将数据划分为有意义的小的组别（也叫簇cluster）。其中每个簇内部成员之间有一定的相似度，簇之间有较大的不同。这也正是聚类作为无监督学习的原因。</li>
</ul>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/08.png" alt="img"></p>
<ul>
<li><p>聚类的应用场景</p>
<ul>
<li>在对业务不是很熟悉的情况下, 使用聚类可以帮助打开思路</li>
<li>使用聚类算法做聚类分析 是分析过程的开头, 得到聚类结果之后, 再详细的分析每个类别各自的特点</li>
</ul>
</li>
</ul>
<p><strong>强化学习</strong>：实质是make decisions 问题，即自动进行决策，并且可以做连续决策。</p>
<ul>
<li><p>举例：小孩想要走路，但在这之前，他需要先站起来，站起来之后还要保持平衡，接下来还要先迈出一条腿，是左腿还是右腿，迈出一步后还要迈出下一步。</p>
</li>
<li><p>小孩就是 agent，他试图通过采取行动（即行走）来操纵环境（行走的表面），并且从一个状态转变到另一个状态（即他走的每一步），当他</p>
</li>
<li><p>完成任务的子任务（即走了几步）时，孩子得到奖励（给巧克力吃），并且当他不能走路时，就不会给巧克力。</p>
</li>
</ul>
<p><strong>半监督学习</strong>：训练集同时包含有标记样本数据和未标记样本数据。</p>
<p>机器学习一般的数据集会划分为两个部分：</p>
<ul>
<li>训练数据：用于训练，构建模型</li>
<li>测试数据：在模型检验时使用，用于评估模型是否有效</li>
</ul>
<p>划分比例：</p>
<ul>
<li>训练集：70% 80% 75%</li>
<li>测试集：30% 20% 25%</li>
</ul>
</blockquote>
<h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><blockquote>
<p>即对数据进行缺失值、去除异常值等处理</p>
</blockquote>
<h3 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h3><ul>
<li><p>特征提取：将任意数据（如文本或图像）转换为可用于机器学习的数字特征</p>
<ul>
<li>例如将语言、图像等自然语言转为计算机可以识别的字符（base64编码or二进制编码</li>
</ul>
</li>
<li><p>特征预处理：通过一些转换函数将特征数据转换成更加适合算法模型的特征数据过程</p>
</li>
</ul>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250605160124144.png" alt="image-20250605160124144"></p>
<ul>
<li>特征降维（特征缩放）：指在某些限定条件下，降低随机变量（特征）个数，得到一组“不相关”主变量的过程</li>
</ul>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250605160141881.png" alt="image-20250605160141881"></p>
<h3 id="机器学习（模型训练）"><a href="#机器学习（模型训练）" class="headerlink" title="机器学习（模型训练）"></a>机器学习（模型训练）</h3><ul>
<li>选择合适的算法对模型进行训练</li>
</ul>
<h3 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h3><ul>
<li><p>分类模型评估</p>
<ul>
<li>准确率：预测正确的数占样本总数的比例。</li>
<li>其他评价指标：精确率、召回率、<strong>F1-score</strong>、<strong>AUC</strong>指标等</li>
</ul>
</li>
<li><p>回归模型评估</p>
<ul>
<li><p>均方根误差（<strong>Root Mean Squared Error</strong>，<strong>RMSE</strong>）</p>
<ul>
<li><p>RMSE是一个衡量回归模型误差率的常用公式。 不过，它仅能比较误差是相同单位的模型。</p>
<p><span>$ RMSE&#x3D;\sqrt{\frac{\sum_{i&#x3D;1}^{n}\left(p_{i}-a_{i}\right)^{2}}{n}} $</span></p>
</li>
</ul>
</li>
<li><p>相对平方误差（<strong>Relative Squared Error</strong>，<strong>RSE</strong>）、平均绝对误差（<strong>Mean Absolute Error</strong>，<strong>MAE)<strong>、相对绝对误差 （</strong>Relative Absolute Error</strong>，<strong>RAE)</strong></p>
</li>
</ul>
</li>
<li><p>拟合</p>
<ul>
<li>过拟合：机器已经基本能区别天鹅和其他动物了。但很不巧已有的天鹅图片全是白天鹅的，于是机器判断黑的天鹅不是天鹅。</li>
<li>欠拟合：模型学习的太过粗糙，连训练集中的样本数据特征关系都没有学出来。比如判断鹦鹉、鸭子也是天鹅。</li>
</ul>
</li>
</ul>
<h1 id="Sklearn与特征工程⭐️"><a href="#Sklearn与特征工程⭐️" class="headerlink" title="Sklearn与特征工程⭐️"></a>Sklearn与特征工程⭐️</h1><blockquote>
<p><code>scikit-learn</code>（简称 <strong>sklearn</strong>）基于 NumPy、SciPy 和 Matplotlib 构建，提供了简单高效的算法工具，适合从数据预处理到模型训练的全流程。</p>
</blockquote>
<hr>
<h2 id="sklearn-的核心组成"><a href="#sklearn-的核心组成" class="headerlink" title="sklearn 的核心组成"></a><strong>sklearn 的核心组成</strong></h2><blockquote>
<p>sklearn的核心部分主要有</p>
<ul>
<li>数据预处理（Preprocessing）<ul>
<li><code>StandardScaler</code> &#x2F; <code>MinMaxScaler</code>：数据标准化&#x2F;归一化。</li>
<li><code>OneHotEncoder</code>：分类变量独热编码。</li>
<li><code>train_test_split</code>：划分训练集和测试集。</li>
<li><code>SimpleImputer</code>：处理缺失值。</li>
</ul>
</li>
<li>监督学习算法（Supervised Learning）<ul>
<li>分类（Classification）：<ul>
<li><code>LogisticRegression</code>（逻辑回归）</li>
<li><code>SVM</code>（支持向量机）</li>
<li><code>RandomForestClassifier</code>（随机森林）</li>
<li><code>KNeighborsClassifier</code>（K近邻）</li>
</ul>
</li>
<li>回归（Regression）：<ul>
<li><code>LinearRegression</code>（线性回归）</li>
<li><code>DecisionTreeRegressor</code>（决策树回归）</li>
<li><code>GradientBoostingRegressor</code>（梯度提升回归）</li>
</ul>
</li>
</ul>
</li>
<li>无监督学习算法（Unsupervised Learning）<ul>
<li>聚类（Clustering）：<ul>
<li><code>KMeans</code>（K均值聚类）</li>
<li><code>DBSCAN</code>（基于密度的聚类）</li>
</ul>
</li>
<li>降维（Dimensionality Reduction）：<ul>
<li><code>PCA</code>（主成分分析）</li>
<li><code>t-SNE</code>（数据可视化降维）</li>
</ul>
</li>
</ul>
</li>
<li>模型评估与选择（Model Evaluation）<ul>
<li>指标计算：<ul>
<li><code>accuracy_score</code>（分类准确率）</li>
<li><code>mean_squared_error</code>（回归均方误差）</li>
<li><code>confusion_matrix</code>（混淆矩阵）</li>
</ul>
</li>
<li>交叉验证：<ul>
<li><code>cross_val_score</code>（K折交叉验证）</li>
</ul>
</li>
</ul>
</li>
<li>特征工程（Feature Engineering）<ul>
<li><code>SelectKBest</code>：基于统计检验选择特征。</li>
<li><code>RFE</code>（递归特征消除）：自动筛选重要特征。</li>
</ul>
</li>
<li>流水线（Pipeline）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line">pipeline = Pipeline([</span><br><span class="line">    (<span class="string">&#x27;scaler&#x27;</span>, StandardScaler()),</span><br><span class="line">    (<span class="string">&#x27;classifier&#x27;</span>, RandomForestClassifier())</span><br><span class="line">])</span><br></pre></td></tr></table></figure>


</blockquote>
<table>
<thead>
<tr>
<th>库</th>
<th>特点</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td><strong>sklearn</strong></td>
<td>传统机器学习算法（非深度学习）</td>
<td>中小规模结构化数据</td>
</tr>
<tr>
<td><strong>TensorFlow&#x2F;PyTorch</strong></td>
<td>深度学习框架</td>
<td>图像、文本等复杂数据</td>
</tr>
<tr>
<td><strong>XGBoost</strong></td>
<td>高性能梯度提升树</td>
<td>表格数据竞赛&#x2F;高精度需求</td>
</tr>
</tbody></table>
<p>Iris 鸢尾花数据集内包含 3 种类别，分别为</p>
<ul>
<li>山鸢尾（Iris-setosa）</li>
<li>变色鸢尾（Iris-versicolor）</li>
<li>维吉尼亚鸢尾（Iris-virginica）<img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250606102258377.png" alt="image-20250606102258377"></li>
</ul>
<h2 id="sklearn随机森林-鸢尾花案例的典型代码流程"><a href="#sklearn随机森林-鸢尾花案例的典型代码流程" class="headerlink" title="sklearn随机森林-鸢尾花案例的典型代码流程"></a><strong>sklearn随机森林-鸢尾花案例的典型代码流程</strong></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 加载数据</span></span><br><span class="line">data = load_iris()</span><br><span class="line">X, y = data.data, data.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 划分数据集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 训练模型</span></span><br><span class="line">model = RandomForestClassifier()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 预测与评估</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准确率:&quot;</span>, accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure>

<h3 id="sklear典型流程-带注释详解"><a href="#sklear典型流程-带注释详解" class="headerlink" title="sklear典型流程(带注释详解)"></a>sklear典型流程(带注释详解)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1, 加载数据</span></span><br><span class="line">data = load_iris()</span><br><span class="line">x, y = data.data, data.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看数据结构</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征矩阵 x 的形状:&quot;</span>, x.shape)  <span class="comment"># 输出: (150, 4) → 150个样本，每个样本4个特征</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;标签数组 y 的形状:&quot;</span>, y.shape)  <span class="comment"># 输出: (150,)  → 150个标签</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;前5个样本的特征:\n&quot;</span>, x[:<span class="number">5</span>])</span><br><span class="line"><span class="comment">#  [[5.1 3.5 1.4 0.2]</span></span><br><span class="line"><span class="comment">#   [4.9 3.  1.4 0.2]</span></span><br><span class="line"><span class="comment">#   [4.7 3.2 1.3 0.2]</span></span><br><span class="line"><span class="comment">#   [4.6 3.1 1.5 0.2]</span></span><br><span class="line"><span class="comment">#   [5.  3.6 1.4 0.2]]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;前5个样本的标签:&quot;</span>, y[:<span class="number">5</span>])</span><br><span class="line"><span class="comment"># 前5个样本的标签: [0 0 0 0 0]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2，划分数据集</span></span><br><span class="line"><span class="comment"># 划分训练集和测试集。表示将数据的 20% 划分为测试集，剩余的 80% 自动作为训练集。也可指定绝对数量（如 test_size=200 表示 200 个样本作为测试集）。</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">其余参数：</span></span><br><span class="line"><span class="string">random_state：控制随机划分的种子（如 random_state=42 确保每次运行结果一致）。</span></span><br><span class="line"><span class="string">shuffle：是否打乱数据后再划分（默认为 True）。</span></span><br><span class="line"><span class="string">stratify：按标签分层划分（确保训练集和测试集的类别比例一致，适用于分类任务）。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># x：特征矩阵（输入数据），形状通常为 [样本数, 特征数]（如 (1000, 5) 表示 1000 个样本，每个样本 5 个特征）。</span></span><br><span class="line"><span class="comment"># y：标签数组（输出数据），形状为 [样本数,]（如 (1000,) 表示 1000 个样本对应的类别或回归值）。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># x_train：训练集特征矩阵（80% 的原始 x）。</span></span><br><span class="line"><span class="comment"># x_test：测试集特征矩阵（20% 的原始 x）。</span></span><br><span class="line"><span class="comment"># y_train：训练集标签（与 x_train 对应）。</span></span><br><span class="line"><span class="comment"># y_test：测试集标签（与 x_test 对应）。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3，训练模型</span></span><br><span class="line"><span class="comment"># 创建随机森林模型对象</span></span><br><span class="line">model = RandomForestClassifier()</span><br><span class="line"><span class="comment"># 用训练数据（x_train 和 y_train）训练模型，也就是训练集特征矩阵以及训练集标签进行有监督学习训练</span></span><br><span class="line">model.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4，预测与评估</span></span><br><span class="line"><span class="comment"># 让训练好的模型处理新数据（如预测新样本的类别）</span></span><br><span class="line">y_pred = model.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(y_pred)</span><br><span class="line"><span class="comment"># [0 2 2 1 0 0 1 0 1 0 2 0 1 1 2 1 2 2 2 1 0 1 1 1 0 1 1 1 1 0]</span></span><br></pre></td></tr></table></figure>

<p>注意事项：</p>
<ul>
<li>如果数据未标准化或存在缺失值，可能需要在 <code>fit</code> 之前进行预处理（如使用 <code>StandardScaler</code>）。</li>
<li>训练后可通过 <code>model.score(x_test, y_test)</code> 快速评估模型在测试集上的准确率。</li>
</ul>
<h2 id="Seaborn鸢尾花案例"><a href="#Seaborn鸢尾花案例" class="headerlink" title="Seaborn鸢尾花案例"></a>Seaborn鸢尾花案例</h2><h2 id="模型选择与调优"><a href="#模型选择与调优" class="headerlink" title="模型选择与调优"></a>模型选择与调优</h2><h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><h3 id="网格搜索"><a href="#网格搜索" class="headerlink" title="网格搜索"></a>网格搜索</h3><h2 id="鸢尾花案例增加K值调优"><a href="#鸢尾花案例增加K值调优" class="headerlink" title="鸢尾花案例增加K值调优"></a>鸢尾花案例增加K值调优</h2><h1 id="KNN算法"><a href="#KNN算法" class="headerlink" title="KNN算法"></a>KNN算法</h1><blockquote>
<p>K Nearest Neighbor算法又叫KNN算法，这个算法是机器学习里面一个比较经典的算法， 相对比较容易理解。</p>
</blockquote>
<h2 id="KNN算法流程"><a href="#KNN算法流程" class="headerlink" title="KNN算法流程"></a>KNN算法流程</h2><ul>
<li>计算测试样本和训练样本中每个样本点的距离（常见的距离度量有欧式距离，马氏距离等）；</li>
<li>对上面所有的距离值进行排序；</li>
<li>选前 k 个最小距离的样本；</li>
<li>根据这 k 个样本的标签进行投票，得到最后的分类类别；</li>
</ul>
<h3 id="K值大小对于训练的影响"><a href="#K值大小对于训练的影响" class="headerlink" title="K值大小对于训练的影响"></a>K值大小对于训练的影响</h3><ul>
<li>K值过小：<ul>
<li>容易受到异常点的影响</li>
<li>容易过拟合</li>
</ul>
</li>
<li>k值过大：<ul>
<li>受到样本均衡的问题</li>
<li>容易欠拟合</li>
</ul>
</li>
</ul>
<h2 id="欧式距离"><a href="#欧式距离" class="headerlink" title="欧式距离"></a>欧式距离</h2><blockquote>
<p>其实就是两点之间的距离计算方式：</p>
</blockquote>
<h3 id="1-二维空间"><a href="#1-二维空间" class="headerlink" title="1. 二维空间"></a>1. 二维空间</h3><p>点 $a(x_{1},y_{1})$ 与 $b(x_{2},y_{2})$ 间的距离：<br>$$ d_{12} &#x3D; \sqrt{(x_{1}-x_{2})^{2} + (y_{1}-y_{2})^{2}} $$</p>
<h3 id="2-三维空间"><a href="#2-三维空间" class="headerlink" title="2. 三维空间"></a>2. 三维空间</h3><p>点 $a(x_{1},y_{1},z_{1})$ 与 $b(x_{2},y_{2},z_{2})$ 间的距离：<br>$$ d_{12} &#x3D; \sqrt{(x_{1}-x_{2})^{2} + (y_{1}-y_{2})^{2} + (z_{1}-z_{2})^{2}} $$</p>
<h3 id="3-n维空间"><a href="#3-n维空间" class="headerlink" title="3. n维空间"></a>3. n维空间</h3><p>点 $a(x_{11},x_{12},\dots,x_{1n})$ 与 $b(x_{21},x_{22},\dots,x_{2n})$ 间的距离：<br>$$ d_{12} &#x3D; \sqrt{\sum_{k&#x3D;1}^{n}(x_{1k} - x_{2k})^{2}} $$</p>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250606110103367.png" alt="image-20250606110103367"></p>
<p>计算唐探与各个电影的欧式距离，取前5个，统计各个电影类型出现的频率，根据频率判断唐探的目标值为喜剧片</p>
<h2 id="sklearn-KNN算法"><a href="#sklearn-KNN算法" class="headerlink" title="sklearn-KNN算法"></a>sklearn-KNN算法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">x = [[<span class="number">0</span>], [<span class="number">3</span>], [<span class="number">6</span>], [<span class="number">10</span>]]</span><br><span class="line">y = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">model = KNeighborsClassifier(n_neighbors=<span class="number">1</span>)</span><br><span class="line">model.fit(x,y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.predict([[<span class="number">5</span>]]))</span><br></pre></td></tr></table></figure>



<h2 id="各种距离计算方式"><a href="#各种距离计算方式" class="headerlink" title="各种距离计算方式"></a>各种距离计算方式</h2><p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250606114135017.png" alt="image-20250606114135017"></p>
<ul>
<li><p>欧式距离(Euclidean Distance)：</p>
<ul>
<li>上面写了</li>
</ul>
</li>
<li><p>曼哈顿距离(Manhattan Distance)：</p>
<ul>
<li><p>二维空间</p>
</li>
<li><p>点 $a(x_{1},y_{1})$ 与 $b(x_{2},y_{2})$ 间的距离：$$ d_{12} &#x3D; |x_{1} - x_{2}| + |y_{1} - y_{2}| $$</p>
</li>
<li><p>n维空间</p>
<ul>
<li>点 $a(x_{11},x_{12},\ldots,x_{1n})$ 与 $b(x_{21},x_{22},\ldots,x_{2n})$ 间的距离：$$ d_{12} &#x3D; \sum_{k&#x3D;1}^{n} |x_{1k} - x_{2k}| $$</li>
</ul>
</li>
</ul>
</li>
<li><p>切比雪夫距离 (Chebyshev Distance)：</p>
</li>
<li><p>二维空间</p>
</li>
<li><p>点 $a(x_{1},y_{1})$ 与 $b(x_{2},y_{2})$ 间的距离：$$ d_{12} &#x3D; \max\left(|x_{1}-x_{2}|,\ |y_{1}-y_{2}|\right) $$</p>
</li>
<li><p>n维空间</p>
<ul>
<li>点 $a(x_{11},x_{12},\ldots,x_{1n})$ 与 $b(x_{21},x_{22},\ldots,x_{2n})$ 间的距离：$$ d_{12} &#x3D; \max_{1 \leq i \leq n} \left( |x_{1i} - x_{2i}| \right) $$</li>
</ul>
</li>
<li><p>标准化欧氏距离 (Standardized EuclideanDistance)：</p>
<ul>
<li>既然数据各维分量的分布不一样，那先将各个分量都”标准化”到均值、方差相等，$$S_k$$表示各个维度的标准差，如果将方差的倒数看成一个权重，也可称之为加权欧氏距离Weiahted Euclidean distance)<ul>
<li>$$ d_{12} &#x3D; \sqrt{\sum_{k&#x3D;1}^{n} \left( \frac{x_{1k} - x_{2k}}{s_{k}} \right)^2 } $$</li>
</ul>
</li>
</ul>
</li>
<li><p>余弦距离(Cosine Distance)：几何中，夹角余弦可用来衡量两个向量方向的差异;机器学习中，借用这一概念来衡量样本向量之间的差异。</p>
<ul>
<li><p>二维空间向量</p>
<ul>
<li>向量 $\vec{a}(x_1,y_1)$ 与 $\vec{b}(x_2,y_2)$ 的夹角余弦：：$$ \cos \theta &#x3D; \frac{x_{1}x_{2} + y_{1}y_{2}}{\sqrt{x_{1}^{2} + y_{1}^{2}} \sqrt{x_{2}^{2} + y_{2}^{2}}} $$</li>
</ul>
</li>
<li><p>n维空间向量</p>
<ul>
<li>对于 $n$ 维样本点：$a(x_{11},x_{12},\ldots,x_{1n})$、$b(x_{21},x_{22},\ldots,x_{2n})$</li>
</ul>
</li>
<li><p>夹角余弦的两种表达形式：</p>
<ul>
<li><strong>点积与模长形式</strong>：<ul>
<li>$$ \cos (\theta) &#x3D; \frac{a \cdot b}{|a| \ |b|} $$</li>
</ul>
</li>
<li><strong>展开形式</strong>：<ul>
<li>$$ \cos (\theta) &#x3D; \frac{\sum\limits_{k&#x3D;1}^{n} x_{1k} x_{2k}}{\sqrt{\sum\limits_{k&#x3D;1}^{n} x_{1k}^{2}} \sqrt{\sum\limits_{k&#x3D;1}^{n} x_{2k}^{2}}} $$</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>汉明距离(Hamming Distance)：</p>
<ul>
<li>两个等长字符串s1与s2的汉明距离为: 将其中一个变为另外一个所需要作的<strong>最小字符替换次数</strong>。</li>
</ul>
</li>
<li><p>杰卡德距离(Jaccard Distance)：</p>
<ul>
<li>杰卡德相似系数(Jaccard slmilarity coeficient): 两个集合A和B的交集元素在A，B的并集中所占的比例，称为两个集合的杰卡德相似系数，用符号J(A,B)表示:</li>
</ul>
<p>$$<br>J(A,B) &#x3D; \frac{|A \cap B|}{|A \cup B|}<br>$$</p>
</li>
<li><p>闵可夫斯基距离(Minkowski Distance)，也叫闵式距离：</p>
<ul>
<li><p>$$ d_{12} &#x3D; \sqrt[p]{\sum_{k&#x3D;1}^{n} \left| x_{1k} - x_{2k} \right|^{p}} $$</p>
</li>
<li><p>参数说明</p>
<ul>
<li><p>$p$：距离参数（$p \geq 1$）</p>
</li>
<li><p>$x_{1k}, x_{2k}$：两个$n$维向量的第$k$个分量</p>
</li>
<li><p>$d_{12}$：两点间的闵氏距离</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="KD树"><a href="#KD树" class="headerlink" title="KD树"></a>KD树</h2><blockquote>
<p>根据<strong>KNN</strong>每次需要预测一个点时，我们都需要计算训练数据集里每个点到这个点的距离，然后选出距离最近的k个点进行投票。<strong>当数据集很大时，这个计算成本非常高</strong>。</p>
<p><strong>kd树</strong>：为了避免每次都重新计算一遍距离，算法会把距离信息保存在一棵树里，这样在计算之前从树里查询距离信息，尽量避免重新计算。其基本原理是，<strong>如果A和B距离很远，B和C距离很近，那么A和C的距离也很远</strong>。有了这个信息，就可以在合适的时候跳过距离远的点。</p>
</blockquote>
<h3 id="KD树的构建（二维平面）"><a href="#KD树的构建（二维平面）" class="headerlink" title="KD树的构建（二维平面）"></a>KD树的构建（二维平面）</h3><ol>
<li>确定split域：按照x&#x2F;y轴进行分割，根据x轴以及y轴数据上的方差，方差大的为split域。</li>
<li>确定Node-Data域：按照split值排序，取中间的点作为Node-Data点</li>
<li>确定左子空间和右子空间：按照Node-Data的x&#x2F;y坐标进行点的分割</li>
</ol>
<p>详细步骤：</p>
<blockquote>
<p>给定一个二维空间数据集：T&#x3D;{(2,3),(5,4),(9,6),(4,7),(8,1),(7,2)}，构造一个平衡kd树。</p>
</blockquote>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250606154437192.png" alt="image-20250606154437192"></p>
<ol>
<li>确定：split域&#x3D;x。具体是：6个数据点在x，y维度上的数据方差分别为39，28.63，在x轴上方差更大，故split域值为x；</li>
<li>确定：Node-data &#x3D; （7,2）。具体是：根据x维上的值将数据排序，6个数据的中值(所谓中值，即中间大小的值)为5,7的平均値，但是没有6，所以往后进一到7（暂时没搞懂）！！所以Node-data域位数据点（7,2）。</li>
<li>确定：左子空间和右子空间。具体是：分割超平面x&#x3D;7将整个空间分为两部分：x&lt;&#x3D;7的部分为左子空间，包含3个节点&#x3D;{(2,3),(5,4),(4,7)}；另一部分为右子空间，包含2个节点&#x3D;{(9,6)，(8,1)}；</li>
<li>如上算法所述，kd树的构建是一个递归过程，我们对左子空间和右子空间内的数据重复根节点的过程就可以得到一级子节点<strong>（5,4）</strong>和<strong>（9,6）</strong>，同时将空间和数据集进一步细分，如此往复直到空间中只包含一个数据点。</li>
</ol>
<h3 id="KD树的快速最近邻搜索算法"><a href="#KD树的快速最近邻搜索算法" class="headerlink" title="KD树的快速最近邻搜索算法"></a>KD树的<strong>快速最近邻搜索</strong>算法</h3><blockquote>
<p>假设标记为星星的点是 test point， 绿色的点是找到的近似点，在回溯过程中，需要用到一个队列，存储需要回溯的点，在判断其他子节点空间中是否有可能有距离查询点更近的数据点时，做法是以查询点为圆心，以当前的最近距离为半径画圆，这个圆称为候选超球（candidate hypersphere），如果圆与回溯点的轴相交，则需要将轴另一边的节点都放到回溯队列里面来。</p>
</blockquote>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250606155816616.png" alt="image-20250606155816616"></p>
<p>样本集{(2,3),(5,4), (9,6), (4,7), (8,1), (7,2)}</p>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250606160159584.png" alt="image-20250606160159584"></p>
<ul>
<li><p>查找点(2.1,3.1)</p>
</li>
<li><p>确定Search_Path为&lt;(7,2),(5,4), (2,3)&gt;；从search_path中取出(2,3)作为当前最佳结点nearest，dist为0.141</p>
<ul>
<li>然后回溯至(5,4)，以(2.1,3.1)为圆心，以dist&#x3D;0.141为半径画一个圆，并不和超平面y&#x3D;4相交，如上图，所以不必跳到结点(5,4)的右子空间去搜索，因为右子空间中不可能有更近样本点了。</li>
</ul>
</li>
<li><p>于是再回溯至(7,2)，同理，以(2.1,3.1)为圆心，以dist&#x3D;0.141为半径画一个圆并不和超平面x&#x3D;7相交，所以也不用跳到结点(7,2)的右子空间去搜索。</p>
<ul>
<li>至此，search_path为空，结束整个搜索，返回nearest(2,3)作为(2.1,3.1)的最近邻点，最近距离为0.141。</li>
</ul>
</li>
<li><p>查找点(2,4.5)</p>
<ul>
<li>在(7,2)处测试到达(5,4)，在(5,4)处测试到达(4,7)【优先选择在本域搜索】，然后search_path中的结点为&lt;(7,2),(5,4), (4,7)&gt;，从search_path中取出(4,7)作为当前最佳结点nearest, dist为3.202；</li>
<li>然后回溯至(5,4)，以(2,4.5)为圆心，以dist&#x3D;3.202为半径画一个圆与超平面y&#x3D;4相交，所以需要跳到(5,4)的左子空间去搜索。所以要将(2,3)加入到search_path中，现在search_path中的结点为&lt;(7,2),(2, 3)&gt;；另外，(5,4)与(2,4.5)的距离为3.04 &lt; dist &#x3D; 3.202，所以将(5,4)赋给nearest，并且dist&#x3D;3.04。</li>
<li>回溯至(2,3)，(2,3)是叶子节点，直接平判断(2,3)是否离(2,4.5)更近，计算得到距离为1.5，所以nearest更新为(2,3)，dist更新为(1.5)</li>
<li>回溯至(7,2)，同理，以(2,4.5)为圆心，以dist&#x3D;1.5为半径画一个圆并不和超平面x&#x3D;7相交, 所以不用跳到结点(7,2)的右子空间去搜索。</li>
<li>至此，search_path为空，结束整个搜索，返回nearest(2,3)作为(2,4.5)的最近邻点，最近距离为1.5。</li>
</ul>
</li>
</ul>
<h3 id="KD树的插入"><a href="#KD树的插入" class="headerlink" title="KD树的插入"></a>KD树的插入</h3><ul>
<li>在现有KD树中插入点 <code>(3, 6)</code>）：<ul>
<li><strong>现有树结构</strong>（按 <code>x→y→x...</code> 划分）：</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">          (5,4)        ← 根节点（x轴分割）</span><br><span class="line">         /     \</span><br><span class="line">    (2,3)       (8,1)   ← 第2层（y轴分割）</span><br><span class="line">     /   \       /   \</span><br><span class="line">(1,7) (4,2) (7,9) (9,5)</span><br></pre></td></tr></table></figure>

<p><strong>插入步骤</strong>：</p>
<ol>
<li>比较根节点 <code>(5,4)</code>（第1层，x轴）：<ul>
<li>插入点 <code>(3,6)</code> 的x值 <code>3 &lt; 5</code> → 进入左子树。</li>
</ul>
</li>
<li>比较 <code>(2,3)</code>（第2层，y轴）：<ul>
<li>插入点y值 <code>6 &gt; 3</code> → 进入右子树。</li>
</ul>
</li>
<li>到达叶子节点 <code>(4,2)</code>：<ul>
<li>第3层按x轴比较，<code>3 &lt; 4</code> → 作为 <code>(4,2)</code> 的左子节点插入。</li>
</ul>
</li>
</ol>
<p><strong>插入后树结构</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">          (5,4)</span><br><span class="line">         /     \</span><br><span class="line">    (2,3)       (8,1)</span><br><span class="line">     /   \       /   \</span><br><span class="line">(1,7) (4,2) (7,9) (9,5)</span><br><span class="line">     /</span><br><span class="line">  (3,6)       ← 新插入节点</span><br></pre></td></tr></table></figure>

<p>图示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">graph TD</span><br><span class="line">    A[(5,4)] --&gt; B[(2,3)]</span><br><span class="line">    A --&gt; C[(8,1)]</span><br><span class="line">    B --&gt; D[(1,7)]</span><br><span class="line">    B --&gt; E[(4,2)]</span><br><span class="line">    E --&gt; F[(3,6)]</span><br><span class="line">    C --&gt; G[(7,9)]</span><br><span class="line">    C --&gt; H[(9,5)]</span><br></pre></td></tr></table></figure>

<h3 id="KD树的删除"><a href="#KD树的删除" class="headerlink" title="KD树的删除"></a>KD树的删除</h3><ul>
<li><p><strong>核心逻辑</strong>：找到待删除节点后，按以下规则处理：</p>
<ul>
<li><p><strong>情况1</strong>：若为叶子节点 → 直接删除。</p>
</li>
<li><p><strong>情况2</strong>：若非叶子节点 → 找到子树中同分割轴的最优替代节点（类似二叉搜索树的中序后继）。</p>
</li>
</ul>
</li>
</ul>
<p>删除节点 <code>(5,4)</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">          (5,4)</span><br><span class="line">         /     \</span><br><span class="line">    (2,3)       (8,1)</span><br><span class="line">     /   \       /   \</span><br><span class="line">(1,7) (4,2) (7,9) (9,5)</span><br><span class="line">     /</span><br><span class="line">  (3,6) </span><br></pre></td></tr></table></figure>

<p><strong>步骤</strong>：</p>
<ol>
<li>定位节点 <code>(5,4)</code>：<ul>
<li>根节点，分割轴为x轴。</li>
</ul>
</li>
<li>寻找替代节点：<ul>
<li>在右子树中找x轴最小的点（即中序后继）→ <code>(7,9)</code>。</li>
</ul>
</li>
<li>替换并递归删除：<ul>
<li>用 <code>(7,9)</code> 替换 <code>(5,4)</code>，再递归删除 <code>(7,9)</code> 的原位置。</li>
</ul>
</li>
</ol>
<p><strong>删除后树结构</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">          (7,9)        ← 原(5,4)被替换</span><br><span class="line">         /     \</span><br><span class="line">    (2,3)       (8,1)</span><br><span class="line">     /   \       /   \</span><br><span class="line">(1,7) (4,2) (9,5)     ← (7,9)从原位置删除</span><br><span class="line">     /</span><br><span class="line">  (3,6)</span><br></pre></td></tr></table></figure>

<p><strong>图示</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">graph TD</span><br><span class="line">    A[(7,9)] --&gt; B[(2,3)]</span><br><span class="line">    A --&gt; C[(8,1)]</span><br><span class="line">    B --&gt; D[(1,7)]</span><br><span class="line">    B --&gt; E[(4,2)]</span><br><span class="line">    E --&gt; F[(3,6)]</span><br><span class="line">    C --&gt; H[(9,5)]</span><br></pre></td></tr></table></figure>



<h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><blockquote>
<p>线性回归(Linear regression)是利用**回归方程(函数)**对一个或多个自变量(特征值)和因变量(目标值)之间关系进行建模的一种分析方式。只有一个自变量的情况称为单变量回归，多于一个自变量情况的叫做多元回归。</p>
</blockquote>
<h2 id="线性回归定义⭐️"><a href="#线性回归定义⭐️" class="headerlink" title="线性回归定义⭐️"></a>线性回归定义⭐️</h2><h3 id="通用公式"><a href="#通用公式" class="headerlink" title="通用公式"></a>通用公式</h3><p>预测函数 $h(w)$ 的向量化表示：<br>$$ h(w) &#x3D; w_1x_1 + w_2x_2 + w_3x_3 \cdots + b &#x3D; w^Tx + b $$</p>
<p>其中参数 $w$ 和特征 $x$ 的矩阵形式：</p>
<p><span>$w &#x3D; \begin{pmatrix}<br>b \<br>w_1 \<br>w_2<br>\end{pmatrix}, \quad<br>x &#x3D; \begin{pmatrix}<br>1 \<br>x_1 \<br>x_2<br>\end{pmatrix}$</span></p>
<p>给定方程组：</p>
<p><span>$\begin{cases}<br>1 \times x_1 + x_2 &#x3D; 2 \<br>0 \times x_1 + x_2 &#x3D; 2 \<br>2 \times x_1 + x_2 &#x3D; 3<br>\end{cases}$</span></p>
<p>其矩阵运算表示为：</p>
<h1 id="begin-bmatrix-1-amp-1-0-amp-1-2-amp-1-end-bmatrix-begin-bmatrix-x-1-x-2-end-bmatrix"><a href="#begin-bmatrix-1-amp-1-0-amp-1-2-amp-1-end-bmatrix-begin-bmatrix-x-1-x-2-end-bmatrix" class="headerlink" title="$\begin{bmatrix}1 &amp; 1 \0 &amp; 1 \2 &amp; 1\end{bmatrix}\begin{bmatrix}x_1 \x_2\end{bmatrix}"></a><span>$\begin{bmatrix}<br>1 &amp; 1 \<br>0 &amp; 1 \<br>2 &amp; 1<br>\end{bmatrix}<br>\begin{bmatrix}<br>x_1 \<br>x_2<br>\end{bmatrix}</h1><p>\begin{bmatrix}<br>2 \<br>2 \<br>3<br>\end{bmatrix}$</span></p>
<h2 id="线性回归的分类及应用场景"><a href="#线性回归的分类及应用场景" class="headerlink" title="线性回归的分类及应用场景"></a>线性回归的分类及应用场景</h2><ul>
<li>一元线性回归：$y &#x3D; kx +b $<ul>
<li>目标值只与一个因变量有关系</li>
</ul>
</li>
</ul>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20230901102857178.png" alt="image-20230901102857178"></p>
<ul>
<li>多元线性回归：$$ h(w) &#x3D; w_1x_1 + w_2x_2 + w_3x_3 \cdots + b &#x3D; w^Tx + b $$<ul>
<li>目标值只与多个因变量有关系</li>
</ul>
</li>
</ul>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20230901103000204.png" alt="image-20230901103000204"></p>
<p>应用场景：</p>
<ul>
<li>国内GDP与双11销售额的关系</li>
<li>贷款额度与工作情况家庭情况的关系</li>
</ul>
<h2 id="损失函数⭐️"><a href="#损失函数⭐️" class="headerlink" title="损失函数⭐️"></a>损失函数⭐️</h2><ul>
<li><strong>误差</strong>：用预测值$y$ – 真实值$y$就是误差</li>
<li><strong>损失函数</strong>：衡量每个样本预测值与真实值效果的函数</li>
</ul>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250607112225011.png" alt="image-20250607112225011"></p>
<p>假设线性方程式为：$$ y &#x3D; kx + b $$</p>
<p>每个样本的<strong>预测值与真实值的误差</strong>来构成损失函数：$$ L(k,b) &#x3D; \sum_{i&#x3D;1}^{n} (y_i - \hat{y}_i)^2 $$</p>
<p>给定数据后，损失函数表达式：<br>$$<br>\begin{aligned}<br>L(k,b) &#x3D; &amp;(160k + b - 56.3)^2 + (166k + b - 60.6)^2 \<br>         + &amp;(172k + b - 65.1)^2 + (174k + b - 58.5)^2 \<br>         + &amp;(180k + b - 56.3)^2<br>\end{aligned}<br>$$</p>
<p>求参数 $(k, b)$ 使得损失函数 $L(k,b)$ 最小化</p>
<p>于是损失函数的求解就变成了数学问题：（为简化计算，先固定截距b，当k为0时，b可以设置成一个负值，b固定成-100）</p>
<p>由此损失函数就成了</p>
<p>$$\begin{aligned}<br>L(k,b) &#x3D; &amp;(160k - 156.3)^2 + (166k - 160.6)^2 +(172k - 165.1)^2 + (174k - 158.5)^2 + (180k - 156.3)^2<br>\end{aligned}$$</p>
<p>展开成二元一次方程组</p>
<p>$$\begin{aligned}<br>L(k,b) &#x3D; 145416k^2 - 281671.6k + 136496.32<br>\end{aligned}$$</p>
<p><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250607143836920.png" alt="image-20250607143836920"></p>
<p>根据图像得知，损失函数的最小值为图像的切线斜率为0的时候，也就是抛物线的低点。</p>
<p>由此可以通过求一元二次方程组的导，然后令导数为0即可求出解。</p>
<h3 id="均方根误差函数-Mean-Squared-Error-MSE-："><a href="#均方根误差函数-Mean-Squared-Error-MSE-：" class="headerlink" title="均方根误差函数(Mean Squared Error, MSE)："></a>均方根误差函数(Mean Squared Error, MSE)：</h3><p>$$ \text{MSE} &#x3D; \frac{1}{n} \sum_{i&#x3D;1}^{n} \left(Y_i - \hat{Y}_i\right)^2 $$</p>
<h3 id="绝对值误差函数-Mean-Absolute-Error-MAE-："><a href="#绝对值误差函数-Mean-Absolute-Error-MAE-：" class="headerlink" title="绝对值误差函数(Mean Absolute Error, MAE)："></a>绝对值误差函数(Mean Absolute Error, MAE)：</h3><p>$$ \text{MAE} &#x3D; \frac{1}{n} \sum_{i&#x3D;1}^{n} \left| Y_i - \hat{Y}_i \right| $$</p>
<h3 id="MSE与MAE对比⭐️"><a href="#MSE与MAE对比⭐️" class="headerlink" title="MSE与MAE对比⭐️"></a>MSE与MAE对比⭐️</h3><table>
<thead>
<tr>
<th align="center">指标</th>
<th align="center">优点</th>
<th align="center">缺点</th>
<th>应用场景</th>
</tr>
</thead>
<tbody><tr>
<td align="center">MSE</td>
<td align="center">处处可导，便于优化</td>
<td align="center">对异常值敏感</td>
<td>通常用于需要精确预测的场景，但可能不适用于异常值较多的数据集。</td>
</tr>
<tr>
<td align="center">MAE</td>
<td align="center">鲁棒性强，解释性直观</td>
<td align="center">在梯度下降中不可导（需次梯度优化）</td>
<td>通常用于异常值可能代表重要信息或损坏数据的场景。</td>
</tr>
</tbody></table>
<h2 id="梯度下降算法⭐️"><a href="#梯度下降算法⭐️" class="headerlink" title="梯度下降算法⭐️"></a>梯度下降算法⭐️</h2><h2 id="回归模型评估方法⭐️"><a href="#回归模型评估方法⭐️" class="headerlink" title="回归模型评估方法⭐️"></a>回归模型评估方法⭐️</h2><h2 id="线性回归API及案例"><a href="#线性回归API及案例" class="headerlink" title="线性回归API及案例"></a>线性回归API及案例</h2><h2 id="过拟合和欠拟合出现原因及解决方案⭐️"><a href="#过拟合和欠拟合出现原因及解决方案⭐️" class="headerlink" title="过拟合和欠拟合出现原因及解决方案⭐️"></a>过拟合和欠拟合出现原因及解决方案⭐️</h2><h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><h1 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h1><h1 id="聚类算法"><a href="#聚类算法" class="headerlink" title="聚类算法"></a>聚类算法</h1><h1 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h1><h1 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h1><h1 id="EM算法"><a href="#EM算法" class="headerlink" title="EM算法"></a>EM算法</h1><h1 id="HMM模型"><a href="#HMM模型" class="headerlink" title="HMM模型"></a>HMM模型</h1><h1 id="模型评估-1"><a href="#模型评估-1" class="headerlink" title="模型评估"></a>模型评估</h1><h1 id="附件"><a href="#附件" class="headerlink" title="附件"></a>附件</h1><h2 id="公共基础知识"><a href="#公共基础知识" class="headerlink" title="公共基础知识"></a>公共基础知识</h2><h3 id="标量（Scalar）"><a href="#标量（Scalar）" class="headerlink" title="标量（Scalar）:"></a>标量（Scalar）:</h3><ul>
<li><p>零阶张量，仅包含大小（Magnitude）​ 没有方向（<code>就是单个数值</code>）</p>
</li>
<li><p>数学表示：<em>s</em>∈R（单个实数或复数）</p>
<ul>
<li>例如：质量：5kg、损失函数值：L&#x3D;0.32</li>
</ul>
</li>
</ul>
<h3 id="向量（Vector）"><a href="#向量（Vector）" class="headerlink" title="向量（Vector）"></a><strong>向量（Vector）</strong></h3><ul>
<li>一阶张量，是标量的有序组合，具有 ​<strong>​大小和方向​</strong>​。（<code>就是一个向量，线性代数里的列向量以及行向量</code>）</li>
<li>可表示空间中的点或方向，例如：<ul>
<li>坐标点：(2,3,5)</li>
<li>速度向量：<strong>v</strong>&#x3D;3<strong>i</strong>+4<strong>j</strong></li>
</ul>
</li>
</ul>
<h3 id="张量（Tensor）"><a href="#张量（Tensor）" class="headerlink" title="张量（Tensor）"></a><strong>张量（Tensor）</strong></h3><ul>
<li><strong>定义</strong>：高阶广义数组（标量是0阶，向量是1阶），可表示 ​<strong>​多维数据关系​</strong>​</li>
<li><strong>特性</strong>：<ul>
<li>阶数（Rank）：索引的自由度（如矩阵是2阶）</li>
<li>支持张量积（⊗）、收缩（Contraction）等运算</li>
<li>内存占用随维度指数增长</li>
</ul>
</li>
<li><strong>示例</strong>：<ul>
<li>矩阵（2阶张量）：$A∈R^{3×3}$(三阶方阵)</li>
<li>RGB图像（3阶张量）：$I∈R^{H×W×3}$</li>
<li>时间序列视频（4阶张量）：$V∈R^{T×H×W×3}$</li>
</ul>
</li>
</ul>
<h3 id="三者区别"><a href="#三者区别" class="headerlink" title="三者区别"></a><strong>三者区别</strong></h3><table>
<thead>
<tr>
<th align="center">特性</th>
<th align="center">标量</th>
<th align="center">向量</th>
<th align="center">张量</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>阶数</strong></td>
<td align="center">0阶</td>
<td align="center">1阶</td>
<td align="center"><em>k</em>阶（<em>k</em>≥2）</td>
</tr>
<tr>
<td align="center"><strong>方向性</strong></td>
<td align="center">无</td>
<td align="center">有</td>
<td align="center">多维方向</td>
</tr>
<tr>
<td align="center"><strong>存储结构</strong></td>
<td align="center">单个数值</td>
<td align="center">一维数组</td>
<td align="center">多维数组</td>
</tr>
<tr>
<td align="center"><strong>运算</strong></td>
<td align="center">算术运算</td>
<td align="center">线性代数运算</td>
<td align="center">张量分解&#x2F;收缩</td>
</tr>
<tr>
<td align="center"><strong>PyTorch表示</strong></td>
<td align="center"><code>torch.tensor(3)</code></td>
<td align="center"><code>torch.tensor([1,2])</code></td>
<td align="center"><code>torch.rand(2,3,4)</code></td>
</tr>
</tbody></table>
<h3 id="图形展示"><a href="#图形展示" class="headerlink" title="图形展示"></a><strong>图形展示</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">    A[标量] --&gt;|升维| B[向量]</span><br><span class="line">    B --&gt;|升维| C[矩阵]</span><br><span class="line">    C --&gt;|升维| D[3阶张量]</span><br></pre></td></tr></table></figure>

<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a><strong>应用场景</strong></h3><ul>
<li><strong>标量</strong>：损失值、阈值参数</li>
<li><strong>向量</strong>：特征表示、词嵌入（Word2Vec）</li>
<li>张量：<ul>
<li>计算机视觉：卷积核（4阶：<code>[out_channels, in_channels, h, w]</code>）</li>
<li>自然语言处理：注意力权重矩阵（<code>[batch_size, seq_len, seq_len]</code>）</li>
</ul>
</li>
</ul>
<h2 id="Latex数学语法支持"><a href="#Latex数学语法支持" class="headerlink" title="Latex数学语法支持"></a>Latex数学语法支持</h2><ul>
<li><a target="_blank" rel="noopener" href="https://blog.kevinchu.top/2023/09/12/hexo-supports-latex/">https://blog.kevinchu.top/2023/09/12/hexo-supports-latex/</a></li>
<li>矩阵在写MarkDown的时候可能会出现异常，用&lt;span&gt;&lt;span&gt;包裹起来就没事了</li>
</ul>
<h2 id="导数-amp-矩阵-amp-向量"><a href="#导数-amp-矩阵-amp-向量" class="headerlink" title="导数&amp;矩阵&amp;向量"></a>导数&amp;矩阵&amp;向量</h2><h3 id="常见函数的导数："><a href="#常见函数的导数：" class="headerlink" title="常见函数的导数："></a>常见函数的导数：</h3><table>
<thead>
<tr>
<th align="center">公式</th>
<th align="center">例子</th>
</tr>
</thead>
<tbody><tr>
<td align="center">$(C)^\prime&#x3D;0$</td>
<td align="center">$\left(5\right)^\prime&#x3D;0$         $\left(10\right)^\prime&#x3D;0$</td>
</tr>
<tr>
<td align="center">$\left(x^\alpha\right)^\prime&#x3D;\alpha x^{\alpha-1}$</td>
<td align="center">$\left(x^3\right)^\prime&#x3D;3 x^{2}$      $\left(x^5\right)^\prime&#x3D;5 x^{4}$</td>
</tr>
<tr>
<td align="center">$\left(a^x\right)^\prime&#x3D;a^{x}\ln{a}$</td>
<td align="center">$\left(2^x\right)^\prime&#x3D;2^x\ln{2}$      $\left(7^x\right)^\prime&#x3D;7^x\ln{7}$</td>
</tr>
<tr>
<td align="center">$\left(e^x\right)^\prime&#x3D;e^{x}$</td>
<td align="center">$\left(e^x\right)^\prime&#x3D;e^{x}$</td>
</tr>
<tr>
<td align="center">$\left(\log{_a}x\right)^\prime&#x3D;\frac{1}{x\ln{a}}$</td>
<td align="center">$\left(\log{<em>{10}}x\right)^\prime&#x3D;\frac{1}{x\ln{10}}$      $\left(\log{</em>{6}}x\right)^\prime&#x3D;\frac{1}{x\ln{6}}$</td>
</tr>
<tr>
<td align="center">$\left(\ln{x}\right)^\prime&#x3D;\frac{1}{x}$</td>
<td align="center">$\left(\ln{x}\right)^\prime&#x3D;\frac{1}{x}$</td>
</tr>
<tr>
<td align="center">$\left(\sin{x}\right)^\prime&#x3D;\cos{x}$</td>
<td align="center">$\left(\sin{x}\right)^\prime&#x3D;\cos{x}$</td>
</tr>
<tr>
<td align="center">$\left(\cos{x}\right)^\prime&#x3D;-\sin{x}$</td>
<td align="center">$\left(\cos{x}\right)^\prime&#x3D;-\sin{x}$</td>
</tr>
</tbody></table>
<h3 id="导数的四则运算："><a href="#导数的四则运算：" class="headerlink" title="导数的四则运算："></a>导数的四则运算：</h3><table>
<thead>
<tr>
<th align="center">公式</th>
<th align="center">例子</th>
</tr>
</thead>
<tbody><tr>
<td align="center">$\left[u(x)\pm v(x)\right]^\prime&#x3D;u^\prime(x) \pm v^\prime(x)$</td>
<td align="center">$(e^x+4\ln{x})^\prime&#x3D;(e^x)^\prime+(4\ln{x})^\prime&#x3D;e^x+\frac{4}{x}$</td>
</tr>
<tr>
<td align="center">$\left[u(x)\cdot v(x)\right]^\prime&#x3D;u^\prime(x) \cdot v(x) + u(x) \cdot v^\prime(x)$</td>
<td align="center">$(\sin{x}\cdot\ln{x})^\prime&#x3D;\cos{x}\cdot\ln{x}+\sin{x}\cdot\frac{1}{x}$</td>
</tr>
<tr>
<td align="center">$\left[\frac{u(x)}{v(x)}\right]^\prime&#x3D;\frac{u^\prime(x) \cdot v(x) - u(x) \cdot v^\prime(x)}{v^2(x)}$</td>
<td align="center">$\left(\frac{e^x}{\cos{x}}\right)^\prime&#x3D;\frac{e^x\cdot\cos{x}-e^x\cdot(-\sin{x})}{cos^2(x)}$</td>
</tr>
<tr>
<td align="center">${g[h(x)]}^\prime&#x3D;g^\prime(h)*h^\prime(x)$</td>
<td align="center">$(\sin{2x})^\prime&#x3D;\cos{2x}\cdot(2x)^\prime&#x3D;2\cos(2x)$</td>
</tr>
</tbody></table>
<h3 id="复合函数求导："><a href="#复合函数求导：" class="headerlink" title="复合函数求导："></a>复合函数求导：</h3><blockquote>
<p>链式法则：先对外函数求导，再对内函数求导</p>
</blockquote>
<p>例如：计算函数 $y &#x3D; (x^{2} + 2x)^{2}$ 的导函数：<br>$$<br>\begin{aligned}<br>y’ &amp;&#x3D; 2(x^{2} + 2x)^{(2-1)} \cdot (x^{2} + 2x)’ \<br>   &amp;&#x3D; 2(x^{2} + 2x)(2x + 2) \<br>   &amp;&#x3D; 4(x^{3} + 3x^{2} + 2x) \<br>   &amp;&#x3D; 4x^{3} + 12x^{2} + 8x<br>\end{aligned}<br>$$</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="https://github.com/weiswift">Johnson Liam</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://github.com/weiswift/2025/06/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/">https://github.com/weiswift/2025/06/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/AI/">AI</a></div><div class="post_share"><div class="social-share" data-image="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250605114200229.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> Donate</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2025/06/03/2025.06.03/" title="OLLAMA"><img class="cover" src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250603132906789.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">OLLAMA</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2025/06/03/2025.06.03/" title="OLLAMA"><img class="cover" src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250603132906789.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-03</div><div class="title">OLLAMA</div></div></a></div><div><a href="/2020/06/07/2020-06-07/" title="基于Python的Socket服务器和客户端通信（Pycharm）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-07</div><div class="title">基于Python的Socket服务器和客户端通信（Pycharm）</div></div></a></div><div><a href="/2020/06/15/2020.06.15/" title="Python面向Socket编程Demo"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-15</div><div class="title">Python面向Socket编程Demo</div></div></a></div><div><a href="/2020/06/08/2020.06.08/" title="Python爬虫前置配置及Demo"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-08</div><div class="title">Python爬虫前置配置及Demo</div></div></a></div><div><a href="/2023/04/12/2023.04.12/" title="Python爬虫回顾(爬报价网)"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-04-12</div><div class="title">Python爬虫回顾(爬报价网)</div></div></a></div><div><a href="/2023/06/24/2020.06.18/" title="Python基础(全)"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-24</div><div class="title">Python基础(全)</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/img/pic.webp" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Johnson Liam</div><div class="author-info__description">机器都在学习,你有什么理由不学习?</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">222</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">58</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><a id="card-info-btn" href="https://github.com/weiswift/"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/weiswift" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:1265019024@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">网站由Github服务器托管,感谢支持！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#AI%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD"><span class="toc-number">1.</span> <span class="toc-text">AI人工智能</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%88%86%E7%B1%BB"><span class="toc-number">1.1.</span> <span class="toc-text">人工智能的分类</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80"><span class="toc-number">2.</span> <span class="toc-text">机器学习基础</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="toc-number">2.1.</span> <span class="toc-text">机器学习的概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E2%AD%90%EF%B8%8F"><span class="toc-number">2.2.</span> <span class="toc-text">机器学习工作流程⭐️</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="toc-number">2.2.1.</span> <span class="toc-text">获取数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">2.2.2.</span> <span class="toc-text">数据预处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="toc-number">2.2.3.</span> <span class="toc-text">特征工程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%EF%BC%89"><span class="toc-number">2.2.4.</span> <span class="toc-text">机器学习（模型训练）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0"><span class="toc-number">2.2.5.</span> <span class="toc-text">模型评估</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Sklearn%E4%B8%8E%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E2%AD%90%EF%B8%8F"><span class="toc-number">3.</span> <span class="toc-text">Sklearn与特征工程⭐️</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#sklearn-%E7%9A%84%E6%A0%B8%E5%BF%83%E7%BB%84%E6%88%90"><span class="toc-number">3.1.</span> <span class="toc-text">sklearn 的核心组成</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sklearn%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97-%E9%B8%A2%E5%B0%BE%E8%8A%B1%E6%A1%88%E4%BE%8B%E7%9A%84%E5%85%B8%E5%9E%8B%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B"><span class="toc-number">3.2.</span> <span class="toc-text">sklearn随机森林-鸢尾花案例的典型代码流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#sklear%E5%85%B8%E5%9E%8B%E6%B5%81%E7%A8%8B-%E5%B8%A6%E6%B3%A8%E9%87%8A%E8%AF%A6%E8%A7%A3"><span class="toc-number">3.2.1.</span> <span class="toc-text">sklear典型流程(带注释详解)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Seaborn%E9%B8%A2%E5%B0%BE%E8%8A%B1%E6%A1%88%E4%BE%8B"><span class="toc-number">3.3.</span> <span class="toc-text">Seaborn鸢尾花案例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E4%B8%8E%E8%B0%83%E4%BC%98"><span class="toc-number">3.4.</span> <span class="toc-text">模型选择与调优</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="toc-number">3.4.1.</span> <span class="toc-text">交叉验证</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2"><span class="toc-number">3.4.2.</span> <span class="toc-text">网格搜索</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%B8%A2%E5%B0%BE%E8%8A%B1%E6%A1%88%E4%BE%8B%E5%A2%9E%E5%8A%A0K%E5%80%BC%E8%B0%83%E4%BC%98"><span class="toc-number">3.5.</span> <span class="toc-text">鸢尾花案例增加K值调优</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#KNN%E7%AE%97%E6%B3%95"><span class="toc-number">4.</span> <span class="toc-text">KNN算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#KNN%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B"><span class="toc-number">4.1.</span> <span class="toc-text">KNN算法流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#K%E5%80%BC%E5%A4%A7%E5%B0%8F%E5%AF%B9%E4%BA%8E%E8%AE%AD%E7%BB%83%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">4.1.1.</span> <span class="toc-text">K值大小对于训练的影响</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AC%A7%E5%BC%8F%E8%B7%9D%E7%A6%BB"><span class="toc-number">4.2.</span> <span class="toc-text">欧式距离</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%BA%8C%E7%BB%B4%E7%A9%BA%E9%97%B4"><span class="toc-number">4.2.1.</span> <span class="toc-text">1. 二维空间</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E4%B8%89%E7%BB%B4%E7%A9%BA%E9%97%B4"><span class="toc-number">4.2.2.</span> <span class="toc-text">2. 三维空间</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-n%E7%BB%B4%E7%A9%BA%E9%97%B4"><span class="toc-number">4.2.3.</span> <span class="toc-text">3. n维空间</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sklearn-KNN%E7%AE%97%E6%B3%95"><span class="toc-number">4.3.</span> <span class="toc-text">sklearn-KNN算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%84%E7%A7%8D%E8%B7%9D%E7%A6%BB%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F"><span class="toc-number">4.4.</span> <span class="toc-text">各种距离计算方式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KD%E6%A0%91"><span class="toc-number">4.5.</span> <span class="toc-text">KD树</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#KD%E6%A0%91%E7%9A%84%E6%9E%84%E5%BB%BA%EF%BC%88%E4%BA%8C%E7%BB%B4%E5%B9%B3%E9%9D%A2%EF%BC%89"><span class="toc-number">4.5.1.</span> <span class="toc-text">KD树的构建（二维平面）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KD%E6%A0%91%E7%9A%84%E5%BF%AB%E9%80%9F%E6%9C%80%E8%BF%91%E9%82%BB%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95"><span class="toc-number">4.5.2.</span> <span class="toc-text">KD树的快速最近邻搜索算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KD%E6%A0%91%E7%9A%84%E6%8F%92%E5%85%A5"><span class="toc-number">4.5.3.</span> <span class="toc-text">KD树的插入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KD%E6%A0%91%E7%9A%84%E5%88%A0%E9%99%A4"><span class="toc-number">4.5.4.</span> <span class="toc-text">KD树的删除</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">5.</span> <span class="toc-text">线性回归</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%AE%9A%E4%B9%89%E2%AD%90%EF%B8%8F"><span class="toc-number">5.1.</span> <span class="toc-text">线性回归定义⭐️</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%9A%E7%94%A8%E5%85%AC%E5%BC%8F"><span class="toc-number">5.1.1.</span> <span class="toc-text">通用公式</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#begin-bmatrix-1-amp-1-0-amp-1-2-amp-1-end-bmatrix-begin-bmatrix-x-1-x-2-end-bmatrix"><span class="toc-number">6.</span> <span class="toc-text">$\begin{bmatrix}1 &amp; 1 \0 &amp; 1 \2 &amp; 1\end{bmatrix}\begin{bmatrix}x_1 \x_2\end{bmatrix}</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E5%88%86%E7%B1%BB%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">6.1.</span> <span class="toc-text">线性回归的分类及应用场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E2%AD%90%EF%B8%8F"><span class="toc-number">6.2.</span> <span class="toc-text">损失函数⭐️</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9D%87%E6%96%B9%E6%A0%B9%E8%AF%AF%E5%B7%AE%E5%87%BD%E6%95%B0-Mean-Squared-Error-MSE-%EF%BC%9A"><span class="toc-number">6.2.1.</span> <span class="toc-text">均方根误差函数(Mean Squared Error, MSE)：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%9D%E5%AF%B9%E5%80%BC%E8%AF%AF%E5%B7%AE%E5%87%BD%E6%95%B0-Mean-Absolute-Error-MAE-%EF%BC%9A"><span class="toc-number">6.2.2.</span> <span class="toc-text">绝对值误差函数(Mean Absolute Error, MAE)：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MSE%E4%B8%8EMAE%E5%AF%B9%E6%AF%94%E2%AD%90%EF%B8%8F"><span class="toc-number">6.2.3.</span> <span class="toc-text">MSE与MAE对比⭐️</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95%E2%AD%90%EF%B8%8F"><span class="toc-number">6.3.</span> <span class="toc-text">梯度下降算法⭐️</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95%E2%AD%90%EF%B8%8F"><span class="toc-number">6.4.</span> <span class="toc-text">回归模型评估方法⭐️</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92API%E5%8F%8A%E6%A1%88%E4%BE%8B"><span class="toc-number">6.5.</span> <span class="toc-text">线性回归API及案例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88%E5%87%BA%E7%8E%B0%E5%8E%9F%E5%9B%A0%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E2%AD%90%EF%B8%8F"><span class="toc-number">6.6.</span> <span class="toc-text">过拟合和欠拟合出现原因及解决方案⭐️</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="toc-number">7.</span> <span class="toc-text">逻辑回归</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">8.</span> <span class="toc-text">决策树</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0"><span class="toc-number">9.</span> <span class="toc-text">集成学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="toc-number">10.</span> <span class="toc-text">聚类算法</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF"><span class="toc-number">11.</span> <span class="toc-text">朴素贝叶斯</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="toc-number">12.</span> <span class="toc-text">支持向量机</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#EM%E7%AE%97%E6%B3%95"><span class="toc-number">13.</span> <span class="toc-text">EM算法</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#HMM%E6%A8%A1%E5%9E%8B"><span class="toc-number">14.</span> <span class="toc-text">HMM模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0-1"><span class="toc-number">15.</span> <span class="toc-text">模型评估</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%99%84%E4%BB%B6"><span class="toc-number">16.</span> <span class="toc-text">附件</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AC%E5%85%B1%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="toc-number">16.1.</span> <span class="toc-text">公共基础知识</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%87%E9%87%8F%EF%BC%88Scalar%EF%BC%89"><span class="toc-number">16.1.1.</span> <span class="toc-text">标量（Scalar）:</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%91%E9%87%8F%EF%BC%88Vector%EF%BC%89"><span class="toc-number">16.1.2.</span> <span class="toc-text">向量（Vector）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%A0%E9%87%8F%EF%BC%88Tensor%EF%BC%89"><span class="toc-number">16.1.3.</span> <span class="toc-text">张量（Tensor）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E8%80%85%E5%8C%BA%E5%88%AB"><span class="toc-number">16.1.4.</span> <span class="toc-text">三者区别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%BE%E5%BD%A2%E5%B1%95%E7%A4%BA"><span class="toc-number">16.1.5.</span> <span class="toc-text">图形展示</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">16.1.6.</span> <span class="toc-text">应用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Latex%E6%95%B0%E5%AD%A6%E8%AF%AD%E6%B3%95%E6%94%AF%E6%8C%81"><span class="toc-number">16.2.</span> <span class="toc-text">Latex数学语法支持</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%BC%E6%95%B0-amp-%E7%9F%A9%E9%98%B5-amp-%E5%90%91%E9%87%8F"><span class="toc-number">16.3.</span> <span class="toc-text">导数&amp;矩阵&amp;向量</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E5%87%BD%E6%95%B0%E7%9A%84%E5%AF%BC%E6%95%B0%EF%BC%9A"><span class="toc-number">16.3.1.</span> <span class="toc-text">常见函数的导数：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%BC%E6%95%B0%E7%9A%84%E5%9B%9B%E5%88%99%E8%BF%90%E7%AE%97%EF%BC%9A"><span class="toc-number">16.3.2.</span> <span class="toc-text">导数的四则运算：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%8D%E5%90%88%E5%87%BD%E6%95%B0%E6%B1%82%E5%AF%BC%EF%BC%9A"><span class="toc-number">16.3.3.</span> <span class="toc-text">复合函数求导：</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/06/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" title="机器学习"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250605114200229.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="机器学习"/></a><div class="content"><a class="title" href="/2025/06/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" title="机器学习">机器学习</a><time datetime="2025-06-03T16:00:00.000Z" title="Created 2025-06-04 00:00:00">2025-06-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/03/2025.06.03/" title="OLLAMA"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250603132906789.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="OLLAMA"/></a><div class="content"><a class="title" href="/2025/06/03/2025.06.03/" title="OLLAMA">OLLAMA</a><time datetime="2025-06-02T16:00:00.000Z" title="Created 2025-06-03 00:00:00">2025-06-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/05/10/2025.05.10/" title="Mozi病毒样本分析"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250604210840482.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Mozi病毒样本分析"/></a><div class="content"><a class="title" href="/2025/05/10/2025.05.10/" title="Mozi病毒样本分析">Mozi病毒样本分析</a><time datetime="2025-05-09T16:00:00.000Z" title="Created 2025-05-10 00:00:00">2025-05-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/04/28/2025.04.28/" title="P2P通信"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250604211011599.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="P2P通信"/></a><div class="content"><a class="title" href="/2025/04/28/2025.04.28/" title="P2P通信">P2P通信</a><time datetime="2025-04-27T16:00:00.000Z" title="Created 2025-04-28 00:00:00">2025-04-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/03/21/2025.03.21/" title="记录一次磁盘坏掉排查过程"><img src="https://wei-blog.oss-cn-beijing.aliyuncs.com/24-07/image-20250604203833317.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="记录一次磁盘坏掉排查过程"/></a><div class="content"><a class="title" href="/2025/03/21/2025.03.21/" title="记录一次磁盘坏掉排查过程">记录一次磁盘坏掉排查过程</a><time datetime="2025-03-20T16:00:00.000Z" title="Created 2025-03-21 00:00:00">2025-03-21</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Johnson Liam</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Welcome to 小威の <a target="_blank" rel="noopener" href="https://www.cnblogs.com/liam-sliversucks/">Blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><canvas class="fireworks" mobile="true"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="true"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>